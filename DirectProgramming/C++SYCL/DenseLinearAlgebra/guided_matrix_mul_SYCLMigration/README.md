# `Matrix Multiplication cuBLAS Migrated` Sample

The `Matrix Multiplication cuBLAS Migrated` sample is a sample illustrating GPU performance for matrix multiplication. This sample also shows how to use the migrated code in a high-performance performance way for matrix multiplication.

| Area                   | Description
|:---                    |:---
| What you will learn    | How to begin migrating CUDA code to a SYCL*-compliant equivalent
| Time to complete       | 90 minutes
| Category               | Code Optimization

For more information on oneMKL and complete documentation of all oneMKL routines, see https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-documentation.html.

## Purpose

The sample source code using SYCL was migrated from CUDA source code for offloading computations to a GPU/CPU. The sample demonstrates how to migrate code to SYCL, optimize the migration steps, and improve processing time.

The sample source files show the usage of oneMKL and performance for GPU/CPU.

>**Note**: This sample is based on the [*CUDA Samples - CUDA Libraries*](https://github.com/NVIDIA/cuda-samples/tree/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS) sample in the NVIDIA/cuda-samples GitHub repository.

## Prerequisites

| Optimized for         | Description
|:---                   |:---
| OS                    | Ubuntu* 20.04
| Hardware              | 10th Gen Intel® processors or newer
| Software              | Intel® oneAPI DPC++/C++ Compiler

## Key Implementation Details

This sample contains two sets of sources in the following folders:

| Folder Name             | Description
|:---                     |:---
| `01_sycl_dpct_output`   | Contains output of Intel® DPC++ Compatibility Tool used to migrate SYCL-compliant code from CUDA code. <br> This SYCL code has some unmigrated or incorrectly generated code that has to be manually fixed before it is functional. (The code does not work as supplied.)
| `02_sycl_dpct_migrated` | Contains SYCL to CUDA migrated code generated by using the Intel® DPC++ Compatibility Tool with the manual changes implemented to make the code fully functional.

## Set Environment Variables

When working with the command-line interface (CLI), you should configure the oneAPI toolkits using environment variables. Set up your CLI environment by sourcing the `setvars` script every time you open a new terminal window. This practice ensures that your compiler, libraries, and tools are ready for development.

## Build the `Matrix Multiplication cuBLAS Migrated` Sample

> **Note**: If you have not already done so, set up your CLI
> environment by sourcing  the `setvars` script in the root of your oneAPI installation.
>
> Linux*:
> - For system wide installations: `. /opt/intel/oneapi/setvars.sh`
> - For private installations: ` . ~/intel/oneapi/setvars.sh`
> - For non-POSIX shells, like csh, use the following command: `bash -c 'source <install-dir>/setvars.sh ; exec csh'`
>
> For more information on configuring environment variables, see *[Use the setvars Script with Linux* or macOS*](https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-script-with-linux-or-macos.html)*.

### On Linux*

1. Change to the sample directory.
2. Build the samples.
   ```
   $ mkdir build
   $ cd build
   $ cmake ..
   $ make
   ```

   By default, this command sequence builds the version of the source code in the  `02_sycl_dpct_migrated` folder.

#### Troubleshooting

If an error occurs, you can get more details by running `make` with
the `VERBOSE=1` argument:
```
make VERBOSE=1
```
If you receive an error message, troubleshoot the problem using the **Diagnostics Utility for Intel® oneAPI Toolkits**. The diagnostic utility provides configuration and system checks to help find missing dependencies, permissions errors, and other issues. See the [Diagnostics Utility for Intel® oneAPI Toolkits User Guide](https://www.intel.com/content/www/us/en/develop/documentation/diagnostic-utility-user-guide/top.html) for more information on using the utility.


## Run the `Matrix Multiplication cuBLAS Migrated` Sample

### On Linux

Run the programs on a CPU or GPU. Each sample uses a default device, which in most cases is a GPU.

1. Run the samples in the `02_sycl_dpct_migrated` folder.
   ```
   make run_matrix_mul
   ```

### Build and Run the `Matrix Multiplication cuBLAS Migrated` Sample in Intel® DevCloud (Optional)

When running a sample in the Intel® DevCloud, you must specify the compute node (CPU, GPU, FPGA) and whether to run in batch or interactive mode. For more information, see the Intel® oneAPI Base Toolkit [Get Started Guide](https://devcloud.intel.com/oneapi/get_started/).

#### Build and Run Samples in Batch Mode (Optional)

You can submit build and run jobs through a Portable Bash Script (PBS). A job is a script that submitted to PBS through the `qsub` utility. By default, the `qsub` utility does not inherit the current environment variables or your current working directory, so you might need to submit jobs to configure the environment variables. To indicate the correct working directory, you can use either absolute paths or pass the `-d \<dir\>` option to `qsub`.

1. Open a terminal on a Linux* system.
2. Log in to Intel® DevCloud.
   ```
   ssh devcloud
   ```
3. Download the samples.
   ```
   git clone https://github.com/oneapi-src/oneAPI-samples.git
   ```
4. Change to the sample directory.
5. Configure the sample for a GPU node and choose the backend as OpenCL.
   ```
   qsub  -I  -l nodes=1:gpu:ppn=2 -d .
   export SYCL_DEVICE_FILTER=opencl:gpu
   ```
   - `-I` (upper case I) requests an interactive session.
   - `-l nodes=1:gpu:ppn=2` (lower case L) assigns one full GPU node.
   - `-d .` makes the current folder as the working directory for the task.

     |Available Nodes  |Command Options
     |:---             |:---
     | GPU	           |`qsub -l nodes=1:gpu:ppn=2 -d .`
     | CPU	           |`qsub -l nodes=1:xeon:ppn=2 -d .`

6. Perform build steps as you would on Linux.
7. Run the programs.
8. Clean up the project files.
   ```
   make clean
   ```
9. Disconnect from the Intel® DevCloud.
   ```
   exit
   ```

## Example Output

This is example output if you built the default and ran `run_matrix_mul`.

```
[ 50%] Building CXX object 02_sycl_dpct_migrated/CMakeFiles/02_sycl_dpct_migrated.dir/src/matrixMulCUBLAS.cpp.o
[100%] Linking CXX executable ../bin/02_sycl_dpct_migrated
[100%] Built target 02_sycl_dpct_migrated
[Matrix Multiply CUBLAS] - Starting...
GPU Device 0: "Intel(R) Core(TM) i7-10610U CPU @ 1.80GHz" with compute capability 3.0

MatrixA(640,480), MatrixB(480,320), MatrixC(640,320)
Computing result using CUBLAS...done.
Performance= 3676.94 GFlop/s, Time= 0.053 msec, Size= 196608000 Ops
Computing result using host CPU...done.
Comparing CUBLAS Matrix Multiply with CPU results: PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
Built target run_matrix_mul
```

## License

Code samples are licensed under the MIT license. See
[License.txt](https://github.com/oneapi-src/oneAPI-samples/blob/master/License.txt) for details.

Third party program licenses are at [third-party-programs.txt](https://github.com/oneapi-src/oneAPI-samples/blob/master/third-party-programs.txt).
