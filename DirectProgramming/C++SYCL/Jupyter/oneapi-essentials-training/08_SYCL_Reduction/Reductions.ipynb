{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kernel Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [What are Reductions?](#What-are-Reductions?)\n",
    "- _Code:_ [Reduction with single_task](#Reduction-with-single_task)\n",
    "- [Group Reduction](#Group-Reduction)\n",
    "- _Code:_ [Reduction using work_group reduce](#Reduction-using-work_group-reduce)\n",
    "- [Reduction object in parallel_for](#Reduction-simplification-in-parallel_for)\n",
    "- _Code:_ [Reduction in parallel_for USM](#Reduction-in-parallel_for-USM)\n",
    "- _Code:_ [Reduction in parallel_for Buffers](#Reduction-in-parallel_for-Buffers)\n",
    "- _Code:_ [Multiple Reductions in one kernel](#Multiple-Reductions-in-one-kernel)\n",
    "- _Code:_ [Reduction with Custom Operator](#Reduction-with-Custom-Operator)\n",
    "- _Lab Exercise:_ [Kernel Reduction](#Lab-Exercise:-Kernel-Reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand how reductions can be performed with parallel kernels\n",
    "- Take advantages __reduce group function__ to do reduction at sub_group and work_group level\n",
    "- Use __reduction object__ to simplify reduction with parallel kernels\n",
    "- Use __multiple__ reductions in a single kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Reductions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __reduction produces a single value by combining multiple values__ in an unspecified order, using an operator that is both associative and commutative (e.g. addition). Only the final value resulting from a reduction is of interest to the programmer.\n",
    "\n",
    "A very common example is calculating __sum__ by adding a bunch of values.\n",
    "\n",
    "Parallelizing reductions can be tricky because of the nature of computation and accelerator hardware. Let's look at code examples showing how reduction can be performed on GPU using kernel invocation using __single_task__ and __parallel_for__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction with single_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to write a kernel function to compute sum for GPU is using a kernel invocation using __single_task__ and using a simple __for-loop__ to compute the sum of all values in the array. This way of reduction works but there is no parallelism in computation.\n",
    "\n",
    "```cpp\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i++){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  });\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SYCL code below demonstrates computing sum of array of values using `single_task` for kernel invocation.\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/sum_single_task.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "\n",
    "int main() {\n",
    "  //# setup sycl::queue with default device selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# user single_task to add all numbers\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i++){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << data[0] << \"\\n\";\n",
    "  \n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_single_task.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_single_task.sh; else ./run_sum_single_task.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction with parallel_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ND-Range kernel allows grouping executions that map to __compute units__ on hardware which allows for parallel execution of work-groups. As shows in the picture below, the entire range is divided into `work_group` which execute on a compute unit on the GPU hardware. Depending on number of compute units in the hardware, multiple work_groups can be executed to get parallelism. This allows to compute sum of each `work_group` and then it is further reduced to add all the work_group sums using a `single_task` kernel invocation. This gives better performance than the previous example which only uses `single_task` to do reduction.\n",
    "\n",
    "<img src=\"assets/hwmapping.png\" alt=\"hwmapping.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sycl::reduce_over_group()` function is group algorithm in SYCL which can also be used to perform certain common reduction operations in the kernel function for each `sub_group` or `work_group`. The reduce function can be used to **simplify reduction computation** with one line of code as shown below, instead of manually coding reduction with for-loop:\n",
    "\n",
    "\n",
    "```cpp\n",
    "      sum = sycl::reduce_over_group(group, data[i], sycl::plus<>());\n",
    "```\n",
    "\n",
    "The `sycl::reduce_over_group()` function takes three parameters: work-group/sub-group, work-item and operation to be performed on the group. There are various common parallel operations available like `sycl::plus<>()`, `sycl::maximum<>()` or `sycl::minimum<>()`\n",
    "\n",
    "Using this reduce function on a `sub_group` will optimize computation by leveraging sub_group shuffle operation to load values from register instead of making repeated access to global memory. The reduce function can also be used on a `work_group` which is also optimized implicitly by making use of sub_group functionality. \n",
    "\n",
    "The next section show how reduce function can be used on `work_group` to do reduction computation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction using work_group reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses work_group reduce function to add all items in a work_group and then the final computation is accomplished using single_task kernel invocation to add all work_group sums.\n",
    "\n",
    "The SYCL code below demonstrates work-group reduce: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/sum_workgroup_reduce.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with in_order property\n",
    "  queue q(property::queue::in_order{});\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# use parallel_for to calculate sum for work_group using reduce\n",
    "  q.parallel_for(nd_range<1>(N, B), [=](nd_item<1> item){\n",
    "    auto wg = item.get_group();\n",
    "    auto i = item.get_global_id(0);\n",
    "\n",
    "    //# Adds all elements in work_group using work_group reduce\n",
    "    int sum_wg = reduce_over_group(wg, data[i], plus<>());\n",
    "\n",
    "    //# write work_group sum to first location for each work_group\n",
    "    if (item.get_local_id(0) == 0) data[i] = sum_wg;\n",
    "\n",
    "  });\n",
    "\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i+=B){\n",
    "        sum += data[i];\n",
    "    }\n",
    "    data[0] = sum;\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << data[0] << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_workgroup_reduce.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_workgroup_reduce.sh; else ./run_sum_workgroup_reduce.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction object in parallel_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples of reduction, the computation requires a two step approach to first perform reduction at group level and then perform reduction of output from each group. This section introduces to a new extension that will greatly simplify reduction computation.\n",
    "\n",
    "__SYCL introduces reduction to the ND-range version of parallel_for__, using syntax that is roughly aligned with OpenMP and C++ for_loop.\n",
    "\n",
    "It is common for parallel kernels to produce a single output resulting from some combination of all inputs (e.g. the sum). Writing efficient reductions is a complex task, depending on both device and runtime characteristics. Providing an abstraction for reductions in SYCL would greatly improve programmer productivity.\n",
    "\n",
    "`sycl::reduction` object in parallel_for encapsulates the reduction variable, an optional operator identity and the reduction operator as shown below:\n",
    "\n",
    "```cpp\n",
    "     q.parallel_for(nd_range<1>{N, B}, sycl::reduction(sum, sycl::plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "       int i = it.get_global_id(0);\n",
    "       temp.combine(data[i]);\n",
    "     });\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction in parallel_for USM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction with just one kernel using Unified Shared Memory(USM) for memory management.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with USM: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/sum_reduction_usm.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# implicit USM for writing sum value\n",
    "  int* sum = malloc_shared<int>(1, q);\n",
    "  *sum = 0;\n",
    "\n",
    "  //# nd-range kernel parallel_for with reduction parameter\n",
    "  q.parallel_for(nd_range<1>{N, B}, reduction(sum, plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "    auto i = it.get_global_id(0);\n",
    "    temp.combine(data[i]);\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << *sum << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  free(sum, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_reduction_usm.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_reduction_usm.sh; else ./run_sum_reduction_usm.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction in parallel_for Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction with just one kernel using SYCL buffers and accessors for memory management.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with Buffers: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/sum_reduction_buffers.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  std::vector<int> data(N);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  int sum = 0;\n",
    "  {\n",
    "    //# create buffers for data and sum\n",
    "    buffer buf_data(data);\n",
    "    buffer buf_sum(&sum, range(1));\n",
    "\n",
    "    q.submit([&](handler& h) {\n",
    "      //# create accessors for buffer\n",
    "      accessor acc_data(buf_data, h, read_only);\n",
    "\n",
    "      //# nd-range kernel parallel_for with reduction parameter\n",
    "      h.parallel_for(nd_range<1>{N, B}, reduction(buf_sum, h, plus<>()), [=](nd_item<1> it, auto& temp) {\n",
    "        auto i = it.get_global_id(0);\n",
    "        temp.combine(acc_data[i]);\n",
    "      });\n",
    "    });\n",
    "  }\n",
    "  std::cout << \"Sum = \" << sum << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_sum_reduction_buffers.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_sum_reduction_buffers.sh; else ./run_sum_reduction_buffers.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Reductions in one kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses multiple __sycl::reduction__ objects in _parallel_for_ to compute the reductions with just one kernel using SYCL buffers and accessors for memory management.\n",
    "\n",
    "Multiple reductions are also supported with just one kernel, the code snippet below shows how to define a kernel using parallel_for with multiple reduction objects:\n",
    "\n",
    "```cpp\n",
    "h.parallel_for(nd_range<1>{N, B}, reduction1, reduction2, ..., [=](nd_item<1> it, auto& temp1, auto& temp2, ...) {\n",
    "  // kernel code\n",
    "});\n",
    "```\n",
    "\n",
    "The SYCL code below demonstrates multiple reduction in parallel_for with Buffers: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/multiple_reductions_buffers.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize inputs and outputs\n",
    "  std::vector<int> data(N);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "  int sum = 0, min = 0, max = 0;\n",
    "  {\n",
    "    //# create buffers\n",
    "    buffer buf_data(data);\n",
    "    buffer buf_sum(&sum, range(1));\n",
    "    buffer buf_min(&min, range(1));\n",
    "    buffer buf_max(&max, range(1));\n",
    "\n",
    "    q.submit([&](handler& h) {\n",
    "      //# create accessors for data and results\n",
    "      accessor acc_data(buf_data, h, read_only);\n",
    "        \n",
    "      //# define reduction objects for sum, min, max reduction\n",
    "      auto reduction_sum = reduction(buf_sum, h, plus<>());\n",
    "      auto reduction_min = reduction(buf_min, h, minimum<>());\n",
    "      auto reduction_max = reduction(buf_max, h, maximum<>());\n",
    "      \n",
    "      //# parallel_for with multiple reduction objects\n",
    "      h.parallel_for(nd_range<1>{N, B}, reduction_sum, reduction_min, reduction_max, [=](nd_item<1> it, auto& temp_sum, auto& temp_min, auto& temp_max) {\n",
    "        auto i = it.get_global_id();\n",
    "        temp_sum.combine(acc_data[i]);\n",
    "        temp_min.combine(acc_data[i]);\n",
    "        temp_max.combine(acc_data[i]);\n",
    "      });\n",
    "    });\n",
    "  }\n",
    " \n",
    "  //# print results\n",
    "  std::cout << \"Sum       = \" << sum << \"\\n\";\n",
    "  std::cout << \"Min       = \" << min << \"\\n\"; \n",
    "  std::cout << \"Max       = \" << max << \"\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_multiple_reductions_buffers.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_multiple_reductions_buffers.sh; else ./run_multiple_reductions_buffers.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduction with Custom Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below uses __sycl::reduction__ object in _parallel_for_ to compute the reduction object that uses a custom operator to find minimum value and index.\n",
    "\n",
    "The SYCL code below demonstrates reduction in parallel_for with custom user defined operator to perform reduction: Inspect code, there are no modifications necessary:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/reduction_custom_operator.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "#include <time.h>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 256; // global size\n",
    "static constexpr size_t B = 64; // work-group size\n",
    "\n",
    "template <typename T, typename I>\n",
    "struct pair {\n",
    "  bool operator<(const pair& o) const {\n",
    "    return val <= o.val || (val == o.val && idx <= o.idx);\n",
    "  }\n",
    "  T val;\n",
    "  I idx;\n",
    "};\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    " \n",
    "  //# initialize input data and result using usm\n",
    "  auto result = malloc_shared<pair<int, int>>(1, q);\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "\n",
    "  //# initialize input data with random numbers\n",
    "  srand(time(0));\n",
    "  for (int i = 0; i < N; ++i) data[i] = rand() % 256;\n",
    "  std::cout << \"Input Data:\\n\";\n",
    "  for (int i = 0; i < N; i++) std::cout << data[i] << \" \"; std::cout << \"\\n\\n\";\n",
    "\n",
    "  //# custom operator for reduction to find minumum and index\n",
    "  pair<int, int> operator_identity = {std::numeric_limits<int>::max(), std::numeric_limits<int>::min()};\n",
    "  *result = operator_identity;\n",
    "  auto reduction_object = reduction(result, operator_identity, minimum<pair<int, int>>());\n",
    "\n",
    "  //# parallel_for with user defined reduction object\n",
    "  q.parallel_for(nd_range<1>{N, B}, reduction_object, [=](nd_item<1> item, auto& temp) {\n",
    "       int i = item.get_global_id(0);\n",
    "       temp.combine({data[i], i});\n",
    "  }).wait();\n",
    "\n",
    "  std::cout << \"Minimum value and index = \" << result->val << \" at \" << result->idx << \"\\n\";\n",
    "\n",
    "  free(result, q);\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_reduction_custom_operator.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_custom_operator.sh; else ./run_reduction_custom_operator.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lab Exercise: Kernel Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the coding excercise below using Kernel Reduction concepts:\n",
    "- The code has an array `data` of size `N=1024` elements initialized\n",
    "- We will offload reduction kernel task to find the minimum and maximum values from the `data` array\n",
    "- Create reduction objects for finding minimum and maximum\n",
    "- Create reduction kernel using `parallel_for` with reduction objects for minimum and maximum.\n",
    "- On the host, compute mid-range, which is average of min and max values\n",
    "\n",
    "1. Edit the code cell below by following the steps and then click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile lab/reduction_lab.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "static constexpr size_t N = 1024; // global size\n",
    "static constexpr size_t B = 128; // work-group size\n",
    "\n",
    "int main() {\n",
    "  //# setup queue with default selector\n",
    "  queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  auto data = malloc_shared<int>(N, q);\n",
    "  for (int i = 0; i < N; i++) data[i] = i;\n",
    "\n",
    "  //# implicit USM for writing min and max value\n",
    "  int* min = malloc_shared<int>(1, q);\n",
    "  int* max = malloc_shared<int>(1, q);\n",
    "  *min = 0;\n",
    "  *max = 0;\n",
    "    \n",
    "  //# STEP 1 : Create reduction objects for computing min and max\n",
    "  \n",
    "  //# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  //# Reduction Kernel get min and max\n",
    "  q.submit([&](handler& h) {\n",
    "      \n",
    "    //# STEP 2 : add parallel_for with reduction objects for min and max\n",
    "    \n",
    "    //# YOUR CODE GOES HERE\n",
    "\n",
    "\n",
    "\n",
    "  }).wait();\n",
    "    \n",
    "  //# STEP 3 : Compute mid_range from min and max\n",
    "  int mid_range = 0;\n",
    "\n",
    "  //# YOUR CODE GOES HERE\n",
    "\n",
    "  std::cout << \"Mid-Range = \" << mid_range << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  free(min, q);\n",
    "  free(max, q);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 run_reduction_lab.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_reduction_lab.sh; else ./run_reduction_lab.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sycl::reduce_over_group` function for sub_group/work_group and `sycl::reduction` in parallel_for helps to optimize and simplify reduction computation in SYCL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
