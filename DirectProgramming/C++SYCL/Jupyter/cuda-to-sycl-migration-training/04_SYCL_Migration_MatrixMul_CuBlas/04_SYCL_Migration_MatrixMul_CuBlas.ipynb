{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726797c2-06bd-4fbe-88b0-734adc409770",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SYCL Migration - Matrix Multiplication cuBlas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada1808-d73a-4d96-a1bf-9dccdab7747b",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [Introduction](#Introduction)\n",
    "- [Analyze CUDA source](#Analyze-CUDA-source)\n",
    "- [Migrate CUDA source to SYCL source](#Migrate-CUDA-source-to-SYCL-source)\n",
    "- [Analyze, Compile and Run the migrated SYCL source](#Analyze,-Compile-and-Run-the-migrated-SYCL-source)\n",
    "- [Source Code](#Source-Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fbb8d-244b-4f90-9de9-3846df15afc1",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Use SYCLomatic Tool to migrate a simple single source CUDA application\n",
    "* Use various command line options of `SYCLomatic` for CUDA to SYCL migration\n",
    "* Compile and run migrated SYCL code on Intel CPUs and GPUs\n",
    "* Optimize the migrated SYCL code with manual coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e6c1f-95ee-419d-8149-6a7789998ef0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This module will walk you through migrating CUDA code to SYCL code using Intel SYCLomatic Tool\n",
    "\n",
    "#### Requirements\n",
    "1. NVidia CUDA development machine\n",
    "2. Development machine with Intel CPU/GPU OR a Intel Developer Cloud account\n",
    "\n",
    "#### Migration Process\n",
    "We will do the following steps in this hands-on workshop:\n",
    "- Analyze CUDA source\n",
    "- Migrate CUDA source to SYCL source\n",
    "- Analyze, Compile and Run the migrated SYCL source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5aa043-0d1f-43df-9a9a-e38f13e4bc86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyze CUDA source\n",
    "\n",
    "The CUDA source for \"Matrix Multiplication cuBlas\" example is available on [Nvidia Github](https://github.com/NVIDIA/cuda-samples/tree/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS/)\n",
    "\n",
    "Pull the entire repository on your CUDA Development machine.\n",
    "\n",
    "```\n",
    "git clone https://github.com/NVIDIA/cuda-samples.git\n",
    "\n",
    "cd cuda-samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS/\n",
    "```\n",
    "\n",
    "The CUDA source for the Matrix Multiplication cuBlas implementation is in the following files.\n",
    "\n",
    "[__matrixMulCUBLAS.cpp__](https://github.com/NVIDIA/cuda-samples/blob/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS/) — host code for:\n",
    "- setting up CUDA stream\n",
    "- memory allocation on GPU\n",
    "- initialization of data on CPU\n",
    "- copy data to GPU memory for computation\n",
    "- kickoff computation on GPU using cuBlas function\n",
    "- verify and print results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495ba6e-e388-4270-87ee-72a669b1aef3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Migrate CUDA source to SYCL source\n",
    "\n",
    "<p style=\"background-color:#cdc\"> Note: A CUDA development machine is required to accomplish the task in this section </p>\n",
    "\n",
    "Now that we have analyzed the CUDA source, we will migrate the CUDA source into SYCL source using the __SYCLomatic Tool__.\n",
    "\n",
    "In this exercise, we will walk you through step-by-step to migrate the CUDA code.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "Make sure you have a __NVIDIA CUDA development machine__ that can __compile and run CUDA code__. The next step is to install the tools for migrating CUDA to SYCL:\n",
    "\n",
    "- Install SYCLomatic Tool on this machine\n",
    "  - go to https://github.com/oneapi-src/SYCLomatic/releases/\n",
    "  - copy link to latest `linux_release.tgz` from assets\n",
    "  - on the CUDA development machine: `mkdir syclomatic; cd syclomatic`\n",
    "  - `wget <link to linux_release.tgz>`\n",
    "  - `tar -xvf linux_release.tgz`\n",
    "  - `export PATH=\"/home/$USER/syclomatic/bin:$PATH\"`\n",
    "  - Verify installation: `c2s --version`\n",
    "- pull the CUDA samples repo to this machine\n",
    "  - `git clone https://github.com/NVIDIA/cuda-samples.git`\n",
    "- Compile and run the `matrixMulCUBLAS` sample\n",
    "  - `cd cuda-samples/Samples/4_CUDA_Libraries/matrixMulCUBLAS`\n",
    "  - `make`\n",
    "\n",
    "\n",
    "### Migrate CUDA source to SYCL source using SYCLomatic\n",
    "\n",
    "On the NVIDIA CUDA Development machine, go to the CUDA source folder and generate a compilation database with the tool `intercept-build`. This creates a JSON file with all the compiler invocations, stores the names of the input files and the compiler options.\n",
    "\n",
    "```\n",
    "make clean\n",
    "intercept-build make\n",
    "```\n",
    "\n",
    "This will create a file named `compile_commands.json` in the sample folder.\n",
    "\n",
    "Next, use the SYCLomatic Tool (c2s) to migrate the code; it will store the result in the migration folder `dpct_output`:\n",
    "\n",
    "```\n",
    "c2s -p compile_commands.json --in-root ../../.. --use-custom-helper=api\n",
    "```\n",
    "\n",
    "The `--use-custom-helper=api` option will copy the SYCLomatic helper header files to output directory.\n",
    "\n",
    "The `--in-root` option will specify the path for all the common include files for the CUDA project.\n",
    "\n",
    "This command should migrate the CUDA source to the C++ SYCL source in a folder named `dpct_output` by default, and the folder will have the C++ SYCL source along with any dependencies from the `Common` folder:\n",
    "\n",
    "- `matrixMulCUBLAS.cpp.dp.cpp`\n",
    "\n",
    "This command may also throw a bunch of warnings about the migration process. The CUDA code that cannot be automatically migrated will have warning comments generated in the migrated source files, which have to be manually migrated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641af418-8989-4523-9e21-5bc62f3ac5f3",
   "metadata": {},
   "source": [
    "## Analyze, Compile and Run the migrated SYCL source\n",
    "\n",
    "<p style=\"background-color:#cdc\"> Note: The tasks in this section should be done on Intel DevCloud or on a system with oneAPI Base toolkit installed.</p>\n",
    "\n",
    "The migrated SYCL code are in the `Samples` folder under the `dpct_output` folder:\n",
    "- `matrixMulCUBLAS.cpp.dp.cpp`\n",
    "\n",
    "The `dpct_output` folder also has headers files needed for compiling the migrated SYCL code. The `Common` folder has header files with CUDA helper functions which are migrated to SYCL and the `include` folder has header files with SYCLomatic helper functions.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "Make sure you have one of the following:\n",
    "- __Development machine with Intel CPU/GPU__ with Intel oneAPI Base Toolkit installed\n",
    "- __Intel Developer Cloud__ account to access the Intel CPUs/GPUs on the cloud\n",
    "\n",
    "### Compiling migrated SYCL code\n",
    "\n",
    "Copy the files mentioned above in `dpct_output` folder on __Nvidia Development Machine__ to __Intel Developer Cloud__\n",
    "\n",
    "To compile the migrated SYCL code we can use the following command:\n",
    "```\n",
    "icpx -fsycl -I ../../../Common -I ../../../include *.cpp -lmkl_sycl -lmkl_intel_ilp64 -lmkl_sequential -lmkl_core\n",
    "```\n",
    "\n",
    "There may be compile errors based on whether all of the CUDA code was migrated to SYCL or not. The migrated code may also include comments with warning messages, which could help make it easier to fix the errors. These errors have to be manually fixed to get the code to compile.\n",
    "\n",
    "\n",
    "### SYCLomatic warnings in migrated SYCL code\n",
    "\n",
    "There are other migration warnings that can be looked at to see if any improvements can be made, below are couple examples of warning in `matrixMulCUBLAS.cpp.dp.cpp`:\n",
    "\n",
    "\n",
    "```cpp\n",
    "         /*\n",
    "         DPCT1005:27: The SYCL device version is different from CUDA Compute\n",
    "         Compatibility. You may need to rewrite this code.\n",
    "         */\n",
    "      deviceProp.get_name(), deviceProp.get_major_version(),\n",
    "         deviceProp.get_minor_version()\n",
    "```\n",
    "\n",
    "\n",
    "```cpp\n",
    "    /*\n",
    "    DPCT1012:38: Detected kernel execution time measurement pattern and\n",
    "    generated an initial code for time measurements in SYCL. You can change the\n",
    "    way time is measured depending on your goals.\n",
    "    */\n",
    "    /*\n",
    "    DPCT1024:39: The original code returned the error code that was further\n",
    "    consumed by the program logic. This original code was replaced with 0. You\n",
    "    may need to rewrite the program logic consuming the error code.\n",
    "    */\n",
    "    start_ct1 = std::chrono::steady_clock::now();\n",
    "```\n",
    "\n",
    "### Compile and Run the migrated SYCL source\n",
    "\n",
    "Once you have successfully migrated the CUDA source to the SYCL source, verify that the migrated SYCL code is functioning correctly by compiling and running it on the Intel Developer Cloud, which has a variety of Intel CPUs and GPUs available for development.\n",
    "\n",
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cee9e-52e2-43e0-9ac4-7748b27562e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_sycl_migrated.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b9672-39ae-4193-8af9-103b58667db4",
   "metadata": {},
   "source": [
    "### SYCL Code Migration Analysis\n",
    "\n",
    "When comparing the CUDA code and migrated SYCL code, we can see that there are some 1:1 equivalent calls, which are listed below in the table:\n",
    "\n",
    "| Functionality|CUDA|SYCL\n",
    "|-|-|-\n",
    "| header file|`#include <cuda_runtime.h>`|`#include <CL/sycl.hpp>` <br> `#include <dpct/dpct.hpp>`\n",
    "|library header file|`#include <cublas_v2.h>`|`#include <dpct/blas_utils.hpp>`\n",
    "| Memory allocation on device| `cudaMalloc((void **)&d_A, mem_size_A)`| `d_A = (float *)sycl::malloc_device(mem_size_A, dpct::get_default_queue())`\n",
    "| Copy memory between host and device| `cudaMemcpy(d_A, h_A, mem_size_A, cudaMemcpyHostToDevice)`| `dpct::get_default_queue().memcpy(d_A, h_A, mem_size_A).wait()`\n",
    "| Free device memory allocation| `free(h_A)` | `sycl::free(h_A, q)`\n",
    "| gemm function | `cublasSgemm(...)`| `oneapi::mkl::blas::column_major::gemm(...)`\n",
    "\n",
    "\n",
    "The main kernel operation to perform matrix multiplication is done using `cuBlas` library in CUDA which is migrated to `oneapi::mkl` library function as shown below:\n",
    "\n",
    "cuBlas sgemm function to perform operation in CUDA code:\n",
    "```cpp\n",
    "      checkCudaErrors(cublasSgemm(\n",
    "          handle, CUBLAS_OP_N, CUBLAS_OP_N, matrix_size.uiWB, matrix_size.uiHA,\n",
    "          matrix_size.uiWA, &alpha, d_B, matrix_size.uiWB, d_A,\n",
    "          matrix_size.uiWA, &beta, d_C, matrix_size.uiWB));\n",
    "```\n",
    "\n",
    "oneapi::mkl::blas gemm function to perform operation in SYCL code:\n",
    "```cpp\n",
    "      checkCudaErrors(\n",
    "          (oneapi::mkl::blas::column_major::gemm(\n",
    "               *handle, oneapi::mkl::transpose::nontrans,\n",
    "               oneapi::mkl::transpose::nontrans, matrix_size.uiWB,\n",
    "               matrix_size.uiHA, matrix_size.uiWA, alpha, d_B, matrix_size.uiWB,\n",
    "               d_A, matrix_size.uiWA, beta, d_C, matrix_size.uiWB),\n",
    "           0));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a1da6-16a9-4cca-9e46-12ae431d04c4",
   "metadata": {},
   "source": [
    "## Source Code\n",
    "\n",
    "This section describes the location of the CUDA source and the contents of different SYCL source code directories in this project.\n",
    "\n",
    "| folder name | source code description\n",
    "| --- | ---\n",
    "| [CUDA github](https://github.com/NVIDIA/cuda-samples/tree/master/Samples/4_CUDA_Libraries/matrixMulCUBLAS) | Original CUDA Source used for migration\n",
    "| dpct_output | SYCL migration output from SYCLomatic Tool, compiles without errors\n",
    "| sycl_migrated | Same as dpct_output, compiles without errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5f463-190f-4ebd-9253-505afa1d5046",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this module we have learnt how to migrate simple CUDA source to SYCL source to get functionality using `SYCLomatic` and then analized/optimized the SYCL source by manually coding. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
