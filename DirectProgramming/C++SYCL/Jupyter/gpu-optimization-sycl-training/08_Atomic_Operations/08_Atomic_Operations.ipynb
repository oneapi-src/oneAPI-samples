{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ea6607-59bb-4df7-84fd-6f5be196127a",
   "metadata": {},
   "source": [
    "# Atomic Operation Optimization\n",
    "\n",
    "In this section we will look at how Atomic Operations can be optimized including synchronization using barriers\n",
    "\n",
    "- [Data Types for Atomic Operations](#Data-Types-for-Atomic-Operations)\n",
    "- [Atomic Operations in Global vs Local Space](#Atomic-Operations-in-Global-vs-Local-Space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb9c23-f6c7-487d-9b5a-c5fc2934bb86",
   "metadata": {},
   "source": [
    "## Data Types for Atomic Operations\n",
    "Atomics allow multiple work-items for any cross work-item communication via memory. SYCL atomics are similar to C++ atomics and make the access to resources protected by atomics guaranteed to be executed as a single unit. \n",
    "\n",
    "#### Atomic Operation: Integer vs Float\n",
    "\n",
    "The following SYCL code shows the implementation of a reduction operation in SYCL where every work-item is updating a global accumulator atomically. The input data type of this addition and the vector on which this reduction operation is being applied is an integer and float. \n",
    "\n",
    "The performance of the kernel with vector integer is reasonable compared to other techniques used for reduction. If the data type of the vector is a float or a double as shown in the second kernel below, the performance on certain accelerators is impaired due to lack of hardware support for float or double atomics. The following two kernels demonstrate how the time to execute an atomic add can vary drastically based on whether native atomics are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbccf3-9cab-47cc-9f35-f364bd811474",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/atomics_data_type.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr size_t N = 1024 * 100;\n",
    "\n",
    "int reductionInt(sycl::queue &q, std::vector<int> &data) {\n",
    "  const size_t data_size = data.size();\n",
    "  int sum = 0;\n",
    "\n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer<int> buf(data.data(), data_size, props);\n",
    "  sycl::buffer<int> sum_buf(&sum, 1, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "    q.submit([&](auto &h) {\n",
    "      sycl::accessor buf_acc(buf, h, sycl::read_only);\n",
    "      sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "      h.parallel_for(data_size, [=](auto index) {\n",
    "        size_t glob_id = index[0];\n",
    "        auto v = sycl::atomic_ref<\n",
    "            int, sycl::memory_order::relaxed,\n",
    "            sycl::memory_scope::device,\n",
    "            sycl::access::address_space::global_space>(sum_acc[0]);\n",
    "        v.fetch_add(buf_acc[glob_id]);\n",
    "      });\n",
    "    });\n",
    "    q.wait();\n",
    "    sycl::host_accessor h_acc(sum_buf);\n",
    "    sum = h_acc[0];\n",
    "  std::cout << \"ReductionInt Sum   = \" << sum << \", Duration \" << (std::chrono::high_resolution_clock::now().time_since_epoch().count() - start) * 1e-9 << \" seconds\\n\";\n",
    "\n",
    "  return sum;\n",
    "}\n",
    "\n",
    "int reductionFloat(sycl::queue &q, std::vector<float> &data) {\n",
    "  const size_t data_size = data.size();\n",
    "  float sum = 0.0;\n",
    "\n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer<float> buf(data.data(), data_size, props);\n",
    "  sycl::buffer<float> sum_buf(&sum, 1, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "    q.submit([&](auto &h) {\n",
    "      sycl::accessor buf_acc(buf, h, sycl::read_only);\n",
    "      sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "      h.parallel_for(data_size, [=](auto index) {\n",
    "        size_t glob_id = index[0];\n",
    "        auto v = sycl::atomic_ref<\n",
    "            float, sycl::memory_order::relaxed,\n",
    "            sycl::memory_scope::device,\n",
    "            sycl::access::address_space::global_space>(sum_acc[0]);\n",
    "        v.fetch_add(buf_acc[glob_id]);\n",
    "      });\n",
    "    });\n",
    "    q.wait();\n",
    "    sycl::host_accessor h_acc(sum_buf);\n",
    "    sum = h_acc[0];\n",
    "  \n",
    "  std::cout << \"ReductionFloat Sum = \" << sum << \", Duration \" << (std::chrono::high_resolution_clock::now().time_since_epoch().count() - start) * 1e-9 << \" seconds\\n\";\n",
    "  return sum;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  {\n",
    "    std::vector<int> data(N, 1);\n",
    "    for(int i=0;i<N;i++) data[i] = 1;\n",
    "    reductionInt(q, data);\n",
    "  }\n",
    "\n",
    "  {\n",
    "    std::vector<float> data(N, 1.0f);\n",
    "    for(int i=0;i<N;i++) data[i] = 1;\n",
    "    reductionFloat(q, data);\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681814e-2f1e-4b58-81eb-924e6272406a",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d879dd-bbd8-4240-8da1-93808a3a1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_atomics_data_type.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc087b9-e143-44bd-92fb-103a6bd9e1af",
   "metadata": {},
   "source": [
    "When using atomics, care must be taken to ensure that there is support in the hardware and that they can be executed efficiently. In Gen9 and Intel® Iris® Xe integrated graphics, there is no support for atomics on float or double data types and the performance of VectorDouble will be very poor. In future GPUs where the float and double atomics are supported in hardware, the performance of the above kernel will be much better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e23e86-37bc-42bf-9749-4134f3262912",
   "metadata": {},
   "source": [
    "### Intel VTune Analysis\n",
    "By analyzing these kernels using VTune Profiler, we can measure the impact of native atomic support. You can see that the VectorInt kernel is much faster than VectorDouble and VectorFloat.\n",
    "\n",
    "<img src=\"assets/atomics_vtune.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e0e08-1183-4887-95f3-83e3b1f21471",
   "metadata": {},
   "source": [
    "### Intel Advisor Report\n",
    "The Intel Advisor tool has a recommendation pane that provides insights on how to improve the performance of GPU kernels.\n",
    "\n",
    "One of the recommendations that Intel Advisor provides is “Inefficient atomics present”. When atomics are not natively supported in hardware, they are emulated. This can be detected and Intel Advisor gives advice on possible solutions.\n",
    "\n",
    "<img src=\"assets/atomics_advisor.png\">\n",
    "\n",
    "The standard C++ memory model assumes that applications execute on a single device with a single address space. Neither of these assumptions holds for DPC++ applications: different parts of the application execute on different devices (i.e., a host device and one or more accelerator devices); each device has multiple address spaces (i.e., private, local, and global); and the global address space of each device may or may not be disjoint (depending on USM support).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18054d-5c73-4bec-9200-50d5735abdb7",
   "metadata": {},
   "source": [
    "## Atomic Operations in Global vs Local Space\n",
    "When using atomics in the global address space, again, care must be taken because global updates are much slower than local.\n",
    "\n",
    "#### Atomic Operation: Global Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bab2f5-eeb4-49df-aa50-473ad80df159",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/atomics_global.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int N = 1024 * 1000 * 1000;\n",
    "  constexpr int M = 256;\n",
    "  int sum = 0;\n",
    "  int *data = static_cast<int *>(malloc(sizeof(int) * N));\n",
    "  for (int i = 0; i < N; i++) data[i] = 1;\n",
    "\n",
    "  sycl::queue q({sycl::property::queue::enable_profiling()});\n",
    "  sycl::buffer<int> buf_sum(&sum, 1);\n",
    "  sycl::buffer<int> buf_data(data, N);\n",
    "\n",
    "  auto e = q.submit([&](sycl::handler &h) {\n",
    "    sycl::accessor acc_sum(buf_sum, h);\n",
    "    sycl::accessor acc_data(buf_data, h, sycl::read_only);\n",
    "    h.parallel_for(sycl::nd_range<1>(N, M), [=](auto it) {\n",
    "      auto i = it.get_global_id();\n",
    "      sycl::atomic_ref<int, sycl::memory_order_relaxed,\n",
    "        sycl::memory_scope_device, sycl::access::address_space::global_space>\n",
    "        atomic_op(acc_sum[0]);\n",
    "      atomic_op += acc_data[i];\n",
    "    });\n",
    "  });\n",
    "  sycl::host_accessor h_a(buf_sum);\n",
    "\n",
    "  std::cout << \"Reduction Sum : \" << sum << \"\\n\";\n",
    "  auto total_time = (e.get_profiling_info<sycl::info::event_profiling::command_end>() - e.get_profiling_info<sycl::info::event_profiling::command_start>()) * 1e-9;\n",
    "  std::cout << \"Kernel Execution Time of Global Atomics : \" << total_time << \"seconds\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96328b-b63f-44a5-a70a-5472f0f82f80",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451074a-767f-43f4-8469-742e9260a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_atomics_global.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a5bcf2-44dd-4bc5-a27c-a0512fa0d48a",
   "metadata": {},
   "source": [
    "#### Atomic Operation: Local Space\n",
    "\n",
    "It is possible to refactor your code to use local memory space as the following example demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394778c-1cd5-43e3-894f-dd94385ea573",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/atomics_local.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int N = 1024 * 1000 * 1000;\n",
    "  constexpr int M = 256;\n",
    "  int sum = 0;\n",
    "  int *data = static_cast<int *>(malloc(sizeof(int) * N));\n",
    "  for (int i = 0; i < N; i++) data[i] = 1;\n",
    "\n",
    "  sycl::queue q({sycl::property::queue::enable_profiling()});\n",
    "  sycl::buffer<int> buf_sum(&sum, 1);\n",
    "  sycl::buffer<int> buf_data(data, N);\n",
    "\n",
    "  auto e = q.submit([&](sycl::handler &h) {\n",
    "    sycl::accessor acc_sum(buf_sum, h);\n",
    "    sycl::accessor acc_data(buf_data, h, sycl::read_only);\n",
    "    sycl::local_accessor<int, 1> local(1, h);\n",
    "    h.parallel_for(sycl::nd_range<1>(N, M), [=](auto it) {\n",
    "      auto i = it.get_global_id(0);\n",
    "      sycl::atomic_ref<int, sycl::memory_order_relaxed,\n",
    "        sycl::memory_scope_device, sycl::access::address_space::local_space>\n",
    "        atomic_op(local[0]);\n",
    "      atomic_op = 0;\n",
    "      sycl::group_barrier(it.get_group());\n",
    "      sycl::atomic_ref<int, sycl::memory_order_relaxed,\n",
    "        sycl::memory_scope_device,sycl::access::address_space::global_space>\n",
    "        atomic_op_global(acc_sum[0]);\n",
    "      atomic_op += acc_data[i];\n",
    "      sycl::group_barrier(it.get_group());\n",
    "      if (it.get_local_id() == 0)\n",
    "        atomic_op_global += local[0];\n",
    "    });\n",
    "  });\n",
    "  sycl::host_accessor ha(buf_sum);\n",
    "\n",
    "  std::cout << \"Reduction Sum : \" << sum << \"\\n\";\n",
    "  auto total_time = (e.get_profiling_info<sycl::info::event_profiling::command_end>() - e.get_profiling_info<sycl::info::event_profiling::command_start>()) * 1e-9;;\n",
    "  std::cout << \"Kernel Execution Time of Local Atomics  : \" << total_time << \" seconds\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8731c-8ea9-4ee1-a873-f8f7b2379d1c",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf1bb0-3654-4f90-b4c3-0e8f562c70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_atomics_local.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6bcda-25a2-498b-a629-ed4fdb1133f0",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Intel GPU Optimization Guide](https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html) - Up to date resources for Intel GPU Optimization\n",
    "- [SYCL Specification](https://registry.khronos.org/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf) - Latest Specification document for reference\n",
    "- [SYCL Essentials Training](https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL/Jupyter/oneapi-essentials-training) - Learn basics of C++ SYCL Programming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
