{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a374a3-84ac-45af-87b6-e048ebd90269",
   "metadata": {},
   "source": [
    "# Memory Optimization - Buffers\n",
    "\n",
    "In this section we cover topics related to declaration, movement, and access to the memory hierarchy.\n",
    "- [Buffer Accessor Modes](#Buffer-Accessor-Modes)\n",
    "- [Optimizing Memory Movement Between Host and Device](#Optimizing-Memory-Movement-Between-Host-and-Device)\n",
    "- [Avoid Declaring Buffers in a Loop](#Avoid-Declaring-Buffers-in-a-Loop)\n",
    "- [Avoid Moving Data Back and Forth Between Host and Device](#Avoid-Moving-Data-Back-and-Forth-Between-Host-and-Device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fbe439-2583-488c-9fc9-79b2e10c3547",
   "metadata": {},
   "source": [
    "## Buffer Accessor Modes\n",
    "In SYCL, a buffer provides an abstract view of memory that can be accessed by the host or a device. A buffer cannot be accessed directly through the buffer object. Instead, we must create an accessor object that allows us to access the buffer’s data.\n",
    "\n",
    "The access mode describes how we intend to use the memory associated with the accessor in the program. The accessor’s access modes are used by the runtime to create an execution order for the kernels and perform data movement. This will ensure that kernels are executed in an order intended by the programmer. Depending on the capabilities of the underlying hardware, the runtime can execute kernels concurrently if the dependencies do not give rise to dependency violations or race conditions.\n",
    "\n",
    "For better performance, make sure that the access modes of accessors reflect the operations performed by the kernel. The compiler will flag an error when a write is done on an accessor which is declared as read_only. But the compiler does not change the declaration of an accessor form `read_write` to read if no write is done in the kernel.\n",
    "\n",
    "The following example shows a simple vector-add computation. A, B, and C buffers have access mode default which is `read_write`.\n",
    "\n",
    "The `read_write` access mode informs the runtime that the data needs to be available on the device before the kernel can begin executing and the data needs to be copied from the device to the host at the end of the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d15d7f-6849-4375-a6ae-7f22e32e4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_access_modes.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr int N = 1024000000;\n",
    "\n",
    "int main() {\n",
    "\n",
    "  std::vector<int> a(N, 1);\n",
    "  std::vector<int> b(N, 2);\n",
    "  std::vector<int> c(N);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "    \n",
    "  sycl::queue q;\n",
    "  {\n",
    "    sycl::buffer<int> a_buf(a);\n",
    "    sycl::buffer<int> b_buf(b);\n",
    "    sycl::buffer<int> c_buf(c);\n",
    "\n",
    "    q.submit([&](auto &h) {\n",
    "      // Create device accessors.\n",
    "      sycl::accessor a_acc(a_buf, h);\n",
    "      sycl::accessor b_acc(b_buf, h);\n",
    "      sycl::accessor c_acc(c_buf, h);\n",
    "\n",
    "      h.parallel_for(N, [=](auto i) {\n",
    "        c_acc[i] = a_acc[i] + b_acc[i];\n",
    "      });\n",
    "    });\n",
    "  }\n",
    "  std::cout << \"C = \" << c[N/2] << \"\\n\";\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a07668-4d2e-4d9b-a7fb-3a224ec4aa64",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ad32d-755d-497b-b9c6-d012e10f62ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_access_modes.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31826c80-f01c-4c98-90a5-4c7ff7711584",
   "metadata": {},
   "source": [
    "A better implementation is to make A and B `read_only` since A and B are not modified, it need not be copied back to host. Similarly make C `write_only` since the value is over-written it need not be copied from host to device to begin with.\n",
    "\n",
    "```cpp\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      sycl::accessor c_acc(c_buf, h, sycl::write_only);\n",
    "```\n",
    "\n",
    "The `read_only` access mode informs the runtime that the data needs to be available on the device before the kernel can begin executing, but the data need not be copied from the device to the host at the end of the computation.\n",
    "\n",
    "The `write_only` access mode informs the runtime that the data need not be available on the device before the kernel can begin executing, but the data needs to be copied from the device to the host at the end of the computation.\n",
    "\n",
    "Making the change to accessors in the above code should give better performance numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d9e6d-82a2-44cc-b5fe-aa343ea7c521",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizing Memory Movement Between Host and Device\n",
    "Buffers can be created using properties to control how they are allocated. One such property is `use_host_ptr`. This informs the runtime that if possible, the host memory should be directly used by the buffer instead of a copy. This avoids the need to copy the content of the buffer back and forth between the host memory and the buffer memory, potentially saving time during buffer creation and destruction. To take another case, when the GPU and CPU have shared memory, it is possible to avoid copies of memory through sharing of pages. But for page sharing to be possible, the allocated memory needs to have some properties like being aligned on page boundary. In case of discrete devices, the benefit may not be realized because any memory operation by the accelerator will have to go across PCIe or some other slower interface than the memory of the accelerator.\n",
    "\n",
    "The following code shows how to print the memory addresses on the host, inside the buffer, and on the accelerator device inside the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd4777-0fe1-4e40-8092-3b1ecbb85eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_host_ptr.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int num_items = 16;\n",
    "  constexpr int iter = 1;\n",
    "\n",
    "  std::vector<int> a(num_items, 10);\n",
    "  std::vector<int> b(num_items, 10);\n",
    "  std::vector<int> sum(num_items, 0);\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  \n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer a_buf(a, props);\n",
    "  sycl::buffer b_buf(b, props);\n",
    "  sycl::buffer sum_buf(sum, props);\n",
    "  {\n",
    "    sycl::host_accessor a_host_acc(a_buf);\n",
    "    std::cout << \"address of vector a     = \" << a.data() << \"\\n\";\n",
    "    std::cout << \"buffer memory address   = \" << a_host_acc.get_pointer() << \"\\n\";\n",
    "  }\n",
    "  q.submit([&](auto &h) {\n",
    "    // Input accessors\n",
    "    sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "    sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "    // Output accessor\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "    sycl::stream out(1024 * 1024, 1 * 128, h);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) {\n",
    "      if (i[0] == 0)\n",
    "        out << \"device accessor address = \" << a_acc.get_pointer() << \"\\n\";\n",
    "      sum_acc[i] = a_acc[i] + b_acc[i];\n",
    "    });\n",
    "  }).wait();\n",
    "  return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c31b2-37fd-447a-aea8-54368ab0dbe4",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23b8e9-8235-4d65-9e76-c637a901e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_host_ptr.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca556b-ba41-4d9f-a7a6-96a06950a549",
   "metadata": {},
   "source": [
    "When this program is run, it can be seen that the addresses for host and the buffer are the same when the property `use_host_ptr` is set.\n",
    "\n",
    "Also note that none of the input vectors are declared to be const. If these are declared const then during buffer creation they are copied and new memory is allocated instead of reusing the memory in the host vectors. You can this in the above code by changing the vector a to `const`:\n",
    "```cpp\n",
    "    const std::vector<int> a(num_items, 10);\n",
    "    ^^^^^\n",
    "```\n",
    "The kernel will incur the cost of copying memory contents between the host and buffer, and also from the buffer to the accelerator.\n",
    "\n",
    "Care must be taken to ensure that unnecessary copies are avoided during the creation of buffers and passing the memory from the buffers to the kernels. Even when the accelerator shares memory with the host, a few additional conditions must be satisfied to avoid these extra copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e84bf-7351-4d05-8264-daad91775bac",
   "metadata": {},
   "source": [
    "## Avoid Declaring Buffers in a Loop\n",
    "When kernels are repeatedly launched inside a for-loop, you can prevent repeated allocation and freeing of a buffer by declaring the buffer outside the loop. Declaring a buffer inside the loop introduces repeated host-to-device and device-to-host memory copies.\n",
    "\n",
    "In the following example, the kernel is repeatedly launched inside a for-loop. The buffer C is used as a temporary array, where it is used to hold values in an iteration, and the values assigned in one iteration are not used in any other iteration. Since the buffer C is declared inside the for-loop, it is allocated and freed in every loop iteration. In addition to the allocation and freeing of the buffer, the memory associated with the buffer is redundantly transferred from host to device and device to host in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74ffdea-8e85-446c-bfac-ae4c3e5ec861",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_loop.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "#include <chrono>\n",
    "\n",
    "constexpr int N = 16;\n",
    "constexpr int STEPS = 10000;\n",
    "\n",
    "int main() {\n",
    "\n",
    "  std::vector<int> a(N, 1);\n",
    "  std::vector<int> b(N, 2);\n",
    "  std::vector<int> c(N);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "    \n",
    "  sycl::queue q;\n",
    "\n",
    "  sycl::buffer<int> a_buf(a);\n",
    "  sycl::buffer<int> b_buf(b);\n",
    "\n",
    "  for (int j = 0; j < STEPS; j++) {\n",
    "    //# Buffer c in the loop\n",
    "    sycl::buffer<int> c_buf(c, sycl::no_init);\n",
    "\n",
    "    q.submit([&](auto &h) {\n",
    "      // Create device accessors.\n",
    "      sycl::accessor a_acc(a_buf, h);\n",
    "      sycl::accessor b_acc(b_buf, h);\n",
    "      sycl::accessor c_acc(c_buf, h);\n",
    "      h.parallel_for(N, [=](auto i) {\n",
    "        c_acc[i] = (a_acc[i] < b_acc[i]) ? -1 : 1;\n",
    "        a_acc[i] += c_acc[i];\n",
    "        b_acc[i] -= c_acc[i];\n",
    "      });\n",
    "    });\n",
    "  }\n",
    "\n",
    "  // Create host accessors.\n",
    "  const sycl::host_accessor ha(a_buf);\n",
    "  const sycl::host_accessor hb(b_buf);\n",
    "  printf(\"%d %d\\n\", ha[N / 2], hb[N / 2]);\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f9ce9-be8a-4180-8e8b-6f3129b99416",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ad5b5-e7de-4ce9-a662-a07fe8533803",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_loop.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1722924-bc60-4a8f-b84a-a4916429732a",
   "metadata": {},
   "source": [
    "A better approach would be to declare the buffer C before the for-loop, so that it is allocated and freed only once, resulting in improved performance by avoiding the redundant data transfers between host and device. \n",
    "\n",
    "In the above code, try moving the buffer C before the for-loop and check the compute duration.\n",
    "```cpp\n",
    "sycl::buffer<int> c_buf(c, sycl::no_init);\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5241a3-0f28-49f5-a46d-c341a98d4309",
   "metadata": {},
   "source": [
    "## Avoid Moving Data Back and Forth Between Host and Device\n",
    "The cost of moving data between host and device is quite high, especially in the case of discrete accelerators. So it is very important to avoid data transfers between host and device as much as possible. In some situations it may be required to bring the data that was computed by a kernel on the accelerator to the host and do some operation on it and send it back to the device for further processing. In such situation we will end up paying for the cost of device to host transfer and then again host to device transfer.\n",
    "\n",
    "Consider the following example, where one kernel produces data through some operation (in this case vector add) into a new vector. This vector is then transformed into another vector by applying a function on each value and then fed as input into another kernel for some additional computation. This form of computation is quite common and occurs in many domains where algorithms are iterative and output from one computation needs to be fed as input into another computation. One classic example is machine learning models which are structured as layers of computation and output of one layer is input to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff31ec-a23a-4e5b-b4ef-a53689cfcf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_mem_move_0.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int num_items = 1024*1000*1000;\n",
    "  std::vector<int> a(num_items);\n",
    "  for(int i=0;i<num_items;i++) a[i] = i;\n",
    "  std::vector<int> b(num_items, 1);\n",
    "  std::vector<int> c(num_items, 2);\n",
    "  std::vector<int> d(num_items, 3);\n",
    "  std::vector<int> sum(num_items, 0);\n",
    "  std::vector<int> res(num_items, 0);\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  \n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer a_buf(a, props);\n",
    "  sycl::buffer b_buf(b, props);\n",
    "  sycl::buffer c_buf(c, props);\n",
    "  sycl::buffer d_buf(d, props);\n",
    "  sycl::buffer sum_buf(sum, props);\n",
    "  sycl::buffer res_buf(res, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  //# Kernel 1\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "    sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) { sum_acc[i] = a_acc[i] + b_acc[i]; });\n",
    "  });\n",
    "\n",
    "  {\n",
    "    sycl::host_accessor h_acc(sum_buf);\n",
    "    for (int j = 0; j < num_items; j++)\n",
    "      if (h_acc[j] > 10)\n",
    "        h_acc[j] = 1;\n",
    "      else\n",
    "        h_acc[j] = 0;\n",
    "  }\n",
    "\n",
    "  //# Kernel 2\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor c_acc(c_buf, h, sycl::read_only);\n",
    "    sycl::accessor d_acc(d_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::read_only);\n",
    "    sycl::accessor res_acc(res_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) { res_acc[i] = sum_acc[i] * c_acc[i] + d_acc[i]; });\n",
    "  }).wait();\n",
    "\n",
    "  sycl::host_accessor h_acc(res_buf); \n",
    "  for (int i = 0; i < 20; i++) std::cout << h_acc[i] << \" \";std::cout << \"...\\n\";\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d74471-3393-4445-9a61-d10739d41b97",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4418eca-eeb8-4e98-a211-7011d6e15b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_mem_move_0.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d96fc-7ab1-475e-9337-8119f9b32c78",
   "metadata": {},
   "source": [
    "Instead of bringing the data to the host and applying the function to the data and sending it back to the device in the second kernel, you can create a kernel to execute this function on the device itself. This has the advantage of avoiding the round trip of data from device to host. This technique is shown in the example below, which is functionally the same as the code before. We now introduce a third kernel kernel3 that operates on the intermediate data in accum_buf in between kernel1 and kernel2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5da114-1340-4991-a1a9-6daff6b6f1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_mem_move_1.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int num_items = 1024*1000*1000;\n",
    "  std::vector<int> a(num_items);\n",
    "  for(int i=0;i<num_items;i++) a[i] = i;\n",
    "  std::vector<int> b(num_items, 1);\n",
    "  std::vector<int> c(num_items, 2);\n",
    "  std::vector<int> d(num_items, 3);\n",
    "  std::vector<int> sum(num_items, 0);\n",
    "  std::vector<int> res(num_items, 0);\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  \n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer a_buf(a, props);\n",
    "  sycl::buffer b_buf(b, props);\n",
    "  sycl::buffer c_buf(c, props);\n",
    "  sycl::buffer d_buf(d, props);\n",
    "  sycl::buffer sum_buf(sum, props);\n",
    "  sycl::buffer res_buf(res, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  //# Kernel 1\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "    sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) { sum_acc[i] = a_acc[i] + b_acc[i]; });\n",
    "  });\n",
    "\n",
    "  //# Kernel 3\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::read_write);\n",
    "    h.parallel_for(num_items, [=](auto i) { \n",
    "      if (sum_acc[i] > 10)\n",
    "        sum_acc[i] = 1;\n",
    "      else\n",
    "        sum_acc[i] = 0;\n",
    "    });\n",
    "  });\n",
    "\n",
    "  //# Kernel 2\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor c_acc(c_buf, h, sycl::read_only);\n",
    "    sycl::accessor d_acc(d_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::read_only);\n",
    "    sycl::accessor res_acc(res_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) { res_acc[i] = sum_acc[i] * c_acc[i] + d_acc[i]; });\n",
    "  }).wait();\n",
    "\n",
    "  sycl::host_accessor h_acc(res_buf); \n",
    "  for (int i = 0; i < 20; i++) std::cout << h_acc[i] << \" \";std::cout << \"...\\n\";\n",
    "\n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb71659-932a-4824-a509-02a815e2a191",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fb583-091c-444f-b317-1a3f20485434",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_mem_move_1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32277d2-0287-4eb9-a5a8-fff283d40f25",
   "metadata": {},
   "source": [
    "There are other ways to optimize this example. For instance, the clipping operation in kernel3 can be merged into the computation of kernel1 as shown below. This is kernel fusion and has the added advantage of not launching a third kernel. The DPCPP compiler cannot do this kind of optimization. In some specific domains like machine learning, there are graph compilers that operate on the ML models and fuse the operations, which has the same impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d9794-a667-4a7d-b7ba-d53da7c0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_mem_move_2.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int num_items = 1024*1000*1000;\n",
    "  std::vector<int> a(num_items);\n",
    "  for(int i=0;i<num_items;i++) a[i] = i;\n",
    "  std::vector<int> b(num_items, 1);\n",
    "  std::vector<int> c(num_items, 2);\n",
    "  std::vector<int> d(num_items, 3);\n",
    "  std::vector<int> sum(num_items, 0);\n",
    "  std::vector<int> res(num_items, 0);\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  \n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer a_buf(a, props);\n",
    "  sycl::buffer b_buf(b, props);\n",
    "  sycl::buffer c_buf(c, props);\n",
    "  sycl::buffer d_buf(d, props);\n",
    "  sycl::buffer sum_buf(sum, props);\n",
    "  sycl::buffer res_buf(res, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  //# Kernel 1\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "    sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) {\n",
    "      int t = a_acc[i] + b_acc[i];\n",
    "      if (t > 10)\n",
    "        sum_acc[i] = 1;\n",
    "      else\n",
    "        sum_acc[i] = 0;\n",
    "    });\n",
    "  });\n",
    "\n",
    "  //# Kernel 2\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor c_acc(c_buf, h, sycl::read_only);\n",
    "    sycl::accessor d_acc(d_buf, h, sycl::read_only);\n",
    "    sycl::accessor sum_acc(sum_buf, h, sycl::read_only);\n",
    "    sycl::accessor res_acc(res_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) { res_acc[i] = sum_acc[i] * c_acc[i] + d_acc[i]; });\n",
    "  }).wait();\n",
    "\n",
    "  sycl::host_accessor h_acc(res_buf); \n",
    "  for (int i = 0; i < 20; i++) std::cout << h_acc[i] << \" \";std::cout << \"...\\n\";\n",
    "\n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "  return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e047e6c-0173-4b35-8ee8-4acd0b2898b3",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88f613-69a4-42c4-97d6-e12d7cdc685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_mem_move_2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e510f0-080b-4d6f-aaac-3128c399be39",
   "metadata": {},
   "source": [
    "We can take this kernel fusion one level further and fuse both kernel1 and kernel2 as shown in the code below. This gives very good performance since it avoids the intermediate accum_buf completely, saving memory in addition to launching an additional kernel. Most of the performance benefit in this case is due to improvement in locality of memory references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56d93f-22a7-4604-b963-00cace06c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/buffer_mem_move_3.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  constexpr int num_items = 1024*1000*1000;\n",
    "  std::vector<int> a(num_items);\n",
    "  for(int i=0;i<num_items;i++) a[i] = i;\n",
    "  std::vector<int> b(num_items, 1);\n",
    "  std::vector<int> c(num_items, 2);\n",
    "  std::vector<int> d(num_items, 3);\n",
    "  std::vector<int> res(num_items, 0);\n",
    "\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  \n",
    "  const sycl::property_list props = {sycl::property::buffer::use_host_ptr()};\n",
    "\n",
    "  sycl::buffer a_buf(a, props);\n",
    "  sycl::buffer b_buf(b, props);\n",
    "  sycl::buffer c_buf(c, props);\n",
    "  sycl::buffer d_buf(d, props);\n",
    "  sycl::buffer res_buf(res, props);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  //# Kernel 1\n",
    "  q.submit([&](auto &h) {\n",
    "    sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "    sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "    sycl::accessor c_acc(c_buf, h, sycl::read_only);\n",
    "    sycl::accessor d_acc(d_buf, h, sycl::read_only);\n",
    "    sycl::accessor res_acc(res_buf, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "    h.parallel_for(num_items, [=](auto i) {\n",
    "      int t = a_acc[i] + b_acc[i];\n",
    "      if (t > 10)\n",
    "        res_acc[i] = c_acc[i] + d_acc[i] ;\n",
    "      else\n",
    "        res_acc[i] = d_acc[i];\n",
    "    });\n",
    "  }).wait();\n",
    "\n",
    "  sycl::host_accessor h_acc(res_buf); \n",
    "  for (int i = 0; i < 20; i++) std::cout << h_acc[i] << \" \";std::cout << \"...\\n\";\n",
    "\n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd4280-e578-498a-8d93-766ea20325f2",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea73769-c323-424d-b7b7-cf2fa348f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_buffer_mem_move_3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f784dac-56ae-459b-a3c9-675407a6d140",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Resources\n",
    "\n",
    "- [Intel GPU Optimization Guide](https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html) - Up to date resources for Intel GPU Optimization\n",
    "- [SYCL Specification](https://registry.khronos.org/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf) - Latest Specification document for reference\n",
    "- [SYCL Essentials Training](https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL/Jupyter/oneapi-essentials-training) - Learn basics of C++ SYCL Programming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
