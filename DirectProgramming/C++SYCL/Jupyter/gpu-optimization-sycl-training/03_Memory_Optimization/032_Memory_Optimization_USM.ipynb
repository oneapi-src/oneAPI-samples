{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a374a3-84ac-45af-87b6-e048ebd90269",
   "metadata": {},
   "source": [
    "# Memory Optimization - USM\n",
    "\n",
    "In this section we cover topics related to declaration, movement, and access to the memory hierarchy.\n",
    "- [Overlapping Data Transfer from Host to Device](#Overlapping-Data-Transfer-from-Host-to-Device)\n",
    "- [Avoid Copying Unnecessary Blocks of Data](#Avoid-Copying-Unnecessary-Blocks-of-Data)\n",
    "- [Copying Memory from Host to USM Device Allocation](#Copying-Memory-from-Host-to-USM-Device-Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8749a6-3ef3-4e8f-8b95-0eaaef3c37d6",
   "metadata": {},
   "source": [
    "## Overlapping Data Transfer from Host to Device\n",
    "Some GPUs provide specialized engines for copying data from host to device. Effective utilization of them will ensure that the host-to-device data transfer can be overlapped with execution on the device. In the following example, a block of memory is divided into chunks and each chunk is transferred to the accelerator, processed , and the result is brought back to the host. These chunks of three tasks are independent, so they can be processed in parallel depending on availability of hardware resources. \n",
    "\n",
    "In systems where there are copy engines that can be used to transfer data between host and device, we can see that the operations from different loop iterations can execute in parallel. The parallel execution can manifest in two ways:\n",
    "- Between two memory copies, where one is executed by the GPU EUs and one by a copy engine, or both are executed by copy engines.\n",
    "- Between a memory copy and a compute kernel, where the memory copy is executed by the copy engine and the compute kernel by the GPU EUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54db442-ea11-47d6-a9c4-23c577bd83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/usm_overlap_copy.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "#define NITERS 10\n",
    "#define KERNEL_ITERS 10000\n",
    "#define NUM_CHUNKS 10\n",
    "#define CHUNK_SIZE 10000000\n",
    "\n",
    "int main() {\n",
    "  const int num_chunks = NUM_CHUNKS;\n",
    "  const int chunk_size = CHUNK_SIZE;\n",
    "  const int iter = NITERS;\n",
    "\n",
    "  sycl::queue q;\n",
    "\n",
    "  //# Allocate and initialize host data\n",
    "  float *host_data[num_chunks];\n",
    "  for (int c = 0; c < num_chunks; c++) {\n",
    "    host_data[c] = sycl::malloc_host<float>(chunk_size, q);\n",
    "    float val = c;\n",
    "    for (int i = 0; i < chunk_size; i++)\n",
    "      host_data[c][i] = val;\n",
    "  }\n",
    "  std::cout << \"Allocated host data\\n\";\n",
    "\n",
    "  //# Allocate and initialize device memory\n",
    "  float *device_data[num_chunks];\n",
    "  for (int c = 0; c < num_chunks; c++) {\n",
    "    device_data[c] = sycl::malloc_device<float>(chunk_size, q);\n",
    "    float val = 1000.0;\n",
    "    q.fill<float>(device_data[c], val, chunk_size);\n",
    "  }\n",
    "  q.wait();\n",
    "  std::cout << \"Allocated device data\\n\";\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  for (int it = 0; it < iter; it++) {\n",
    "    for (int c = 0; c < num_chunks; c++) {\n",
    "\n",
    "      //# Copy-in not dependent on previous event\n",
    "      auto copy_in_event = q.memcpy(device_data[c], host_data[c], sizeof(float) * chunk_size);\n",
    "\n",
    "      //# Compute waits for copy_in_event\n",
    "      auto compute_event = q.parallel_for(chunk_size, copy_in_event, [=](auto id) {\n",
    "        for (int i = 0; i < KERNEL_ITERS; i++) device_data[c][id] += 1.0;\n",
    "      });\n",
    "\n",
    "      //# Copy out waits for compute_event\n",
    "      auto copy_out_event = q.memcpy(host_data[c], device_data[c], sizeof(float) * chunk_size, compute_event);\n",
    "    }\n",
    "\n",
    "    q.wait();\n",
    "  }\n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "\n",
    "  for (int c = 0; c < num_chunks; c++) {\n",
    "    for (int i = 0; i < chunk_size; i++) {\n",
    "      if (host_data[c][i] != (float)((c + KERNEL_ITERS * iter))) {\n",
    "        std::cout << \"Mismatch for chunk: \" << c << \" position: \" << i\n",
    "                  << \" expected: \" << c + 10000 << \" got: \" << host_data[c][i]\n",
    "                  << \"\\n\";\n",
    "        break;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070dedae-a22b-44eb-896f-1abf1d384ace",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828f5aa-fd39-4a28-a191-4ecfdb83dd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ./q.sh run_usm_overlap_copy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb08b02-707f-44fe-92ff-ae1ecf5c6d95",
   "metadata": {},
   "source": [
    "In the timeline picture below, which is collected using ze_tracer, we can see that copy-ins from upcoming iterations overlap with the execution of compute kernel. Also, we see multiple copy-ins executing in parallel on multiple copy engines.\n",
    "\n",
    "ze_tracer plot showing copy-in overlap with execution of compute kernel\n",
    "<img src=\"assets/zetracer_overlap.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a14e1-53bb-4802-96d9-daa927f808ca",
   "metadata": {},
   "source": [
    "## Avoid Copying Unnecessary Blocks of Data\n",
    "\n",
    "The example below is allocating memory on device to perform simple addition of all elements in an array, the resulting data is stored in the first element of the array. You can limit the amount of data being copied back by copying back only the first element in the array when doing `memcpy` to copy memory from device to host.\n",
    "\n",
    "```cpp\n",
    "q.memcpy(data, device_data, sizeof(int) * N).wait();\n",
    "\n",
    "vs\n",
    "\n",
    "q.memcpy(data, device_data, sizeof(int) * 1).wait();\n",
    "                                          ^\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe8b40-5ffe-45b4-940b-c617a50ca91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/usm_copy_partial.cpp\n",
    "//==============================================================\n",
    "// Copyright © 2020 Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "static constexpr size_t N = 102400000; // global size\n",
    "\n",
    "int main() {\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "    \n",
    "  //# setup queue with default selector\n",
    "  sycl::queue q;\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# initialize data array using usm\n",
    "  int *data = static_cast<int *>(malloc(N * sizeof(int)));\n",
    "  for (int i = 0; i < N; i++) data[i] = 1;\n",
    "\n",
    "  //# USM device allocation\n",
    "  auto device_data = sycl::malloc_device<int>(N, q);\n",
    "\n",
    "  //# copy mem from host to device\n",
    "  q.memcpy(device_data, data, sizeof(int) * N).wait();\n",
    "\n",
    "  //# single_task kernel performing simple addition of all elements\n",
    "  q.single_task([=](){\n",
    "    int sum = 0;\n",
    "    for(int i=0;i<N;i++){\n",
    "        sum += device_data[i];\n",
    "    }\n",
    "    device_data[0] = sum;\n",
    "  }).wait();\n",
    "\n",
    "  //# copy mem from device to host\n",
    "  q.memcpy(data, device_data, sizeof(int) * N).wait();\n",
    "\n",
    "  std::cout << \"Sum = \" << data[0] << \"\\n\";\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  sycl::free(device_data, q);\n",
    "  free(data);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4cdde-72d7-4d56-9135-8b24d4aa66f9",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5a9cd-c258-4cd2-96f7-d7429a22306e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ./q.sh run_usm_copy_partial.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a2d7b-aa77-48f2-a5f8-64f75c62e4f1",
   "metadata": {},
   "source": [
    "## Copying Memory from Host to USM Device Allocation\n",
    "\n",
    "When copying memory from host to USM device allocation, it is faster if the host memory is allocated using USM `malloc_host` rather than regular `malloc`.\n",
    "\n",
    "The example below shows 2 host allocations using `malloc` and USM `malloc_host`, we also allocate memory on the device using USM `malloc_device`. We then copy both the host allocations using `q.memcpy()` and then capture the `memcpy` execution duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b535fa-152d-4ce9-a5dd-e7409623aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/usm_memcpy.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "int main() {\n",
    "  sycl::queue q{sycl::property::queue::enable_profiling{}};\n",
    "  std::cout << \"Device : \" << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "\n",
    "  constexpr int N = 1024000000;\n",
    "  //# host allocation using malloc\n",
    "  auto host_data = static_cast<int *>(malloc(N * sizeof(int)));\n",
    "  //# USM host allocation using malloc_host\n",
    "  auto host_data_usm = sycl::malloc_host<int>(N, q);\n",
    "\n",
    "  //# USM device allocation using malloc_device\n",
    "  auto device_data_usm = sycl::malloc_device<int>(N, q);\n",
    "\n",
    "  //# copy mem from host (malloc) to device\n",
    "  auto e1 = q.memcpy(device_data_usm, host_data, sizeof(int) * N);\n",
    "    \n",
    "  //# copy mem from host (malloc_host) to device\n",
    "  auto e2 = q.memcpy(device_data_usm, host_data_usm, sizeof(int) * N);\n",
    "\n",
    "  q.wait();\n",
    "\n",
    "  //# free allocations\n",
    "  sycl::free(device_data_usm, q);\n",
    "  sycl::free(host_data_usm, q);\n",
    "  free(host_data);\n",
    "\n",
    "  std::cout << \"memcpy Time (malloc-to-malloc_device)     : \" << (e1.template get_profiling_info<sycl::info::event_profiling::command_end>() - e1.template get_profiling_info<sycl::info::event_profiling::command_start>()) / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  std::cout << \"memcpy Time (malloc_host-to-malloc_device : \" << (e2.template get_profiling_info<sycl::info::event_profiling::command_end>() - e2.template get_profiling_info<sycl::info::event_profiling::command_start>()) / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fa8e6-496e-4382-83f0-adc8ced12045",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe6c41e-6a7d-4fd3-9300-e6edfd32e30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ./q.sh run_usm_memcpy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4154d87-a7bd-4542-b027-3bb5c9cae418",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Intel GPU Optimization Guide](https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html) - Up to date resources for Intel GPU Optimization\n",
    "- [SYCL Specification](https://registry.khronos.org/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf) - Latest Specification document for reference\n",
    "- [SYCL Essentials Training](https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL/Jupyter/oneapi-essentials-training) - Learn basics of C++ SYCL Programming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
