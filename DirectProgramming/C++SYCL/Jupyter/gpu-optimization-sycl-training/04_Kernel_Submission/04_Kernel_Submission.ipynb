{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a374a3-84ac-45af-87b6-e048ebd90269",
   "metadata": {},
   "source": [
    "# Kernel Submission\n",
    "\n",
    "In this section we cover performance impact and consideration when submitting a kernel in SYCL:\n",
    "- [Kernel Launch](#Kernel-Launch)\n",
    "- [Executing Multiple Kernels](#Executing-Multiple-Kernels)\n",
    "- [Submitting Kernels to Multiple Queues](#Submitting-Kernels-to-Multiple-Queues)\n",
    "- [Avoid Redundant Queue Construction](#Avoid-Redundant-Queue-Construction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94d3d97-1614-4bd3-88c8-14925cc46c68",
   "metadata": {},
   "source": [
    "## Kernel Launch\n",
    "In SYCL, work is performed by enqueueing kernels into queues targeting specific devices. These kernels are submitted by the host to the device, executed by the device and results are sent back. The kernel submission by the host and the actual start of execution do not happen immediately - they are asynchronous and as such we have to keep track of the following timings associated with a kernel.\n",
    "#### Kernel submission start time\n",
    "This is the at which the host starts the process of submitting the kernel.\n",
    "#### Kernel submission end time\n",
    "This is the time at which the host finished submitting the kernel. The host performs multiple tasks like queuing the arguments, allocating resources in the runtime for the kernel to start execution on the device.\n",
    "#### Kernel launch time\n",
    "This is the time at which the kernel that was submitted by the host starts executing on the device. Note that this is not exactly same as the kernel submission end time. There is a lag between the submission end time and the kernel launch time, which depends on the availability of the device. It is possible for the host to queue up a number of kernels for execution before the kernels are actually launched for execution. More over, there are a few data transfers that need to happen before the actual kernel starts execution which is typically not accounted separately from kernel launch time.\n",
    "#### Kernel completion time\n",
    "This is the time at which the kernel finishes execution on the device. The current generation of devices are non-preemptive, which means that once a kernel starts, it has to complete its execution.\n",
    "\n",
    "Tools like VTune™ Profiler (vtune), clIntercept, and zeIntercept provide a visual timeline for each of the above times for every kernel in the application.\n",
    "\n",
    "The following simple example shows time being measured for the kernel execution since the time is measured after `wait`. This will involve the kernel submission time on the host, the kernel execution time on the device, and any data transfer times (since there are no buffers or memory, this is usually zero in this case).\n",
    "\n",
    "The time before the `wait` measures the time it takes for the host to submit the kernel to the runtime. These overheads are highly dependent on the backend runtime being used and the processing power of the host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931b73f-7025-4bd5-99ca-191d8e696002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/kernel_launch.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr int N = 1024000000;\n",
    "\n",
    "int main() {\n",
    "  sycl::queue q;\n",
    "    \n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  q.parallel_for(N, [=](auto id) {\n",
    "    /* NOP */\n",
    "  });\n",
    "  \n",
    "  auto k_subm = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "    \n",
    "  q.wait();\n",
    "    \n",
    "  auto k_exec = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Kernel Submission Time: \" << k_subm / 1e+9 << \" seconds\\n\";\n",
    "  std::cout << \"Kernel Submission + Execution Time: \" << k_exec / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c58df-3798-4cc0-9a8a-8a9d2ea47e05",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e74bf-fad3-471f-b2a8-70101e817270",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_kernel_launch.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c0505-9455-458a-be4a-6f9ad7a72df3",
   "metadata": {},
   "source": [
    "#### SYCL Profiling API\n",
    "\n",
    "One way to measure the actual kernel execution time on the device is to use the SYCL built-in profiling API. \n",
    "```cpp\n",
    "sycl::queue q{sycl::property::queue::enable_profiling()};\n",
    "```\n",
    "The following code demonstrates usage of the SYCL profiling API to profile kernel execution times. It also shows the kernel submission time. There is no way to programmatically measure the kernel launch time since it is dependent on the runtime and the device driver. Profiling tools can provide this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c37ebb-15f7-4b8b-ad81-72a0550af75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/kernel_profiling.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr int N = 1024000000;\n",
    "\n",
    "int main() {\n",
    "  sycl::queue q{sycl::property::queue::enable_profiling()};\n",
    "    \n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  auto e = q.parallel_for(N, [=](auto id) {\n",
    "    /* NOP */\n",
    "  });\n",
    "  e.wait();\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Kernel Duration  : \" << duration / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  auto startK = e.get_profiling_info<sycl::info::event_profiling::command_start>();\n",
    "  auto endK = e.get_profiling_info<sycl::info::event_profiling::command_end>();\n",
    "  std::cout << \"Kernel Execturion: \" << (endK - startK) / 1e+9 << \" seconds\\n\";\n",
    "    \n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300e9bb-e1e1-438e-9952-4b898e7cb8da",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6be4c6-0805-48c5-99e4-e45583eb49f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_kernel_profiling.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1884fc1-a6d0-4fae-bae6-894d31a98231",
   "metadata": {},
   "source": [
    "## Executing Multiple Kernels\n",
    "SYCL has two kinds of queues that a programmer can create and use to submit kernels for execution.\n",
    "- __in-order queues__ : where kernels are executed in the order they were submitted to the queue\n",
    "- __out-of-order queues__ : where kernels can be executed in an arbitrary order (subject to the dependency constraints among them).\n",
    "\n",
    "The choice to create an in-order or out-of-order queue is made at queue construction time through the property `sycl::property::queue::in_order()`. By default, when no property is specified, the queue is out-of-order.\n",
    "\n",
    "In the following example, three kernels are submitted per iteration. Each of these kernels uses only one work-group with 256 work-items. These kernels are created specifically with one group to ensure that they do not use the entire machine. This is done to illustrate the benefit of parallel kernel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943cba8-e952-4953-bef7-927c6be7d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/kernel_multiple.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "// Array type and data size for this example.\n",
    "constexpr size_t array_size = (1 << 15);\n",
    "typedef std::array<int, array_size> IntArray;\n",
    "\n",
    "#define iter 10\n",
    "\n",
    "int multi_queue(sycl::queue &q, const IntArray &a, const IntArray &b) {\n",
    "  size_t num_items = a.size();\n",
    "  IntArray s1, s2, s3;\n",
    "\n",
    "  sycl::buffer a_buf(a);\n",
    "  sycl::buffer b_buf(b);\n",
    "  sycl::buffer sum_buf1(s1);\n",
    "  sycl::buffer sum_buf2(s2);\n",
    "  sycl::buffer sum_buf3(s3);\n",
    "\n",
    "  size_t num_groups = 1;\n",
    "  size_t wg_size = 256;\n",
    "  auto start = std::chrono::steady_clock::now();\n",
    "  for (int i = 0; i < iter; i++) {\n",
    "    q.submit([&](sycl::handler &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      sycl::accessor sum_acc(sum_buf1, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < array_size; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "    q.submit([&](sycl::handler &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      sycl::accessor sum_acc(sum_buf2, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < array_size; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "    q.submit([&](sycl::handler &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      sycl::accessor sum_acc(sum_buf3, h, sycl::write_only, sycl::no_init);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < array_size; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "  }\n",
    "  q.wait();\n",
    "  auto end = std::chrono::steady_clock::now();\n",
    "  std::cout << \"multi_queue completed on device - took \"\n",
    "            << (end - start).count()/ 1e+9 << \" seconds\\n\";\n",
    "  // check results\n",
    "  return ((end - start).count());\n",
    "} // end multi_queue\n",
    "\n",
    "void InitializeArray(IntArray &a) {\n",
    "  for (size_t i = 0; i < a.size(); i++)\n",
    "    a[i] = 1;\n",
    "}\n",
    "\n",
    "IntArray a, b;\n",
    "\n",
    "int main() {\n",
    "\n",
    "  sycl::queue q;\n",
    "\n",
    "  InitializeArray(a);\n",
    "  InitializeArray(b);\n",
    "\n",
    "  std::cout << \"Running on device: \"\n",
    "            << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  std::cout << \"Vector size: \" << a.size() << \"\\n\";\n",
    "\n",
    "  // begin in-order submission\n",
    "  std::cout << \"In order queue: Jitting+Execution time\\n\";\n",
    "  sycl::queue q1{sycl::property::queue::in_order()};\n",
    "  multi_queue(q1, a, b);\n",
    "  std::cout << \"In order queue: Execution time\\n\";\n",
    "  multi_queue(q1, a, b);\n",
    "  // end in-order submission\n",
    "\n",
    "  // begin out-of-order submission\n",
    "  sycl::queue q2;\n",
    "  std::cout << \"Out of order queue: Jitting+Execution time\\n\";\n",
    "  multi_queue(q2, a, b);\n",
    "  std::cout << \"Out of order queue: Execution time\\n\";\n",
    "  multi_queue(q2, a, b);\n",
    "  // end out-of-order submission\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bae7f6-36d5-42d8-81e2-a86bc22702d6",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9861bda-3aed-48ed-a667-af0f279f1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_kernel_multiple.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2a6c52-a00c-41cb-befc-62c345cfeb3c",
   "metadata": {},
   "source": [
    "In the case where the underlying queue is in-order, these kernels cannot be executed in parallel and have to be executed sequentially even though there are adequate resources in the machine and there are no dependencies among the kernels. This can be seen from the larger total execution time for all the kernels. The creation of the queue and the kernel submission is shown below.\n",
    "\n",
    "When the queue is out-of-order, the overall execution time is much lower, indicating that the machine is able to execute different kernels from the queue at the same time. The creation of the queue and the invocation of the kernel is shown below.\n",
    "\n",
    "In situations where kernels do not scale strongly and therefore cannot effectively utilize full machine compute resources, it is better to allocate only the required compute units through appropriate selection of work-group/work-item values and try to execute multiple kernels at the same time.\n",
    "\n",
    "It is also possible to statically partition a single device into sub-devices through the use of `create_sub_devices` function of device class. This provides more control to the programmer for submitting kernels to an appropriate sub-device. However, the partition of a device into sub-devices is static, so the runtime will not be able to adapt to the dynamic load of an application because it does not have flexibility to move kernels from one sub-device to another.\n",
    "\n",
    "> NOTE:\n",
    "> At the time of writing, only the OpenCL backend is able to execute the kernels out of order. Support in the Level Zero backend to execute kernels out of order is still in development.\n",
    ">\n",
    "> To see concurrent kernel execution we will have to set the SYCL backend to `opencl`, by default the SYCL backend is `level_zero` for Intel oneAPI DPC++ Compiler\n",
    ">```sh\n",
    "export SYCL_DEVICE_FILTER=opencl\n",
    "> \n",
    ">export SYCL_DEVICE_FILTER=level_zero\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489cfa2-660f-47de-b87f-862051d2f6db",
   "metadata": {},
   "source": [
    "## Submitting Kernels to Multiple Queues\n",
    "Queues provide a channel to submit kernels for execution on an accelerator. Queues also hold a context that describes the state of the device. This state includes the contents of buffers and any memory needed to execute the kernels. The runtime keeps track of the current device context and avoids unnecessary memory transfers between host and device. Therefore, it is better to submit and launch kernels from one context together, as opposed to interleaving the kernel submissions in different contexts.\n",
    "\n",
    "The following example submits 3000 independent kernels that use the same buffers as input to compute the result into different output buffers. All these kernels are completely independent and can potentially execute concurrently and out of order. The kernels are submitted to three queues, and the execution of each kernel will incur different costs depending on the how the queues are created. The SYCL code submits kernels in 3 different ways:\n",
    "- Kernel submission to same queue\n",
    "- Kernel submission to different queues with same context\n",
    "- Kernel submission to different queues with different contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca857c-2862-4beb-bdb6-fdc320da79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/kernel_multiple_queues.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr int N = 1024;\n",
    "#define iter 1000\n",
    "\n",
    "int VectorAdd(sycl::queue &q1, sycl::queue &q2, sycl::queue &q3,\n",
    "              std::vector<int> a, std::vector<int> b) {\n",
    "\n",
    "  sycl::buffer a_buf(a);\n",
    "  sycl::buffer b_buf(b);\n",
    "  sycl::buffer<int> *sum_buf[3 * iter];\n",
    "  for (size_t i = 0; i < (3 * iter); i++)\n",
    "    sum_buf[i] = new sycl::buffer<int>(256);\n",
    "\n",
    "  size_t num_groups = 1;\n",
    "  size_t wg_size = 256;\n",
    "  auto start = std::chrono::steady_clock::now();\n",
    "  for (int i = 0; i < iter; i++) {\n",
    "    q1.submit([&](auto &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      auto sum_acc = sum_buf[3 * i]->get_access<sycl::access::mode::write>(h);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < N; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "    q2.submit([&](auto &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      auto sum_acc =\n",
    "          sum_buf[3 * i + 1]->get_access<sycl::access::mode::write>(h);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < N; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "    q3.submit([&](auto &h) {\n",
    "      sycl::accessor a_acc(a_buf, h, sycl::read_only);\n",
    "      sycl::accessor b_acc(b_buf, h, sycl::read_only);\n",
    "      auto sum_acc =\n",
    "          sum_buf[3 * i + 2]->get_access<sycl::access::mode::write>(h);\n",
    "\n",
    "      h.parallel_for(sycl::nd_range<1>(num_groups * wg_size, wg_size),\n",
    "                     [=](sycl::nd_item<1> index) {\n",
    "                       size_t loc_id = index.get_local_id();\n",
    "                       sum_acc[loc_id] = 0;\n",
    "                       for (int j = 0; j < 1000; j++)\n",
    "                         for (size_t i = loc_id; i < N; i += wg_size) {\n",
    "                           sum_acc[loc_id] += a_acc[i] + b_acc[i];\n",
    "                         }\n",
    "                     });\n",
    "    });\n",
    "  }\n",
    "  q1.wait();\n",
    "  q2.wait();\n",
    "  q3.wait();\n",
    "  auto end = std::chrono::steady_clock::now();\n",
    "  std::cout << \"Vector add completed on device - took \" << (end - start).count() / 1e+9 << \" seconds\\n\";\n",
    "  // check results\n",
    "  for (size_t i = 0; i < (3 * iter); i++)\n",
    "    delete sum_buf[i];\n",
    "  return ((end - start).count());\n",
    "}\n",
    "\n",
    "\n",
    "int main() {\n",
    "\n",
    "  sycl::queue q(sycl::default_selector_v);\n",
    "  \n",
    "  std::vector<int> a(N, 1);\n",
    "  std::vector<int> b(N, 2);\n",
    "\n",
    "  std::cout << \"Running on device: \"\n",
    "            << q.get_device().get_info<sycl::info::device::name>() << \"\\n\";\n",
    "  std::cout << \"Vector size: \" << a.size() << \"\\n\";\n",
    "\n",
    "  // jit the code\n",
    "  VectorAdd(q, q, q, a, b);\n",
    "\n",
    "  std::cout << \"\\nSubmission to same queue out_of_order\\n\";\n",
    "  VectorAdd(q, q, q, a, b);\n",
    "\n",
    "  sycl::queue q0(sycl::default_selector_v, sycl::property::queue::in_order());\n",
    "  std::cout << \"\\nSubmission to same queue in_order\\n\";\n",
    "  VectorAdd(q0, q0, q0, a, b);\n",
    "    \n",
    "  std::cout << \"\\nSubmission to different queues with same context\\n\";\n",
    "  sycl::queue q1(sycl::default_selector_v);\n",
    "  sycl::queue q2(q1.get_context(), sycl::default_selector_v);\n",
    "  sycl::queue q3(q1.get_context(), sycl::default_selector_v);\n",
    "  VectorAdd(q1, q2, q3, a, b);\n",
    "\n",
    "  std::cout << \"\\nSubmission to different queues with different contexts\\n\";\n",
    "  sycl::queue q4(sycl::default_selector_v);\n",
    "  sycl::queue q5(sycl::default_selector_v);\n",
    "  sycl::queue q6(sycl::default_selector_v);\n",
    "  VectorAdd(q4, q5, q6, a, b);\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ad6f9-61d4-4e24-935c-4c5077fc9c28",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5577d8-d137-4488-a18a-0a1d6fda7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_kernel_multiple_queues.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e08e-59f0-463e-a517-d6f3418e5e10",
   "metadata": {},
   "source": [
    "Submitting the kernels to the same queue gives the best performance because all the kernels are able to just transfer the needed inputs once at the beginning and do all their computations.\n",
    "```cpp\n",
    "  VectorAdd(q, q, q, a, b);\n",
    "```\n",
    "If the kernels are submitted to different queues that share the same context, the performance is similar to submitting it to one queue. The issue to note here is that when a kernel is submitted to a new queue with a different context, the JIT process compiles the kernel to the new device associated with the context. If this JIT compilation time is discounted, the actual execution of the kernels is similar.\n",
    "```cpp\n",
    "  sycl::queue q1(d_selector);\n",
    "  sycl::queue q2(q1.get_context(), d_selector);\n",
    "  sycl::queue q3(q1.get_context(), d_selector);\n",
    "  VectorAdd(q1, q2, q3, a, b);\n",
    "```\n",
    "If the kernels are submitted to three different queues that have three different contexts, performance degrades because at kernel invocation, the runtime needs to transfer all input buffers to the accelerator every time. In addition, the kernels will be JITed for each of the contexts.\n",
    "```cpp\n",
    "  sycl::queue q4(d_selector);\n",
    "  sycl::queue q5(d_selector);\n",
    "  sycl::queue q6(d_selector);\n",
    "  VectorAdd(q4, q5, q6, a, b);\n",
    "```\n",
    "If for some reason you need to use different queues, the problem can be alleviated by creating the queues with shared context. This will prevent the need to transfer the input buffers, but the memory footprint of the kernels will increase because all the output buffers have to be resident at the same time in the context, whereas earlier the same memory on the device could be used for the output buffers. \n",
    "\n",
    "Another thing to remember is the issue of __memory-to-compute ratio__ in the kernels. If the compute requirement of the kernel is low, the overall execution is dominated by the memory transfers. When the compute is high, these transfers do not contribute much to the overall execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592aeb8-63c5-46af-9b42-b4a41bf1724f",
   "metadata": {},
   "source": [
    "## Avoid Redundant Queue Construction\n",
    "To execute kernels on a device, the user must create a queue, which references an associated context, platform, and device. These may be chosen automatically, or specified by the user.\n",
    "\n",
    "A context is constructed, either directly by the user or implicitly when creating a queue, to hold all the runtime information required by the SYCL runtime and the SYCL backend to operate on a device. When a queue is created with no context specified, a new context is implicitly constructed using the default constructor. In general, creating a new context is a heavy duty operation due to the need for JIT compiling the program every time a kernel is submitted to a queue with a new context. For good performance one should use as few contexts as possible in their application.\n",
    "\n",
    "In the following example, a queue is created inside the loop and the kernel is submitted to this new queue. This will essentially invoke the JIT compiler for every iteration of the loop.\n",
    "\n",
    "Try the 4 modifications and compare the performance numbers:\n",
    "\n",
    "1. Run the code and check the performance number.\n",
    "\n",
    "2. In case you need to create multiple queues, try to share the contexts among the queues. This will improve the performance.\n",
    "\n",
    "   In the code below you can change `sycl::queue q2;` to:\n",
    "   ```cpp\n",
    "   sycl::queue q2{ q1.get_context(), sycl::default_selector() };\n",
    "   ```\n",
    "3. Another implementation is by moving the `q2` queue declaration outside the for-loop, which improves performance quite dramatically.\n",
    "\n",
    "4. You can also use the same `sycl::queue` `q1` inside the for-loop, instead of using `q2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570eb205-4177-4ff4-b3ac-bf647a82ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/kernel_redundant_queue.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "constexpr int N = 1024000;\n",
    "constexpr int ITER = 1000;\n",
    "\n",
    "int main() {\n",
    "\n",
    "  std::vector<int> data(N);\n",
    "  sycl::buffer<int> data_buf(data);\n",
    "\n",
    "  auto start = std::chrono::high_resolution_clock::now().time_since_epoch().count();\n",
    "\n",
    "  //# kernel to initialize data \n",
    "  sycl::queue q1;\n",
    "  q1.submit([&](auto &h) {\n",
    "    sycl::accessor data_acc(data_buf, h, sycl::write_only, sycl::no_init);\n",
    "    h.parallel_for(N, [=](auto i) { data_acc[i] = i; });\n",
    "  }).wait();\n",
    "\n",
    "  //# for-loop with kernel computation\n",
    "  for (int i = 0; i < ITER; i++) {\n",
    "\n",
    "    sycl::queue q2;\n",
    "\n",
    "    q2.submit([&](auto &h) {\n",
    "      sycl::accessor data_acc(data_buf, h);\n",
    "      h.parallel_for(N, [=](auto i) {\n",
    "        data_acc[i] += 1;\n",
    "      });\n",
    "    });\n",
    "    sycl::host_accessor ha(data_buf);\n",
    "\n",
    "  }\n",
    "  std::cout << \"data[0] = \" << data[0] << \"\\n\";\n",
    "    \n",
    "  auto duration = std::chrono::high_resolution_clock::now().time_since_epoch().count() - start;\n",
    "  std::cout << \"Compute Duration: \" << duration / 1e+9 << \" seconds\\n\";\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860da732-35d1-4be6-8fc4-42f45f9feebb",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456763f5-900d-4d5a-9363-3866c9a4613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q.sh run_kernel_redundant_queue.sh gen9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0633fe9-0ac5-4b65-bb15-2a5d59f3f5fb",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Intel GPU Optimization Guide](https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html) - Up to date resources for Intel GPU Optimization\n",
    "- [SYCL Specification](https://registry.khronos.org/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf) - Latest Specification document for reference\n",
    "- [SYCL Essentials Training](https://github.com/oneapi-src/oneAPI-samples/tree/master/DirectProgramming/C%2B%2BSYCL/Jupyter/oneapi-essentials-training) - Learn basics of C++ SYCL Programming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
