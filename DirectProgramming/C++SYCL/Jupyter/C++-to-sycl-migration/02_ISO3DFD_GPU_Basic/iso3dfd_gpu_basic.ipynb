{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISO3DFD and Implementation using SYCL offloading to a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Understand how to offload the most profitable loops in your code on the GPU using SYCL</li>    \n",
    "    <li>Map arrays on the device and define how you are going to access you data</li>\n",
    "    <li>Offload the loops to dispatch the work on the selected device</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISO3DFD offloading to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous activity, we used Intel® Offload Advisor to decide which sections of codes would be good candidates for offloading on the gen9. Advisor ended up recommending to focus on one of the most profitable loop in our serial version of the CPU code.\n",
    "\n",
    "Our goal is now to make sure that this loop is going to be correctly offloaded to a GPU\n",
    "\n",
    "Based on the output provided by the Advisor, we can see the estimated speed-up if we offload loops identified in the Top Offloaded section of the output.Using SYCL, we'll offload that function to run as a kernel on the system's GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Offloading ISO3DFD application to a GPU\n",
    "The 2_GPU_basic_offload version of the sample has implemented the basic offload of the iso3dfd function to an available GPU on the system.\n",
    "* We have to create queue in iso3dfd function as per below.\n",
    "\n",
    "```\n",
    "queue q(default_selector_v, {property::queue::in_order()});\n",
    "```\n",
    "* Instead of iterating over all the cells in the memory, we will create buffers and accessors to move the data to the GPU when needed\n",
    "\n",
    "```\n",
    "// Create 3D SYCL range for kernels which not include HALO\n",
    "  range<3> kernel_range(n1 - 2 * kHalfLength, n2 - 2 * kHalfLength,\n",
    "                        n3 - 2 * kHalfLength);\n",
    "  // Create 3D SYCL range for buffers which include HALO\n",
    "  range<3> buffer_range(n1, n2, n3);\n",
    "  // Create buffers using SYCL class buffer\n",
    "  buffer next_buf(next, buffer_range);\n",
    "  buffer prev_buf(prev, buffer_range);\n",
    "  buffer vel_buf(vel, buffer_range);\n",
    "  buffer coeff_buf(coeff, range(kHalfLength + 1));\n",
    "  ```\n",
    "* Create a kernel which will do the calculations, each kernel will calculate one cell.\n",
    "\n",
    "```\n",
    "// Send a SYCL kernel(lambda) to the device for parallel execution\n",
    "      // Each kernel runs single cell\n",
    "      h.parallel_for(kernel_range, [=](id<3> idx) {\n",
    "        // Start of device code\n",
    "        // Add offsets to indices to exclude HALO\n",
    "        int i = idx[0] + kHalfLength;\n",
    "        int j = idx[1] + kHalfLength;\n",
    "        int k = idx[2] + kHalfLength;\n",
    "\n",
    "        // Calculate values for each cell\n",
    "        //Please refer to the below source code        \n",
    "      });\n",
    "    });\n",
    "    \n",
    "```\n",
    "The SYCL code below shows Iso3dFD GPU code using SYCL: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/2_GPU_basic.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "#include <chrono>\n",
    "#include <string>\n",
    "#include <fstream>\n",
    "\n",
    "#include \"Utils.hpp\"\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "void iso3dfd(queue& q, float* next, float* prev, float* vel, float* coeff,\n",
    "             const size_t n1, const size_t n2, const size_t n3,\n",
    "             const size_t nreps) {\n",
    "  // Create 3D SYCL range for kernels which not include HALO\n",
    "  range<3> kernel_range(n1 - 2 * kHalfLength, n2 - 2 * kHalfLength,\n",
    "                        n3 - 2 * kHalfLength);\n",
    "  // Create 3D SYCL range for buffers which include HALO\n",
    "  range<3> buffer_range(n1, n2, n3);\n",
    "  // Create buffers using SYCL class buffer\n",
    "  buffer next_buf(next, buffer_range);\n",
    "  buffer prev_buf(prev, buffer_range);\n",
    "  buffer vel_buf(vel, buffer_range);\n",
    "  buffer coeff_buf(coeff, range(kHalfLength + 1));\n",
    "\n",
    "  for (auto it = 0; it < nreps; it += 1) {\n",
    "    // Submit command group for execution\n",
    "    q.submit([&](handler& h) {\n",
    "      // Create accessors\n",
    "      accessor next_acc(next_buf, h);\n",
    "      accessor prev_acc(prev_buf, h);\n",
    "      accessor vel_acc(vel_buf, h, read_only);\n",
    "      accessor coeff_acc(coeff_buf, h, read_only);\n",
    "\n",
    "      // Send a SYCL kernel(lambda) to the device for parallel execution\n",
    "      // Each kernel runs single cell\n",
    "      h.parallel_for(kernel_range, [=](id<3> idx) {\n",
    "        // Start of device code\n",
    "        // Add offsets to indices to exclude HALO\n",
    "        int i = idx[0] + kHalfLength;\n",
    "        int j = idx[1] + kHalfLength;\n",
    "        int k = idx[2] + kHalfLength;\n",
    "\n",
    "        // Calculate values for each cell\n",
    "        float value = prev_acc[i][j][k] * coeff_acc[0];\n",
    "#pragma unroll(8)\n",
    "        for (int x = 1; x <= kHalfLength; x++) {\n",
    "          value +=\n",
    "              coeff_acc[x] * (prev_acc[i][j][k + x] + prev_acc[i][j][k - x] +\n",
    "                              prev_acc[i][j + x][k] + prev_acc[i][j - x][k] +\n",
    "                              prev_acc[i + x][j][k] + prev_acc[i - x][j][k]);\n",
    "        }\n",
    "        next_acc[i][j][k] = 2.0f * prev_acc[i][j][k] - next_acc[i][j][k] +\n",
    "                            value * vel_acc[i][j][k];\n",
    "        // End of device code\n",
    "      });\n",
    "    });\n",
    "\n",
    "    // Swap the buffers for always having current values in prev buffer\n",
    "    std::swap(next_buf, prev_buf);\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "  // Arrays used to update the wavefield\n",
    "  float* prev;\n",
    "  float* next;\n",
    "  // Array to store wave velocity\n",
    "  float* vel;\n",
    "\n",
    "  // Variables to store size of grids and number of simulation iterations\n",
    "  size_t n1, n2, n3;\n",
    "  size_t num_iterations;\n",
    "\n",
    "  // Flag to verify results with CPU version\n",
    "  bool verify = false;\n",
    "\n",
    "  if (argc < 5) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    // Parse command line arguments and increase them by HALO\n",
    "    n1 = std::stoi(argv[1]) + (2 * kHalfLength);\n",
    "    n2 = std::stoi(argv[2]) + (2 * kHalfLength);\n",
    "    n3 = std::stoi(argv[3]) + (2 * kHalfLength);\n",
    "    num_iterations = std::stoi(argv[4]);\n",
    "    if (argc > 5) verify = true;\n",
    "  } catch (...) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  // Validate input sizes for the grid\n",
    "  if (ValidateInput(n1, n2, n3, num_iterations)) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  // Create queue and print target info with default selector and in order\n",
    "  // property\n",
    "  queue q(default_selector_v, {property::queue::in_order()});\n",
    "  std::cout << \" Running GPU basic offload version\\n\";\n",
    "  printTargetInfo(q);\n",
    "\n",
    "  // Compute the total size of grid\n",
    "  size_t nsize = n1 * n2 * n3;\n",
    "\n",
    "  prev = new float[nsize];\n",
    "  next = new float[nsize];\n",
    "  vel = new float[nsize];\n",
    "\n",
    "  // Compute coefficients to be used in wavefield update\n",
    "  float coeff[kHalfLength + 1] = {-3.0548446,   +1.7777778,     -3.1111111e-1,\n",
    "                                  +7.572087e-2, -1.76767677e-2, +3.480962e-3,\n",
    "                                  -5.180005e-4, +5.074287e-5,   -2.42812e-6};\n",
    "\n",
    "  // Apply the DX, DY and DZ to coefficients\n",
    "  coeff[0] = (3.0f * coeff[0]) / (dxyz * dxyz);\n",
    "  for (auto i = 1; i <= kHalfLength; i++) {\n",
    "    coeff[i] = coeff[i] / (dxyz * dxyz);\n",
    "  }\n",
    "\n",
    "  // Initialize arrays and introduce initial conditions (source)\n",
    "  initialize(prev, next, vel, n1, n2, n3);\n",
    "\n",
    "  auto start = std::chrono::steady_clock::now();\n",
    "\n",
    "  // Invoke the driver function to perform 3D wave propagation offloaded to\n",
    "  // the device\n",
    "  iso3dfd(q, next, prev, vel, coeff, n1, n2, n3, num_iterations);\n",
    "\n",
    "  auto end = std::chrono::steady_clock::now();\n",
    "  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start)\n",
    "                  .count();\n",
    "  printStats(time, n1, n2, n3, num_iterations);\n",
    "\n",
    "  // Verify result with the CPU serial version\n",
    "  if (verify) {\n",
    "    VerifyResult(prev, next, vel, coeff, n1, n2, n3, num_iterations);\n",
    "  }\n",
    "\n",
    "  delete[] prev;\n",
    "  delete[] next;\n",
    "  delete[] vel;\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is created, we can run it from the command line by using few parameters as following:\n",
    "src/2_GPU_basic 256 256 256 100\n",
    "<ul>\n",
    "    <li>bin/2_GPU_basic is the binary</li>\n",
    "    <li>128 128 128 are the size for the 3 dimensions, increasing it will result in more computation time</li>    \n",
    "    <li>100 is the number of time steps</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_only.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_only.sh; else ./run_gpu_only.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iso3DFD GPU Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started from a code version running with standard C++ on the CPU. Using Intel® Offload Advisor, we determined which loop was a good candidate for offload and then using SYCL we worked on a solution to make our code run on the GPU but also on the CPU.\n",
    "\n",
    "Getting the best performances possible on the CPU or on the GPU would require some fine tuning specific to each platform but we already have a portable solution.\n",
    "\n",
    "The next step, to optimize further on the GPU would be to run the Roofline Model and/or VTune to try to understand if we have obvious bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is the Roofline Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Roofline chart is a visual representation of application performance in relation to hardware limitations, including memory bandwidth and computational peaks.  Intel Advisor includes an automated Roofline tool that measures and plots the chart on its own, so all you need to do is read it.\n",
    "\n",
    "The chart can be used to identify not only where bottlenecks exist, but what’s likely causing them, and which ones will provide the most speedup if optimized.\n",
    "\n",
    "#### Requirements for a Roofline Model on a GPU\n",
    "In order to generate a roofline analysis report ,application must be at least partially running on a GPU and the Offload must be implemented with OpenMP, SYCL or OpenCL and a recent version of Intel® Advisor \n",
    "\n",
    "Generating a Roofline Model on GPU generates a multi-level roofline where a single loop generates several dots and each dot can be compared to its own memory (GTI/L3/DRAM/SLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Finding Effective Optimization Strategies\n",
    " Here are the GPU Roofline Performance Insights, it highlights poor performing loops and shows performance ‘headroom’  for each loop which can be improved and which are worth improving. The report shows likely causes of bottlenecks where it can be Memory bound vs. compute bound. It also suggests next optimization steps\n",
    "\n",
    "  \n",
    "  <img src=\"img/r1.png\">\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running the GPU Roofline Analysis\n",
    "With the offload implemented in 2_GPU_basic using SYCL, we'll want to run roofline analysis to look for areas where there is room for performance optimization.\n",
    "```\n",
    "advisor --collect=roofline --profile-gpu --project-dir=./advi_results -- ./myApplication \n",
    "```\n",
    "The iso3DFD CPU code can be run using\n",
    "```\n",
    "advisor --collect=roofline --profile-gpu --project-dir=./../advisor/2_gpu -- ./build/src/2_GPU_basic 256 256 256 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_roofline_advisor.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_roofline_advisor.sh; else ./run_gpu_roofline_advisor.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the HTML report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the roofline analysis of the 2_GPU_basic_offload.cpp version, we can see that the performance is close to predicted. \n",
    "As noted in the below roofline model we can observe that,\n",
    "\n",
    "* The application is bounded by compute, specifically that the kernels have high arithmetic intensity.\n",
    "* GINTOPS is more than 15X of the GFLOPS\n",
    "* High XVE Threading Occupancy\n",
    "* We are clearly bounded by the INT operations which is all about index computations\n",
    "\n",
    "<img src=\"img/gpu_basic.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Roofline Analysis report\n",
    "To display the report, just execute the following frame. In practice, the report will be available in the folder you defined as --out-dir in the previous script. \n",
    "\n",
    "[View the report in HTML](reports/advisor-report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/advisor-report.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating VTune reports\n",
    "Below exercises we use VTune™  analyzer as a way to see what is going on with each implementation. The information was the high-level hotspot generated from the collection and rendered in an HTML iframe. Depending on the options chosen, many of the VTune analyzer's performance collections can be rendered via HTML pages. The below vtune scripts collect GPU offload and GPU hotspots information.\n",
    "\n",
    "#### Learn more about VTune\n",
    "​\n",
    "There is extensive training on VTune, click [here](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html#gs.2xmez3) to get deep dive training.\n",
    "\n",
    "```\n",
    "vtune -run-pass-thru=--no-altstack -collect=gpu-offload -result-dir=vtune_dir -- ./build/src/2_GPU_basic 1024 1024 1024 100\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -run-pass-thru=--no-altstack -collect=gpu-hotspots -result-dir=vtune_dir_hotspots -- ./build/src/2_GPU_basic 1024 1024 1024 100\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -report summary -result-dir vtune_dir -format html -report-output ./reports/output_offload.html\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -report summary -result-dir vtune_dir_hotspots -format html -report-output ./reports/output_hotspots.html\n",
    "```\n",
    "[View the Vtune offload report in HTML](reports/output_offload.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/output_offload.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[View the Vtune hotspots report in HTML](reports/output_hotspots.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/output_hotspots.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_vtune.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_vtune.sh; else ./run_gpu_vtune.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Next Iteration of implemeting GPU Optimizations\n",
    "\n",
    "We ran the roofline model and observed:\n",
    "* The application is now bounded by compute, specifically that the kernels have high arithmetic intensity and we are bounded by the INT operations which is all about index computations.\n",
    "* What we need to solve, is to provide to the kernel the good index (offset in the original code). \n",
    "* SYCL provides this information through an iterator that is sent by the runtime to the function. This iterator allows to identify the position of the current iteration in the 3D space. \n",
    "* It can be accessed on 3 dimensions by calling: it.get_global_id(0), it.get_global_id(1), it.get_global_id(2).\n",
    "* In this next iteration, we'll address the problem being compute bound in kernels by reducing index calculations by changing how we calculate indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
