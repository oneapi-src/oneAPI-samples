{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISO3DFD using nd_range kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Understand how to further optimize the application using L1 cache reusage</li>    \n",
    "    <li>Run roofline analysis and the VTune reports again to gauge the results</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iso3DFD using nd_range kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous activity, we used Intel® Advisor roofline analysis to decide on if the application is memory bound and specifically that the kernels have less cache reuse and we are bounded by the L3 memory bound which is all about re-using the memory.\n",
    "\n",
    "In this notebook, we'll address the problem being L3 memory bound in kernels by using dedicated cache reuse memory.\n",
    "\n",
    "The tuning puts more work in each local work group, which optimizes loading neighboring stencil points from the fast L1 cache.\n",
    "\n",
    "To do this we need to change the kernel to nd_range; now they will not calculate only one cell but will iterate so that it schedules 1024 x 1 x 1 grid points on each SIMD16 core and all 1024 points share an L1 cache. The previous activity we schedule 16 x 1 x 1 grid points on each SIMD16 core and only 16 points share L1 cache.\n",
    "\n",
    "We can change the parameters passed to the application to find the best load for each work group. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimizing using nd_range kernel\n",
    "The 4_GPU_optimized version of the sample addresses the memory issue constraints where we'll reuse data from L1 cache resue, where it schedules 1024 x 1 x 1 grid points on each SIMD16 core and all 1024 points share an L1 cache.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "// Create USM objects \n",
    "  auto next = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  next += (16 - kHalfLength);\n",
    "  q.memcpy(next, ptr_next, sizeof(float)*grid_size);\n",
    "  auto prev = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  prev += (16 - kHalfLength);\n",
    "  q.memcpy(prev, ptr_prev, sizeof(float)*grid_size);\n",
    "  auto vel = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  vel += (16 - kHalfLength);\n",
    "  q.memcpy(vel, ptr_vel, sizeof(float)*grid_size);\n",
    "  //auto coeff = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  auto coeff = sycl::aligned_alloc_device<float>(64, kHalfLength+1 , q);\n",
    "  q.memcpy(coeff, ptr_coeff, sizeof(float)*(kHalfLength+1));  \n",
    "  q.wait();  \n",
    "```\n",
    "\n",
    "* The following integer function rounds N up to next multiple of M. Global nd_range must be integer multiple of local nd_range, so global nd_range is rounded to next multiple of local nd_range.  A conditional statement is added to ensure any extra work items do no work.\n",
    "\n",
    "```\n",
    "// Create 1D SYCL range for buffers which include HALO\n",
    "range<1> buffer_range(n1 * n2 * n3);\n",
    "auto global_nd_range = range<3>((n3-2*kHalfLength+n3_block-1)/n3_block*n3_block,(n2-2*kHalfLength+n2_block-1)/n2_block*n2_block,n1_block);\n",
    "\n",
    "```\n",
    "* Change parallel_for to use nd_range. Here each work-item is doing more work reading from faster L1 cache.\n",
    "\n",
    "```\n",
    "q.submit([&](auto &h) {      \n",
    "        h.parallel_for(\n",
    "              nd_range(global_nd_range, local_nd_range), [=](auto item)          \n",
    "         {\n",
    "            const int iz = kHalfLength + item.get_global_id(0);\n",
    "            const int iy = kHalfLength + item.get_global_id(1);\n",
    "            if (iz < n3 - kHalfLength && iy < n2 - kHalfLength)\n",
    "             for (int ix = kHalfLength+item.get_global_id(2); ix < n1 - kHalfLength; ix += n1_block)\n",
    "                {\n",
    "                  auto gid = ix + iy*nx + iz*nxy;\n",
    "                  float *pgid = prev+gid;\n",
    "                  auto value = coeff[0] * pgid[0];\n",
    "#pragma unroll(kHalfLength)\n",
    "                  for (auto iter = 1; iter <= kHalfLength; iter++)\n",
    "                    value += coeff[iter]*(pgid[iter*nxy] + pgid[-iter*nxy] + pgid[iter*nx] + pgid[-iter*nx] + pgid[iter] + pgid[-iter]);\n",
    "                  next[gid] = 2.0f*pgid[0] - next[gid] + value*vel[gid];\n",
    "                }\n",
    "      });    \n",
    "    }).wait();\n",
    "   std::swap(next, prev);\n",
    "\n",
    "```\n",
    "We will run roofline analysis and the VTune reports again to gauge the results.\n",
    "\n",
    "The SYCL code below shows Iso3dFD GPU code using SYCL with Index optimizations: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/4_GPU_optimized.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "\n",
    "#include <sycl/sycl.hpp>\n",
    "#include <chrono>\n",
    "#include <string>\n",
    "#include <fstream>\n",
    "\n",
    "#include \"Utils.hpp\"\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "void iso3dfd(queue& q, float* ptr_next, float* ptr_prev, float* ptr_vel, float* ptr_coeff,\n",
    "             const size_t n1, const size_t n2, const size_t n3,size_t n1_block, size_t n2_block, size_t n3_block,\n",
    "             const size_t nIterations) {\n",
    "  auto nx = n1;\n",
    "  auto nxy = n1*n2;\n",
    "  auto grid_size = nxy*n3;  \n",
    "\n",
    "  auto next = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  next += (16 - kHalfLength);\n",
    "  q.memcpy(next, ptr_next, sizeof(float)*grid_size);\n",
    "  auto prev = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  prev += (16 - kHalfLength);\n",
    "  q.memcpy(prev, ptr_prev, sizeof(float)*grid_size);\n",
    "  auto vel = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  vel += (16 - kHalfLength);\n",
    "  q.memcpy(vel, ptr_vel, sizeof(float)*grid_size);\n",
    "  //auto coeff = sycl::aligned_alloc_device<float>(64, grid_size + 16, q);\n",
    "  auto coeff = sycl::aligned_alloc_device<float>(64, kHalfLength+1 , q);\n",
    "  q.memcpy(coeff, ptr_coeff, sizeof(float)*(kHalfLength+1));  \n",
    "  q.wait();  \n",
    "\t\t\t\t  \n",
    "  auto local_nd_range = range<3>(n3_block,n2_block,n1_block);\n",
    "  auto global_nd_range = range<3>((n3-2*kHalfLength+n3_block-1)/n3_block*n3_block,(n2-2*kHalfLength+n2_block-1)/n2_block*n2_block,n1_block);\n",
    "  \n",
    "\n",
    "  for (auto i = 0; i < nIterations; i += 1) {\n",
    "    q.submit([&](auto &h) {      \n",
    "        h.parallel_for(\n",
    "              nd_range(global_nd_range, local_nd_range), [=](auto item)          \n",
    "         {\n",
    "            const int iz = kHalfLength + item.get_global_id(0);\n",
    "            const int iy = kHalfLength + item.get_global_id(1);\n",
    "            if (iz < n3 - kHalfLength && iy < n2 - kHalfLength)\n",
    "             for (int ix = kHalfLength+item.get_global_id(2); ix < n1 - kHalfLength; ix += n1_block)\n",
    "                {\n",
    "                  auto gid = ix + iy*nx + iz*nxy;\n",
    "                  float *pgid = prev+gid;\n",
    "                  auto value = coeff[0] * pgid[0];\n",
    "#pragma unroll(kHalfLength)\n",
    "                  for (auto iter = 1; iter <= kHalfLength; iter++)\n",
    "                    value += coeff[iter]*(pgid[iter*nxy] + pgid[-iter*nxy] + pgid[iter*nx] + pgid[-iter*nx] + pgid[iter] + pgid[-iter]);\n",
    "                  next[gid] = 2.0f*pgid[0] - next[gid] + value*vel[gid];\n",
    "                }\n",
    "      });    \n",
    "    }).wait();\n",
    "   std::swap(next, prev);\n",
    "  }\n",
    "  q.memcpy(ptr_prev, prev, sizeof(float)*grid_size);\n",
    "\n",
    "  sycl::free(next - (16 - kHalfLength),q);\n",
    "  sycl::free(prev - (16 - kHalfLength),q);\n",
    "  sycl::free(vel - (16 - kHalfLength),q);\n",
    "  sycl::free(coeff,q);  \n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "  // Arrays used to update the wavefield\n",
    "  float* prev;\n",
    "  float* next;\n",
    "  // Array to store wave velocity\n",
    "  float* vel;\n",
    "\n",
    "  // Variables to store size of grids and number of simulation iterations\n",
    "  size_t n1, n2, n3;\n",
    "    size_t n1_block, n2_block, n3_block;\n",
    "  size_t num_iterations;\n",
    "\n",
    "  // Flag to verify results with CPU version\n",
    "  bool verify = false;\n",
    "\n",
    "  if (argc < 5) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    // Parse command line arguments and increase them by HALO\n",
    "    n1 = std::stoi(argv[1]) + (2 * kHalfLength);\n",
    "    n2 = std::stoi(argv[2]) + (2 * kHalfLength);\n",
    "    n3 = std::stoi(argv[3]) + (2 * kHalfLength);\n",
    "    n1_block = std::stoi(argv[4]);\n",
    "    n2_block = std::stoi(argv[5]);\n",
    "    n3_block = std::stoi(argv[6]);\n",
    "    num_iterations = std::stoi(argv[7]);    \n",
    "  } catch (...) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  // Validate input sizes for the grid\n",
    "  if (ValidateInput(n1, n2, n3, num_iterations)) {\n",
    "    Usage(argv[0]);\n",
    "    return 1;\n",
    "  }\n",
    "\n",
    "  // Create queue and print target info with default selector and in order\n",
    "  // property\n",
    "  queue q(default_selector_v, {property::queue::in_order()});\n",
    "  std::cout << \" Running nd_range GPU version\\n\";\n",
    "  printTargetInfo(q);\n",
    "\n",
    "  // Compute the total size of grid\n",
    "  size_t nsize = n1 * n2 * n3;\n",
    "\n",
    "  prev = new float[nsize];\n",
    "  next = new float[nsize];\n",
    "  vel = new float[nsize];\n",
    "\n",
    "  // Compute coefficients to be used in wavefield update\n",
    "  float coeff[kHalfLength + 1] = {-3.0548446,   +1.7777778,     -3.1111111e-1,\n",
    "                                  +7.572087e-2, -1.76767677e-2, +3.480962e-3,\n",
    "                                  -5.180005e-4, +5.074287e-5,   -2.42812e-6};\n",
    "\n",
    "  // Apply the DX, DY and DZ to coefficients\n",
    "  coeff[0] = (3.0f * coeff[0]) / (dxyz * dxyz);\n",
    "  for (auto i = 1; i <= kHalfLength; i++) {\n",
    "    coeff[i] = coeff[i] / (dxyz * dxyz);\n",
    "  }\n",
    "\n",
    "  // Initialize arrays and introduce initial conditions (source)\n",
    "  initialize(prev, next, vel, n1, n2, n3);\n",
    "\n",
    "  auto start = std::chrono::steady_clock::now();\n",
    "\n",
    "  // Invoke the driver function to perform 3D wave propagation offloaded to\n",
    "  // the device\n",
    "  iso3dfd(q, next, prev, vel, coeff, n1, n2, n3,n1_block,n2_block,n3_block, num_iterations);\n",
    "\n",
    "  auto end = std::chrono::steady_clock::now();\n",
    "  auto time = std::chrono::duration_cast<std::chrono::milliseconds>(end - start)\n",
    "                  .count();\n",
    "  printStats(time, n1, n2, n3, num_iterations);  \n",
    "\n",
    "  delete[] prev;\n",
    "  delete[] next;\n",
    "  delete[] vel;\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is created, we can run it from the command line by using few parameters as following:\n",
    "src/4_GPU_optimized /4_GPU_optimized 1024 1024 1024 32 8 4 100\n",
    "<ul>\n",
    "    <li>bin/4_GPU_optimized is the binary</li>\n",
    "    <li>/1024 1024 1024 32 8 4 100 are the size for the 3 dimensions, increasing it will result in more computation time</li>    \n",
    "    <li>100 is the number of time steps</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_optimized.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_optimized.sh; else ./run_gpu_optimized.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISO3DFD GPU Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We started from a code version running with standard C++ on the CPU.\n",
    "* Using Intel® Offload Advisor, we determined which loop was a good candidate for offload and then using SYCL we worked on a solution to make our code run on the GPU but also on the CPU.\n",
    "* We identifed the application is bound by Integer opearations.\n",
    "* We fixed the indexing to make the code more optimized with reduced INT operations\n",
    "* we are going to check how the implementation of L1 cache reusage works\n",
    "* The next step, is to to run the Roofline Model and VTune to\n",
    "    * Check the current optimizations using L1 cache reusage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running the GPU Roofline Analysis\n",
    "With the offload implemented in 4_GPU_optimized using SYCL, we'll want to run roofline analysis to see the improvements we made to the application and look for more areas where there is room for performance optimization.\n",
    "```\n",
    "advisor --collect=roofline --profile-gpu --project-dir=./advi_results -- ./myApplication \n",
    "```\n",
    "The iso3DFD GPU optimized code can be run using\n",
    "```\n",
    "advisor --collect=roofline --profile-gpu --project-dir=./../advisor/4_gpu -- ./build/src/4_GPU_optimized 1024 1024 1024 32 8 4 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_roofline_advisor.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_roofline_advisor.sh; else ./run_gpu_roofline_advisor.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the HTML report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As noted in the below roofline model we can observe that,\n",
    "\n",
    "* We can observe it is bounded by HBM memory\n",
    "* Still lesser INT operations.\n",
    "* High HBM traffic\n",
    "* Higher Threading occupancy\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/4_iso.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Roofline Analysis report overview\n",
    "To display the report, just execute the following frame. In practice, the report will be available in the folder you defined as --out-dir in the previous script. \n",
    "\n",
    "[View the report in HTML](reports/advisor-report_linear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/advisor-report.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generating VTune reports\n",
    "Below exercises we use VTune™  analyzer as a way to see what is going on with each implementation. The information was the high-level hotspot generated from the collection and rendered in an HTML iframe. Depending on the options chosen, many of the VTune analyzer's performance collections can be rendered via HTML pages. The below vtune scripts collect GPU offload and GPU hotspots information.\n",
    "\n",
    "#### Learn more about VTune\n",
    "​\n",
    "There is extensive training on VTune, click [here](https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/vtune-profiler.html#gs.2xmez3) to get deep dive training.\n",
    "\n",
    "```\n",
    "vtune -run-pass-thru=--no-altstack -collect=gpu-offload -result-dir=vtune_dir -- ./build/src/3_GPU_linear 256 256 256 100\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -run-pass-thru=--no-altstack -collect=gpu-hotspots -result-dir=vtune_dir_hotspots -- ./build/src/3_GPU_linear 256 256 256 100\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -report summary -result-dir vtune_dir -format html -report-output ./reports/output_offload.html\n",
    "```\n",
    "\n",
    "```\n",
    "vtune -report summary -result-dir vtune_dir_hotspots -format html -report-output ./reports/output_hotspots.html\n",
    "```\n",
    "\n",
    "[View the report in HTML](reports/output_offload_linear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/output_offload_linear.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[View the report in HTML](reports/output_hotspots_linear.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(src='reports/output_hotspots_linear.html', width=1024, height=768))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_gpu_linear_vtune.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_gpu_linear_vtune.sh; else ./run_gpu_linear_vtune.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* We started from a code version running with standard C++ on the CPU. * Using Intel® Offload Advisor, we determined which loop was a good candidate for offload\n",
    "* Using SYCL we worked on a solution to make our code run on the GPU but also on the CPU.\n",
    "* In the first iteration We identifed the application is bound by Integer opearations and we fixed the indexing to make it more optimized.\n",
    "* The last step we tune by adding more work in each local work group, which optimizes loading neighboring stencil points from the fast L1 cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
