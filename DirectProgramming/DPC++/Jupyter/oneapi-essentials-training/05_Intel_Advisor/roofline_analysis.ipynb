{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel® Advisor - Roofline Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sections demonstrates how to collect and generate a roofline report using Intel Advisor.\n",
    "\n",
    "##### Sections\n",
    "- [What is the Roofline Model?](#What-is-the-Roofline-Model?)\n",
    "- _Analysis:_ [Roofline Analysis Report](#Roofline-Analysis-Report)\n",
    "- [Finding Effective Optimization Strategies](#Finding-Effective-Optimization-Strategies)\n",
    "- [Command Line Options for GPU Roofline Analysis](#Command-Line-Options-for-GPU-Roofline-Analysis)\n",
    "- [Using Roofline Analysis on Intel GPU](#Using-Roofline-Analysis-on-Intel-GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Explain how Intel® Advisor performs GPU Roofline Analysis.\n",
    "- Run the GPU Roofline Analysis using command line syntax.\n",
    "- Use GPU Roofline Analysis to identify effective optimization strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Roofline Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Roofline chart is a visual representation of application performance in relation to hardware limitations, including memory bandwidth and computational peaks.  Intel Advisor includes an automated Roofline tool that measures and plots the chart on its own, so all you need to do is read it.\n",
    "\n",
    "The chart can be used to identify not only where bottlenecks exist, but what’s likely causing them, and which ones will provide the most speedup if optimized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for a Roofline Model on a GPU\n",
    "\n",
    "In order to generate a roofline analysis report ,application must be at least partially running on a GPU, Gen9 or Gen11 integrated graphics and the Offload must be implemented with OpenMP, SYCL, DPC++, or OpenCL and a recent version of Intel® Advisor \n",
    "\n",
    "Generating a Roofline Model on GPU generates a multi-level roofline where a single loop generates several dots and each dot can be compared to its own memory (GTI/L3/DRAM/SLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen9 Memory Hierarchy\n",
    "\n",
    "![image](assets/gen9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roofline Analysis Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a roofline report -- this is another <b>live</b> report that is interactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Intel Advisor Roofline report](assets/roofline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('/bin/echo $(whoami) is running DPCPP_Essentials Module5 -- Roofline_Analysis - 2 of 2 roofline.html')\n",
    "from IPython.display import IFrame\n",
    "IFrame(src='assets/roofline.html', width=1024, height=769)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Effective Optimization Strategies\n",
    " Here are the GPU Roofline Performance Insights, it highlights poor performing loops and shows performance ‘headroom’  for each loop which can be improved and which are worth improving. The report shows likely causes of bottlenecks where it can be Memory bound vs. compute bound. It also suggests next optimization steps\n",
    "\n",
    "  \n",
    "  <img src=\"assets/r1.png\">\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Survey is usually the first analysis you want to run with Intel® Advisor. The survey is mainly used to time your application as well as the different loops and functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the trip count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is to run the trip count analysis. This step uses instrumentation to count how many iterations you are running in each loops. Adding the option -flop will also provide the precise number of operations executed in each of your code sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advisor Command-Line for generating \"roofline\" on the CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clone official GitHubb samples repository\n",
    "     git clone https://github.com/oneapi-src/oneAPI-samples.git\n",
    "        \n",
    "* Go into Project directory to the matrix multiply advisor sample \n",
    "\n",
    "    ``cd oneAPI-samples/Tools/Advisor/matrix_multiply_advisor/``\n",
    "    \n",
    "* Build the application and generate the matrix multiplication binary\n",
    "\n",
    "    ``cmake .``    \n",
    "    ``make``\n",
    "\n",
    "* To run the GPU Roofline analysis in the Intel® Advisor CLI:\n",
    "  Run the Survey analysis with the --enable-gpu-profiling option    \n",
    "     ``advixe-cl –collect=survey --enable-gpu-profiling --project-dir=./adv -- ./matrix.dpcpp``\n",
    "        \n",
    "* Run the Trip Counts and FLOP analysis with --enable-gpu-profiling option:\n",
    "\n",
    "    ``advixe-cl -–collect=tripcounts --stacks --flop --enable-gpu-profiling --project-dir=./adv -- ./matrix.dpcpp``\n",
    "\n",
    "*Generate a GPU Roofline report:\n",
    "    ``advixe-cl --report=roofline --gpu  --project-dir=./adv`` \n",
    "    \n",
    "* Open the generated roofline.html in a web browser to visualize GPU performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile advisor_roofline.sh\n",
    "#!/bin/bash\n",
    "\n",
    "advixe-cl –collect=survey --enable-gpu-profiling --project-dir=./adv -- ./matrix.dpcpp\n",
    "\n",
    "advixe-cl -–collect=tripcounts --stacks --flop --enable-gpu-profiling --project-dir=./adv -- ./matrix.dpcpp\n",
    "\n",
    "advixe-cl --report=roofline --gpu  --project-dir=./adv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Roofline Analysis on Intel GPU\n",
    "You can see how close you are to the system maximums. The roofline indicates maximum room for improvement\n",
    "\n",
    "<img src=\"assets/r2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Dots for all Memory Sub-systems\n",
    "\n",
    "![alt text](assets/roofline3.png \"More info.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Labels\n",
    "\n",
    "![alt text](assets/roofline4.png \"Labeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the View\n",
    "\n",
    "![alt text](assets/roofline5.png \"Clean View.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Guidance\n",
    "\n",
    "![alt text](assets/roofline6.png \"Guidance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "  * We ran a roofline report.\n",
    "  * Explored the features of the roofline report and learned how to interpret the report.\n",
    "  * Examined the information to determine where speedup opportunites exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><span style=\"color:Red\"><h1>Reset Notebook</h1></span></body></html>\n",
    "\n",
    "##### Should you be experiencing any issues with your notebook or just want to start fresh run the below cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "button = widgets.Button(\n",
    "    description='Reset Notebook',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='This will update this notebook, overwriting any changes.',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "out = widgets.Output()\n",
    "def on_button_clicked(_):\n",
    "      # \"linking function with output\"\n",
    "      with out:\n",
    "          # what happens when we press the button\n",
    "          clear_output()\n",
    "          !rsync -a --size-only /data/oneapi_workshop/oneAPI_Essentials/05_Intel_Advisor/ ~/oneAPI_Essentials/05_Intel_Advisor\n",
    "          print('Notebook reset -- now click reload on browser.')\n",
    "# linking button and function together using a button's method\n",
    "button.on_click(on_button_clicked)\n",
    "# displaying button and its output together\n",
    "widgets.VBox([button,out])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
