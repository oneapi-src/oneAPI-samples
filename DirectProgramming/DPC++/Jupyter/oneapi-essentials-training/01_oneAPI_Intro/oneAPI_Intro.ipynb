{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to oneAPI and SYCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sections\n",
    "- [oneAPI Programming Model Overview](#oneAPI-Software-Model-Overview)\n",
    "- [Programming Challenges for Multiple architectures](#Programming-Challenges-for-Multiple-architectures)\n",
    "- [Introducing oneAPI](#Introducing-oneAPI)\n",
    "- _Code:_ [SYCL Hello World](#Simple-Exercise)\n",
    "- [What is SYCL](#SYCL)\n",
    "- [How to Compile & Run a SYCL program](#How-to-Compile-&-Run-SYCL-program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Explain how the __oneAPI__ programming model can solve the challenges of programming in a heterogeneous world \n",
    "* Use oneAPI projects to enable your workflows\n",
    "* Understand the __SYCL__ language and programming model\n",
    "* Familiarization on the use Jupyter notebooks for training throughout the course\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oneAPI Programming Model Overview\n",
    "The __oneAPI__ programming model provides a comprehensive and unified portfolio of developer tools that can\n",
    "be used across hardware targets, including a range of performance libraries spanning several workload\n",
    "domains. The libraries include functions custom-coded for each target architecture so the same\n",
    "function call delivers optimized performance across supported architectures. __DPC++__ is based on\n",
    "industry standards and open specifications to encourage ecosystem collaboration and innovation.\n",
    "\n",
    "### oneAPI Distribution\n",
    "Intel&reg; oneAPI toolkits are available via multiple distribution channels:\n",
    "* Local product installation: install the oneAPI toolkits from the __Intel® Developer Zone__.\n",
    "* Install from containers or repositories: install the oneAPI toolkits from one of several supported\n",
    "containers or repositories.\n",
    "* Pre-installed in the __Intel® DevCloud__: a free development sandbox for access to the latest Intel® SVMS hardware and select oneAPI toolkits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Challenges for Multiple architectures\n",
    "Currently in the data centric space there is growth in specialized workloads. Each kind of data centric hardware typically needs to be programmed using different languages and libraries as there is no common programming language or APIs, this requires maintaining separate code bases. Developers have to learn a whole set of different tools as there is inconsistent tool support across platforms. Developing software for each hardware platform requires a separate investment, with little ability to reuse that work to target a different architecture. You will also have to consider the requirement of the diverse set of data-centric hardware.\n",
    "\n",
    "<img src=\"Assets/oneapi1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing oneAPI\n",
    "__oneAPI__ is a solution to deliver unified programming model to __simplify development__ across diverse architectures. It includes a unified and simplified language and libraries for expressing __parallelism__ and delivers uncompromised native high-level language performance across a range of hardware including __CPUs, GPUs, FPGAs__. oneAPI initiative is based on __industry standards and open specifications__ and is interoperable with existing HPC programming models.\n",
    "\n",
    "<img src=\"Assets/oneapi2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Simple Exercise\n",
    "This exercise introduces SYCL to the developer by way of a small simple code. In addition, it introduces the developer to the Jupyter notebook environment for editing and saving code; and for running and submitting programs to the Intel® DevCloud.\n",
    "\n",
    "##  Editing the simple.cpp code\n",
    "The Jupyter cell below with the gray background can be edited in-place and saved.\n",
    "\n",
    "The first line of the cell contains the command **%%writefile 'simple.cpp'** This tells the input cell to save the contents of the cell into a file named 'simple.cpp' in your current directory (usually your home directory). As you edit the cell and run it in the Jupyter notebook, it will save your changes into that file.\n",
    "\n",
    "The code below is some simple SYCL code to get you started in the DevCloud environment. Simply inspect the code - there are no modifications necessary. Run the first cell to create the file, then run the cell below it to compile and execute the code.\n",
    "1. Inspect the code cell below, then click run ▶ to save the code to a file\n",
    "2. Run ▶ the cell in the __Build and Run__ section below the code snippet to compile and execute the code in the saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "using namespace sycl;\n",
    "static const int N = 16;\n",
    "int main(){\n",
    "  //# define queue which has default device associated for offload\n",
    "  queue q;\n",
    "  std::cout << \"Device: \" << q.get_device().get_info<info::device::name>() << \"\\n\";\n",
    "\n",
    "  //# Unified Shared Memory Allocation enables data access on host and device\n",
    "  int *data = malloc_shared<int>(N, q);\n",
    "\n",
    "  //# Initialization\n",
    "  for(int i=0; i<N; i++) data[i] = i;\n",
    "\n",
    "  //# Offload parallel computation to device\n",
    "  q.parallel_for(range<1>(N), [=] (id<1> i){\n",
    "    data[i] *= 2;\n",
    "  }).wait();\n",
    "\n",
    "  //# Print Output\n",
    "  for(int i=0; i<N; i++) std::cout << data[i] << \"\\n\";\n",
    "\n",
    "  free(data, q);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click Run ▶ to compile and execute the code above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_simple.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_simple.sh; else ./run_simple.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYCL\n",
    "__SYCL__ (pronounced ‘sickle’) represents an industry standardization effort that includes\n",
    "support for data-parallel programming for C++. It is summarized as “C++ Single-source\n",
    "Heterogeneous Programming for OpenCL.” The SYCL standard, like OpenCL*, is managed\n",
    "by the __Khronos Group*__.\n",
    "\n",
    "SYCL is a cross-platform abstraction layer that builds on OpenCL. It enables code\n",
    "for heterogeneous processors to be written in a “single source” style using C++. This is not\n",
    "only useful to the programmers, but it also gives a compiler the ability to analyze and\n",
    "optimize across the entire program regardless of the device on which the code is to be run.\n",
    "\n",
    "Unlike OpenCL, SYCL includes templates and lambda functions to enable higher-level application software to be cleanly coded with optimized acceleration of kernel code.\n",
    "Developers program at a higher level than OpenCL but always have access to lower-level code through seamless integration with OpenCL, as well as C/C++ libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Parallel C++\n",
    "__Data Parallel C++ (DPC++)__ is oneAPI's implementation of SYCL compiler. It takes advantage of modern C++ productivity benefits and familiar constructs, and incorporates the __SYCL*__ standard for data parallelism and heterogeneous programming. SYCL is a __single source__ language where host code and __heterogeneous accelerator kernels__ can be mixed in same source files. A SYCL program is invoked on the host computer and offloads the computation to an accelerator. Programmers use familiar C++ and library constructs with added functionalities like a __queue__ for work targeting, __buffer__ for data management, and __parallel_for__ for parallelism to direct which parts of the computation and data should be offloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPC++ extends SYCL\n",
    "DPC++ programs __enhance productivity__. Simple things should be simple to express and lower verbosity and programmer burden. They also __enhance performance__ by giving programmers control over program execution and by enabling hardware-specific features. It is a fast-moving open collaboration feeding into the __SYCL* standard__, and is an __open source__ implementation with the goal of upstreaming LLVM and DPC++ extensions to become core __SYCL*__, or __Khronos*__ extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPC Single Node Workflow with oneAPI \n",
    "Accelerated code can be written in either a kernel (SYCL) or __directive-based style__. Developers can use the __Intel® DPC++ Compatibility tool__ to perform a one-time migration from __CUDA__ to __SYCL__. Existing __Fortran__ applications can use a __directive-based style in OpenMP__. Existing __C++__ applications can choose either the __Kernel style__ or the __directive-based style option__ and existing __OpenCL__ applications can remain in the OpenCL language or migrate to SYCL.\n",
    "\n",
    "__Intel® Advisor__ is recommended to  __Optimize__ the design for __vectorization and memory__ (CPU and GPU) and __Identify__ loops that are candidates for __offload__ and project the __performance on target accelerators.__\n",
    "\n",
    "The figure below shows the recommended approach of different starting points for HPC developers:\n",
    "\n",
    "\n",
    "<img src=\"Assets/workflow.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oneAPI Programming models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform Model\n",
    "\n",
    "The platform model for oneAPI is based upon the SYCL* platform model. It specifies a host controlling one or more devices. A host is the computer, typically a CPU-based system executing the primary portion of a program, specifically the application scope and the command group scope. \n",
    "\n",
    "The host coordinates and controls the compute work that is performed on the devices. A device is an accelerator, a specialized component containing compute resources that can quickly execute a subset of operations typically more efficiently than the CPUs in the system. Each device contains one or more compute units that can execute several operations in parallel. Each compute unit contains one or more processing elements that serve as the individual engine for computation.\n",
    "\n",
    "The following figure provides a visual depiction of the relationships in the platform model. One host communicates with one or more devices. Each device can contain one or more compute units. Each compute unit can contain one or more processing elements. In this example, the CPU in a desktop computer is the host and it can also be made available as a device in a platform configuration.\n",
    "\n",
    "<img src=\"Assets/plat30.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Model\n",
    "\n",
    "The execution model is based upon the SYCL* execution model. It defines and specifies how code, termed kernels, execute on the devices and interact with the controlling host.\n",
    "The host execution model coordinates execution and data management between the host and devices via command groups. The command groups, which are groupings of commands like kernel invocation and accessors, are submitted to queues for execution.\n",
    "\n",
    "Accessors, which are formally part of the memory model, also communicate ordering requirements of execution. A program employing the execution model declares and instantiates queues. Queues can execute with an in-order or out-of-order policy controllable by the program. In-order execution is an Intel extension.\n",
    "\n",
    "The device execution model specifies how computation is accomplished on the accelerator. Compute ranging from small one-dimensional data to large multidimensional data sets are allocated across a hierarchy of ND-ranges, work-groups, sub-groups (Intel extension), and work-items, which are all specified when the work is submitted to the command queue.\n",
    "\n",
    "It is important to note that the actual kernel code represents the work that is executed for one work-item. The code outside of the kernel controls just how much parallelism is executed; the amount and distribution of the work is controlled by specification of the sizes of the ND-range and work-group.\n",
    "\n",
    "\n",
    "The following figure depicts the relationship between an ND-range, work-group, sub-group, and work-item. The total amount of work is specified by the ND-range size. The grouping of the work is specified by the work-group size. The example shows the ND-range size of X * Y * Z, work-group size of X’ * Y’ * Z’, and subgroup size of X’. Therefore, there are X * Y * Z work-items. There are (X * Y * Z) / (X’ * Y’ * Z’) work-groups and (X * Y * Z) / X’ subgroups.\n",
    "\n",
    "<img src=\"Assets/kernel30.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Model\n",
    "\n",
    "The memory model for oneAPI is based upon the SYCL* memory model. It defines how the host and devices interact with memory. It coordinates the allocation and management of memory between the host and devices. The memory model is an abstraction that aims to generalize across and be adaptable to the different possible host and device configurations.\n",
    "\n",
    "In this model, memory resides upon and is owned by either the host or the device and is specified by declaring a memory object. There are two different types of memory objects, buffers and images. Interaction of these memory objects between the host and device is accomplished via an accessor, which communicates the desired location of access, such as host or device, and the particular mode of access, such as read or write.\n",
    "\n",
    "Consider a case where memory is allocated on the host through a traditional malloc call. Once the memory is allocated on the host, a buffer object is created, which enables the host allocated memory to be communicated to the device. The buffer class communicates the type and number of items of that type to be communicated to the device for computation. Once a buffer is created on the host, the type of access allowed on the device is communicated via an accessor object, which specifies the type of access to the buffer.\n",
    "\n",
    "<img src=\"Assets/memory.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Programming Model\n",
    "The kernel programming model for oneAPI is based upon the SYCL* kernel programming model. It enables explicit parallelism between the host and device. The parallelism is explicit in the sense that the programmer determines what code executes on the host and device; it is not automatic. The kernel code executes on the accelerator. \n",
    "\n",
    "Programs employing the oneAPI programming model support single source, meaning the host code and device code can be in the same source file. However, there are differences between the source code accepted in the host code and the device code with respect to language conformance and language features. \n",
    "\n",
    "The SYCL Specification defines in detail the required language features for host code and device code. The following is a summary that is specific to the oneAPI product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Compile & Run SYCL program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three main steps of compiling and running a SYCL program are:\n",
    "1. Initialize environment variables\n",
    "2. Compile the SYCL source code\n",
    "3. Run the application\n",
    " \n",
    "#### Compiling and Running on Intel&reg; DevCloud:\n",
    " \n",
    "For this training, we have written a script (q) to aid developers in developing projects on DevCloud. This script submits the `run.sh` script to a GPU node on DevCloud for execution, waits for the job to complete and prints out the output/errors. We will be using this command to run on DevCloud: `./q run.sh`\n",
    "\n",
    "\n",
    "\n",
    "#### Compiling and Running on a Local System:\n",
    "\n",
    "If you have installed the Intel&reg; oneAPI Base Toolkit on your local system, you can use the commands below to compile and run a SYCL program:\n",
    "\n",
    "    source /opt/intel/inteloneapi/setvars.sh\n",
    "\n",
    "    icpx -fsycl simple.cpp -o simple\n",
    "\n",
    "    ./simple\n",
    "    \n",
    "_Note: run.sh script is a combination of the three steps listec above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this module you will have learned the following:\n",
    "* How oneAPI solves the challenges of programming in a heterogeneous world \n",
    "* Take advantage of oneAPI solutions to enable your workflows\n",
    "* Use the Intel® DevCloud to test-drive oneAPI tools and libraries\n",
    "* Basics of the SYCL language and programming model\n",
    "* Become familiarized with the use of Juypter notebooks by editing of source code in context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><body><span style=\"color:green\"><h1>Survey</h1></span></body></html>\n",
    "\n",
    "[Tell us how we did in this module with a short survey. We will use your feedback to improve the quality and impact of these learning materials. Thanks!](https://intel.az1.qualtrics.com/jfe/form/SV_6m4G7BXPNSS7FBz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Check out these related resources\n",
    "\n",
    "#### Intel® oneAPI Toolkit documentation\n",
    "* [Intel® oneAPI main page](https://software.intel.com/oneapi \"oneAPI main page\")\n",
    "* [Intel® oneAPI programming guide](https://software.intel.com/sites/default/files/oneAPIProgrammingGuide_3.pdf \"oneAPI programming guide\")\n",
    "* [Intel® DevCloud Signup](https://software.intel.com/en-us/devcloud/oneapi \"Intel DevCloud\")  Sign up here if you do not have an account.\n",
    "* [Intel® DevCloud Connect](https://devcloud.intel.com/datacenter/connect)  Login to the DevCloud here.\n",
    "* [Get Started with oneAPI for Linux*](https://software.intel.com/en-us/get-started-with-intel-oneapi-linux)\n",
    "* [Get Started with oneAPI for Windows*](https://software.intel.com/en-us/get-started-with-intel-oneapi-windows)\n",
    "* [Intel® oneAPI Code Samples](https://software.intel.com/en-us/articles/code-samples-for-intel-oneapibeta-toolkits)\n",
    "* [oneAPI Specification elements](https://www.oneapi.com/spec/)\n",
    "\n",
    "#### SYCL \n",
    "* [SYCL 2020 Specification](https://www.khronos.org/registry/SYCL/specs/sycl-2020/pdf/sycl-2020.pdf)\n",
    "\n",
    "#### Modern C++\n",
    "* [CPPReference](https://en.cppreference.com/w/)\n",
    "* [CPlusPlus](http://www.cplusplus.com/)\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "525.6px",
    "left": "28px",
    "top": "137.8px",
    "width": "301.109px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
