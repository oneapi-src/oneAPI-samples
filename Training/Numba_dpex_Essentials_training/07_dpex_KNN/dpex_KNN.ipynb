{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours Algorithm Using Numba-dpex\n",
    "\n",
    "![Assets/knn2.png](Assets/knn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "- [KNN Algorithm](#KMeans-Algorithm)\n",
    "- _Code:_ [Implementation of KNN targeting CPU using Numba JIT](#Implementation-of-KNN-targeting-CPU-using-Numba-JIT)\n",
    "- _Code:_ [Implementation of KNN targeting GPU using Numba JIT](#Implementation-of-KNN-targeting-GPU-using-Numba-JIT)\n",
    "- _Code:_ [Implementation of KNN targeting GPU using Kernels](#Implementation-of-KNN-targeting-GPU-using-Kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Build a Numba implementation of KNN targeting CPU and GPU using Numba JIT\n",
    "* Build a Numba-dpex implementation of KNN on CPU and GPU using kernel approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numba-dpex\n",
    "\n",
    "Numba-dpex is a standalone extension to the Numba JIT compiler that adds SYCL programming capabilities to Numba. Numba-dpex is packaged as part of the IDP that comes with oneAPI base toolkit, and you don’t need to install any specific Conda packages. The support for SYCL is via SYCL runtime and other SYCL compilers are not supported by Numba-dpex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line parameters\n",
    "\n",
    "| Type | Default Value | Description |\n",
    "|:---|:---|:---|\n",
    "| --steps | 10 | Number of workload runs |\n",
    "| --step | 2  | Data growth factor on each iteration |\n",
    "| --size | 2 ** 28 | Initial data size |\n",
    "| --repeat | 1 | Iterations inside measured region |\n",
    "| --json | False | Output json data filename |\n",
    "| -d | 1 | Data Dimension |\n",
    "| --usm | False | Use USM Shared |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KNN Algorithm\n",
    "KNN is a supervised ML algorithm that based on similar patters where the items are placed closer to each other. Supervised machine learning involves situations where there is a known outcome from historical data. ​ The goal is to take a small subset of data to learn how to predict these outcomes so that the same method can be applied later to predict outcomes for as yet unseen data. For supervised learning, you need both “X”, the feature data, as well as “y” data, also known as a target variable.\n",
    "\n",
    "Classification routines are typically used to analyze features of a dataset. Think of these as columns of data in a spreadsheet, and to find patterns among the data in order to predict or classify a target variable, think of this as a single column (typically) that we might call the “y” value. In classification, the “y” value is usually a discrete variable – such as “tumor”, “no tumor”. Another example might be “cat” versus “dog” versus “bird”. \n",
    "\n",
    "In Regression problems, outcome is a continuous number​ For example, house prices, box office revenue, attendance to an event etc. \n",
    "\n",
    "KNN is a simple and powerful ML algorithm that places similar items together. We need model data with features that can be quantitated, labels that are known and method to measure similarity.\n",
    "\n",
    "In KNN the first thing we need is the correctly determined value of k. Second we need to know how to measure the distance of neighbors using for example L2 distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of KNN using Numba JIT\n",
    "In the following example, we introduce a naive KNN implementation that targets a CPU using the Numba JIT.\n",
    "\n",
    "This is the decorator-based approach, where we offload data parallel code sections like parallel-for, and certain NumPy function calls. With the decorator method, a programmer needs to simply identify the most time-consuming parts of the program. If those parts can be parallelized, the programmer needs to annotate those sections using Numba-dpex, and can expect those code sections to execute on a GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/knn_jit.py\n",
    "import base_knn_jit\n",
    "import numpy as np\n",
    "\n",
    "import numba\n",
    "from numba import jit, njit, vectorize\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def euclidean_dist(x1, x2):\n",
    "    distance = 0\n",
    "\n",
    "    for i in range(len(x1)):\n",
    "        diff = x1[i] - x2[i]\n",
    "        distance += diff * diff\n",
    "\n",
    "    result = distance**0.5\n",
    "    # result = np.sqrt(distance)\n",
    "    return result\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def push_queue(queue_neighbors, new_distance, index=4):\n",
    "    while index > 0 and new_distance[0] < queue_neighbors[index - 1][0]:\n",
    "        queue_neighbors[index] = queue_neighbors[index - 1]\n",
    "        index = index - 1\n",
    "        queue_neighbors[index] = new_distance\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def sort_queue(queue_neighbors):\n",
    "    for i in range(len(queue_neighbors)):\n",
    "        push_queue(queue_neighbors, queue_neighbors[i], i)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def simple_vote(neighbors, classes_num=3):\n",
    "    votes_to_classes = np.zeros(classes_num)\n",
    "\n",
    "    for neighbor in neighbors:\n",
    "        votes_to_classes[neighbor[1]] += 1\n",
    "\n",
    "    max_ind = 0\n",
    "    max_value = 0\n",
    "\n",
    "    for i in range(classes_num):\n",
    "        if votes_to_classes[i] > max_value:\n",
    "            max_value = votes_to_classes[i]\n",
    "            max_ind = i\n",
    "\n",
    "    return max_ind\n",
    "\n",
    "\n",
    "@jit(nopython=True, parallel=True)\n",
    "def run_knn(train, train_labels, test, k=5, classes_num=3):\n",
    "    test_size = len(test)\n",
    "    train_size = len(train)\n",
    "\n",
    "    predictions = np.empty(test_size)\n",
    "\n",
    "    for i in numba.prange(test_size):\n",
    "        queue_neighbors = []\n",
    "\n",
    "        for j in range(k):\n",
    "            dist = euclidean_dist(train[j], test[i])\n",
    "            # queue_neighbors[j] = (dist, train_labels[j])\n",
    "            queue_neighbors.append((dist, train_labels[j]))\n",
    "\n",
    "        sort_queue(queue_neighbors)\n",
    "\n",
    "        for j in range(k, train_size):\n",
    "            dist = euclidean_dist(train[j], test[i])\n",
    "            new_neighbor = (dist, train_labels[j])\n",
    "\n",
    "            if dist < queue_neighbors[k - 1][0]:\n",
    "                queue_neighbors[k - 1] = new_neighbor\n",
    "                push_queue(queue_neighbors, new_neighbor)\n",
    "\n",
    "        predictions[i] = simple_vote(queue_neighbors, classes_num)\n",
    "\n",
    "    return predictions\n",
    "base_knn_jit.run(\"K-Nearest-Neighbors Numba\", run_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_knn_cpu.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_knn_cpu.sh; else ./run_knn_cpu.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_If the Jupyter cells are not responsive or if they error out when you compile the code samples, please restart the Jupyter Kernel: \n",
    "\"Kernel->Restart Kernel and Clear All Outputs\" and compile the code samples again__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of KNN targeting GPU using Kernels\n",
    "\n",
    "## Writing Explicit Kernels in numba-dpex\n",
    "\n",
    "Writing a SYCL kernel using the `@numba_dpex.kernel` decorator has similar syntax to writing OpenCL kernels. As such, the numba-dpex module provides similar indexing and other functions as OpenCL. The indexing functions supported inside a `numba_dpex.kernel` are:\n",
    "\n",
    "* numba_dpex.get_local_id : Gets the local ID of the item\n",
    "* numba_dpex.get_local_size: Gets the local work group size of the device\n",
    "* numba_dpex.get_group_id : Gets the group ID of the item\n",
    "* numba_dpex.get_num_groups: Gets the number of gropus in a worksgroup\n",
    "\n",
    "Refer https://intelpython.github.io/numba-dpex/latest/user_guides/kernel_programming_guide/index.html for more details.\n",
    "\n",
    "In the following example we use the dpex-kernel approach for explicit kernel programming where, if the programmer wants to extract further performance from the offloaded code, the programmer can use the explicit kernel programming approach using dpex-kernels, and tune the GPU parameters where we take advantage of the work groups and the work items in a device using the kernel approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inspect the code cell below and click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/knn_kernel.py\n",
    "# SPDX-FileCopyrightText: 2022 - 2023 Intel Corporation\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "from math import sqrt\n",
    "import base_knn\n",
    "\n",
    "import numba_dpex as dpex\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dpex.kernel\n",
    "def _knn_kernel(  # noqa: C901: TODO: can we simplify logic?\n",
    "    train,\n",
    "    train_labels,\n",
    "    test,\n",
    "    k,\n",
    "    classes_num,\n",
    "    train_size,\n",
    "    predictions,\n",
    "    votes_to_classes_lst,\n",
    "    data_dim,\n",
    "):\n",
    "    dtype = train.dtype\n",
    "    i = dpex.get_global_id(0)\n",
    "    # here k has to be 5 in order to match with numpy\n",
    "    queue_neighbors = dpex.private.array(shape=(5, 2), dtype=dtype)\n",
    "\n",
    "    for j in range(k):\n",
    "        x1 = train[j]\n",
    "        x2 = test[i]\n",
    "\n",
    "        distance = dtype.type(0.0)\n",
    "        for jj in range(data_dim):\n",
    "            diff = x1[jj] - x2[jj]\n",
    "            distance += diff * diff\n",
    "        dist = sqrt(distance)\n",
    "\n",
    "        queue_neighbors[j, 0] = dist\n",
    "        queue_neighbors[j, 1] = train_labels[j]\n",
    "\n",
    "    for j in range(k):\n",
    "        new_distance = queue_neighbors[j, 0]\n",
    "        new_neighbor_label = queue_neighbors[j, 1]\n",
    "        index = j\n",
    "\n",
    "        while index > 0 and new_distance < queue_neighbors[index - 1, 0]:\n",
    "            queue_neighbors[index, 0] = queue_neighbors[index - 1, 0]\n",
    "            queue_neighbors[index, 1] = queue_neighbors[index - 1, 1]\n",
    "\n",
    "            index = index - 1\n",
    "\n",
    "            queue_neighbors[index, 0] = new_distance\n",
    "            queue_neighbors[index, 1] = new_neighbor_label\n",
    "\n",
    "    for j in range(k, train_size):\n",
    "        x1 = train[j]\n",
    "        x2 = test[i]\n",
    "\n",
    "        distance = dtype.type(0.0)\n",
    "        for jj in range(data_dim):\n",
    "            diff = x1[jj] - x2[jj]\n",
    "            distance += diff * diff\n",
    "        dist = sqrt(distance)\n",
    "\n",
    "        if dist < queue_neighbors[k - 1][0]:\n",
    "            queue_neighbors[k - 1][0] = dist\n",
    "            queue_neighbors[k - 1][1] = train_labels[j]\n",
    "            new_distance = queue_neighbors[k - 1, 0]\n",
    "            new_neighbor_label = queue_neighbors[k - 1, 1]\n",
    "            index = k - 1\n",
    "\n",
    "            while index > 0 and new_distance < queue_neighbors[index - 1, 0]:\n",
    "                queue_neighbors[index, 0] = queue_neighbors[index - 1, 0]\n",
    "                queue_neighbors[index, 1] = queue_neighbors[index - 1, 1]\n",
    "\n",
    "                index = index - 1\n",
    "\n",
    "                queue_neighbors[index, 0] = new_distance\n",
    "                queue_neighbors[index, 1] = new_neighbor_label\n",
    "\n",
    "    votes_to_classes = votes_to_classes_lst[i]\n",
    "\n",
    "    for j in range(len(queue_neighbors)):\n",
    "        votes_to_classes[int(queue_neighbors[j, 1])] += 1\n",
    "\n",
    "    max_ind = 0\n",
    "    max_value = dtype.type(0)\n",
    "\n",
    "    for j in range(classes_num):\n",
    "        if votes_to_classes[j] > max_value:\n",
    "            max_value = votes_to_classes[j]\n",
    "            max_ind = j\n",
    "\n",
    "    predictions[i] = max_ind\n",
    "\n",
    "\n",
    "def knn(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    k,\n",
    "    classes_num,\n",
    "    test_size,\n",
    "    train_size,\n",
    "    predictions,\n",
    "    votes_to_classes,\n",
    "    data_dim,\n",
    "):\n",
    "    _knn_kernel[test_size,](\n",
    "        x_train,\n",
    "        y_train,\n",
    "        x_test,\n",
    "        k,\n",
    "        classes_num,\n",
    "        train_size,\n",
    "        predictions,\n",
    "        votes_to_classes,\n",
    "        data_dim,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_knn_kernel.sh; if [ -x \"$(command -v qsub)\" ]; then ./q  run_knn_kernel.sh; else ./run_knn_kernel.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot GPU Results\n",
    "\n",
    "Below sample runs the KNN algorithm on the GPU and plots the points based on input data and the test data.\n",
    "\n",
    "Here’s an example that runs the KNN algorithm using numba-dpex on a GPU and plots the centroids with the cluster of points:\n",
    "\n",
    "1. Inspect the code cell below and click run ▶ to save the code to a file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### View the results\n",
    "Select the cell below and click run ▶ to view the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import joblib\n",
    "def read_dictionary(fn):\n",
    "    import joblib\n",
    "    # Load data (deserialize)\n",
    "    with open(fn, 'rb') as handle:\n",
    "        dictionary = joblib.load(handle)\n",
    "    return dictionary\n",
    "resultsDict = read_dictionary('resultsDict_knn.dat')\n",
    "limit = 5\n",
    "from matplotlib import pyplot as plt\n",
    "predictions = resultsDict['predictions']\n",
    "votes_to_classes_lst = resultsDict['votes_to_classes_lst']\n",
    "xC = resultsDict['xC']\n",
    "yC = resultsDict['yC']\n",
    "zC = resultsDict['zC']\n",
    "xtest = resultsDict['xtest']\n",
    "ytest = resultsDict['ytest']\n",
    "\n",
    "plt.style.use('default')\n",
    "#plt.style.use('dark_background')\n",
    "\n",
    "print(predictions[0])\n",
    "print(predictions[1])\n",
    "print(predictions[2])\n",
    "print(predictions[3])\n",
    "print(predictions[4])\n",
    "print(predictions[5])\n",
    "print(predictions[6])\n",
    "print(predictions[7])\n",
    "print(predictions[8])\n",
    "print(predictions[9])\n",
    "\n",
    "plt.scatter(x=xC[:100], y=yC[:100],s=75,  c='r', edgecolor=\"k\")\n",
    "plt.scatter(x=xtest[:10], y=ytest[:10],s=150,  c='b', edgecolor=\"k\")\n",
    "#plt.scatter(x=predictions[:100], y=predictions[:100],s=75,  c='b', edgecolor=\"k\")\n",
    "\n",
    "plt.title('KNN')\n",
    "\n",
    "#plt.grid()\n",
    "plt.gcf().set_size_inches((16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this module you will have learned the following:\n",
    "* Numba implementation of KNN using Numba JIT\n",
    "* Numba-dpex implementation of KNN on GPU using the kernel approach\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "525.6px",
    "left": "28px",
    "top": "137.8px",
    "width": "301.09px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
