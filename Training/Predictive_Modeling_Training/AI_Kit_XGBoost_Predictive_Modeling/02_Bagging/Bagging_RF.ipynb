{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Objectives\n",
    "\n",
    "- Determine if stratefiedshuffle split is the best approach\n",
    "- Recognize how to identify the optimal number of trees\n",
    "- Understand the resulting plot of out-of-band errors\n",
    "- Explore Random Forest vs Extra Random Trees and determine which one worked better\n",
    "- Apply IntelÂ® Extension for Scikit-learn* to leverage underlying compute capabilities of hardware\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will use the wine quality data set again and compare our results to the decion tree results. This data set contains various chemical properties of wine, such as acidity, sugar, pH, and alcohol. It also contains a quality metric (3-9, with highest being better) and a color (red or white). The name of the file is `Wine_Quality_Data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.080220Z",
     "start_time": "2021-09-17T09:30:43.065481Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']\n",
    "\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "#unpatch_sklearn()\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image, display\n",
    "import time\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "* Import the data and examine the features.\n",
    "* We will be using all of them to predict `color` (white or red), but the colors feature will need to be integer encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.096180Z",
     "start_time": "2021-09-17T09:30:44.082012Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "filepath = os.sep.join(data_path + ['Wine_Quality_Data.csv'])\n",
    "data = pd.read_csv(filepath, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.128177Z",
     "start_time": "2021-09-17T09:30:44.100135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine the top 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.144136Z",
     "start_time": "2021-09-17T09:30:44.130134Z"
    }
   },
   "outputs": [],
   "source": [
    "# What types of data do we have?\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows of data are there?\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the color feature to an integer. This is a quick way to do it using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.160135Z",
     "start_time": "2021-09-17T09:30:44.146134Z"
    }
   },
   "outputs": [],
   "source": [
    "data['color'] = data.color.replace('white',0).replace('red',1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "* Examine distribution of the predicted variable (`color`).\n",
    "* Split the data into train and test sets. Again use __StratefiedShuffleSplit__\n",
	"* Note: you are expected to solve this exercise by replacing the 'xxx' in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.176134Z",
     "start_time": "2021-09-17T09:30:44.162138Z"
    }
   },
   "outputs": [],
   "source": [
    "# All data columns except for color\n",
    "feature_cols = [x for x in data.columns if x not in 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.207056Z",
     "start_time": "2021-09-17T09:30:44.177134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into two parts with 1000 points in the test data\n",
    "# This creates a generator\n",
    "strat_shuff_split = xxx(n_splits=1, test_size=1000, random_state=42)\n",
    "\n",
    "# Get the index values from the generator\n",
    "train_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data['color']))\n",
    "\n",
    "# Create the data sets\n",
    "X_train = data.loc[train_idx, feature_cols]\n",
    "y_train = data.loc[train_idx, 'color']\n",
    "\n",
    "X_test = data.loc[test_idx, feature_cols]\n",
    "y_test = data.loc[test_idx, 'color']\n",
    "\n",
    "strat_shuff_split.get_n_splits(X_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the percent composition of each quality level in the train and test data sets. The data set is mostly white wine, as can be seen below. 0 for white 1 for red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.238224Z",
     "start_time": "2021-09-17T09:30:44.209035Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T09:30:44.254277Z",
     "start_time": "2021-09-17T09:30:44.240222Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "* Fit random forest models with a range of tree numbers and evaluate the out-of-bag error for each of these models.\n",
    "* Plot the resulting oob errors as a function of the number of trees.\n",
    "\n",
    "*Hint:* since the only thing changing is the number of trees, the `warm_start` flag can be used so that the model just adds more trees to the existing model each time. Use the `set_params` method to update the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings about too few trees from the early models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "unpatch_sklearn\n",
    "#patch_sklearn()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the random forest estimator\n",
    "# Note that the number of trees is not setup here\n",
    "RF = RandomForestClassifier(oob_score=True, \n",
    "                            random_state=42, \n",
    "                            warm_start=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    "# Iterate through all of the possibilities for number of trees.  \n",
    "for n_trees in [25, 50, 100, x, x, x, x]:\n",
    "    \n",
    "    # Use this to set the number of trees\n",
    "    RF.set_params(n_estimators=n_trees)\n",
    "    \n",
    "    # Time fit function\n",
    "    t = time.process_time()\n",
    "\n",
    "    # Fit the model\n",
    "    RF.fit(X_train, y_train)\n",
    "    elapsed_time = time.process_time() - t\n",
    "    \n",
    "    # Get the oob error\n",
    "    oob_error = 1 - RF.oob_score_\n",
    "    \n",
    "    # Store it\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "rf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "print (\"It took\",elapsed_time,\" to fit.\")\n",
    "\n",
    "rf_oob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where has the error stabilized?  Plot the out of bag error to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_palette('dark')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = rf_oob_df.plot(legend=False, marker='o')\n",
    "ax.set(ylabel='out-of-bag error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "* Repeat question 3 using extra randomized trees __ExtraTreesClassifier__. Note that the `bootstrap` parameter will have to be set to `True` for this model.\n",
    "* Compare the out-of-bag errors for the two different types of models.\n",
	"* Note: you are expected to solve this exercise by replacing the 'xxx' in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize the random forest estimator\n",
    "# Note that the number of trees is not setup here\n",
    "EF = xxx(oob_score=True, \n",
    "                          random_state=42, \n",
    "                          warm_start=True,\n",
    "                          bootstrap=True,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "oob_list = list()\n",
    "\n",
    "# Iterate through all of the possibilities for \n",
    "# number of trees\n",
    "for n_trees in [x,x,x, 150, 200, 300, 400]:\n",
    "    \n",
    "    # Use this to set the number of trees\n",
    "    EF.set_params(n_estimators=n_trees)\n",
    "    \n",
    "    # Time fit function\n",
    "    t = time.process_time()\n",
    "    EF.fit(X_train, y_train)\n",
    "    elapsed_time = time.process_time() - t\n",
    "    \n",
    "    # oob error\n",
    "    oob_error = 1 - EF.oob_score_\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "et_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "\n",
    "et_oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_df = pd.concat([rf_oob_df.rename(columns={'oob':'RandomForest'}),\n",
    "                    et_oob_df.rename(columns={'oob':'ExtraTrees'})], axis=1)\n",
    "\n",
    "oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"It took\",elapsed_time,\"to fit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think the extra trees out performed the RandomForest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_palette('dark')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = oob_df.plot(marker='o')\n",
    "ax.set(ylabel='out-of-bag error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "* Select one of the models that performs well and calculate error metrics and a confusion matrix on the test data set. \n",
    "* Given the distribution of the predicted class, which metric is most important? Which could be deceiving?\n",
	"* Note: you are expected to solve this exercise by replacing the 'xxx' in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest with extra trees 50 estimators\n",
    "model = RF.set_params(n_estimators=50)\n",
    "t = time.process_time()\n",
    "y_pred = model.predict(X_test)\n",
    "elapsed_time = time.process_time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"It took\",elapsed_time,\"seconds to predict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)\n",
    "\n",
    "score_df = pd.DataFrame({'accuracy': accuracy_score(y_test, y_pred),\n",
    "                         'precision': precision_score(y_test, y_pred),\n",
    "                         'recall': recall_score(y_test, y_pred),\n",
    "                         'f1': f1_score(y_test, y_pred),\n",
    "                         'auc': roc_auc_score(y_test, y_pred)},\n",
    "                         index=pd.Index([0]))\n",
    "\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n",
    "\n",
    "sns.set_context('talk')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
    "\n",
    "labels = ['False', 'True']\n",
    "ax.set_xticklabels(labels);\n",
    "ax.set_yticklabels(labels[::-1]);\n",
    "ax.set_ylabel('Prediction');\n",
    "ax.set_xlabel('Ground Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "fig, axList = plt.subplots(ncols=2)\n",
    "fig.set_size_inches(11, 5)\n",
    "\n",
    "# Get the probabilities for each of the two categories\n",
    "y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Plot the ROC-AUC curve\n",
    "ax = axList[0]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])\n",
    "ax.plot(fpr, tpr)\n",
    "# It is customary to draw a diagonal dotted line in ROC plots.\n",
    "# This is to indicate completely random prediction. Deviation from this\n",
    "# dotted line towards the upper left corner signifies the power of the model.\n",
    "ax.plot([0, 1], [0, 1], ls='--', color='black', lw=.3)\n",
    "ax.set(xlabel='False Positive Rate',\n",
    "       ylabel='True Positive Rate',\n",
    "       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n",
    "       title='ROC curve')\n",
    "ax.grid(True)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "ax = axList[1]\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob[:,1])\n",
    "ax.plot(recall, precision)\n",
    "ax.set(xlabel='Recall', ylabel='Precision',\n",
    "       xlim=[-.01, 1.01], ylim=[-.01, 1.01],\n",
    "       title='Precision-Recall curve')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which feature was most important, plot the biggest predictor. Use feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model.xxx, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "ax = feature_imp.plot(kind='bar')\n",
    "ax.set(ylabel='Relative Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
