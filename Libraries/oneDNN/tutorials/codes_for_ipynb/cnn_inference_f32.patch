--- cnn_inference_f32.cpp	2020-02-12 10:12:10.467690007 -0800
+++ cnn_inference_f32_gpu.cpp	2020-02-12 10:12:28.395690295 -0800
@@ -19,12 +19,62 @@
             std::multiplies<memory::dim>());
 }
 
+
+// ------ GPU code conversion --Step 2 >>>>>>
+// Read from handle, write to memory
+inline void write_to_dnnl_memory(void *handle, dnnl::memory &mem) {
+
+    dnnl::engine eng = mem.get_engine();
+    size_t size = mem.get_desc().get_size();
+
+    bool is_cpu_sycl = (DNNL_CPU_RUNTIME == DNNL_RUNTIME_SYCL
+            && eng.get_kind() == dnnl::engine::kind::cpu);
+    bool is_gpu_sycl = (DNNL_GPU_RUNTIME == DNNL_RUNTIME_SYCL
+            && eng.get_kind() == dnnl::engine::kind::gpu);
+    if (is_cpu_sycl || is_gpu_sycl) {
+
+        auto buffer = mem.get_sycl_buffer<uint8_t>();
+        auto dst = buffer.get_access<cl::sycl::access::mode::write>();
+        uint8_t *dst_ptr = dst.get_pointer();
+
+        if (!dst_ptr || !handle) {
+            std::cerr << "memory is NULL"
+                      << "\n";
+            return;
+        }
+        for (size_t i = 0; i < size; ++i)
+            dst_ptr[i] = ((uint8_t *)handle)[i];
+        return;
+    }
+
+    if (eng.get_kind() == dnnl::engine::kind::cpu) {
+        uint8_t *dst = static_cast<uint8_t *>(mem.get_data_handle());
+        if (!dst || !handle) {
+            std::cerr << "memory is NULL"
+                      << "\n";
+            return;
+        }
+        for (size_t i = 0; i < size; ++i)
+            dst[i] = ((uint8_t *)handle)[i];
+        return;
+    }
+
+    assert(!"not expected");
+}  
+//<<<<<< ------ GPU code conversion --Step 2
+
+
+
 void simple_net(int times = 100) {
     using tag = memory::format_tag;
     using dt = memory::data_type;
 
 
-    engine eng(engine::kind::cpu, 0);
+// ------ GPU code conversion --Step 1 >>>>>>
+    engine eng(engine::kind::gpu, 0);
+//<<< <<<------ GPU code conversion --Step 1
+
+    
     stream s(eng);
 
     std::vector<primitive> net;
@@ -53,13 +103,17 @@
 //[Allocate buffers]
 
 
+// ------ GPU code conversion --Step 3 >>>>>>
     auto user_src_memory = memory(
-            { { conv1_src_tz }, dt::f32, tag::nchw }, eng, user_src.data());
+            { { conv1_src_tz }, dt::f32, tag::nchw }, eng);
+    write_to_dnnl_memory(user_src.data(), user_src_memory);
     auto user_weights_memory
-            = memory({ { conv1_weights_tz }, dt::f32, tag::oihw }, eng,
-                    conv1_weights.data());
+            = memory({ { conv1_weights_tz }, dt::f32, tag::oihw }, eng);
+    write_to_dnnl_memory(conv1_weights.data(), user_weights_memory);
     auto conv1_user_bias_memory = memory(
-            { { conv1_bias_tz }, dt::f32, tag::x }, eng, conv1_bias.data());
+            { { conv1_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(conv1_bias.data(), conv1_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
 
 
@@ -175,13 +229,18 @@
     std::vector<float> conv2_weights(product(conv2_weights_tz));
     std::vector<float> conv2_bias(product(conv2_bias_tz));
 
+
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto conv2_user_weights_memory
-            = memory({ { conv2_weights_tz }, dt::f32, tag::goihw }, eng,
-                    conv2_weights.data());
+            = memory({ { conv2_weights_tz }, dt::f32, tag::goihw }, eng);
+    write_to_dnnl_memory(conv2_weights.data(), conv2_user_weights_memory);
     auto conv2_user_bias_memory = memory(
-            { { conv2_bias_tz }, dt::f32, tag::x }, eng, conv2_bias.data());
+            { { conv2_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(conv2_bias.data(), conv2_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto conv2_src_md = memory::desc({ conv2_src_tz }, dt::f32, tag::any);
     auto conv2_bias_md = memory::desc({ conv2_bias_tz }, dt::f32, tag::any);
@@ -291,13 +350,18 @@
     std::vector<float> conv3_weights(product(conv3_weights_tz));
     std::vector<float> conv3_bias(product(conv3_bias_tz));
 
+
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto conv3_user_weights_memory
-            = memory({ { conv3_weights_tz }, dt::f32, tag::oihw }, eng,
-                    conv3_weights.data());
+            = memory({ { conv3_weights_tz }, dt::f32, tag::oihw }, eng);
+    write_to_dnnl_memory(conv3_weights.data(), conv3_user_weights_memory);
     auto conv3_user_bias_memory = memory(
-            { { conv3_bias_tz }, dt::f32, tag::x }, eng, conv3_bias.data());
+            { { conv3_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(conv3_bias.data(), conv3_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto conv3_src_md = memory::desc({ conv3_src_tz }, dt::f32, tag::any);
     auto conv3_bias_md = memory::desc({ conv3_bias_tz }, dt::f32, tag::any);
@@ -364,13 +428,17 @@
     std::vector<float> conv4_weights(product(conv4_weights_tz));
     std::vector<float> conv4_bias(product(conv4_bias_tz));
 
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto conv4_user_weights_memory
-            = memory({ { conv4_weights_tz }, dt::f32, tag::goihw }, eng,
-                    conv4_weights.data());
+            = memory({ { conv4_weights_tz }, dt::f32, tag::goihw }, eng);
+    write_to_dnnl_memory(conv4_weights.data(), conv4_user_weights_memory);
     auto conv4_user_bias_memory = memory(
-            { { conv4_bias_tz }, dt::f32, tag::x }, eng, conv4_bias.data());
+            { { conv4_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(conv4_bias.data(), conv4_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto conv4_src_md = memory::desc({ conv4_src_tz }, dt::f32, tag::any);
     auto conv4_bias_md = memory::desc({ conv4_bias_tz }, dt::f32, tag::any);
@@ -436,13 +504,18 @@
     std::vector<float> conv5_weights(product(conv5_weights_tz));
     std::vector<float> conv5_bias(product(conv5_bias_tz));
 
+
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto conv5_user_weights_memory
-            = memory({ { conv5_weights_tz }, dt::f32, tag::goihw }, eng,
-                    conv5_weights.data());
+            = memory({ { conv5_weights_tz }, dt::f32, tag::goihw }, eng);
+    write_to_dnnl_memory(conv5_weights.data(), conv5_user_weights_memory);
     auto conv5_user_bias_memory = memory(
-            { { conv5_bias_tz }, dt::f32, tag::x }, eng, conv5_bias.data());
+            { { conv5_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(conv5_bias.data(), conv5_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto conv5_src_md = memory::desc({ conv5_src_tz }, dt::f32, tag::any);
     auto conv5_weights_md
@@ -532,13 +605,18 @@
     std::vector<float> fc6_weights(product(fc6_weights_tz));
     std::vector<float> fc6_bias(product(fc6_bias_tz));
 
+
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto fc6_user_weights_memory
-            = memory({ { fc6_weights_tz }, dt::f32, tag::oihw }, eng,
-                    fc6_weights.data());
+            = memory({ { fc6_weights_tz }, dt::f32, tag::oihw }, eng);
+    write_to_dnnl_memory(fc6_weights.data(), fc6_user_weights_memory);
     auto fc6_user_bias_memory = memory(
-            { { fc6_bias_tz }, dt::f32, tag::x }, eng, fc6_bias.data());
+            { { fc6_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(fc6_bias.data(), fc6_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto fc6_src_md = memory::desc({ fc6_src_tz }, dt::f32, tag::any);
     auto fc6_bias_md = memory::desc({ fc6_bias_tz }, dt::f32, tag::any);
@@ -583,13 +661,18 @@
     std::vector<float> fc7_weights(product(fc7_weights_tz));
     std::vector<float> fc7_bias(product(fc7_bias_tz));
 
+
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto fc7_user_weights_memory = memory(
-            { { fc7_weights_tz }, dt::f32, tag::nc }, eng, fc7_weights.data());
-
+            { { fc7_weights_tz }, dt::f32, tag::nc }, eng);
+    write_to_dnnl_memory(fc7_weights.data(), fc7_user_weights_memory);
     auto fc7_user_bias_memory = memory(
-            { { fc7_bias_tz }, dt::f32, tag::x }, eng, fc7_bias.data());
-
+            { { fc7_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(fc7_bias.data(), fc7_user_bias_memory);
+//<<<<<< ------ GPU code conversion --Step 3
+ 
+    
     // create memory descriptors for convolution data w/ no specified format
     auto fc7_bias_md = memory::desc({ fc7_bias_tz }, dt::f32, tag::any);
     auto fc7_weights_md = memory::desc({ fc7_weights_tz }, dt::f32, tag::any);
@@ -624,14 +707,20 @@
     std::vector<float> fc8_weights(product(fc8_weights_tz));
     std::vector<float> fc8_bias(product(fc8_bias_tz));
 
+// ------ GPU code conversion --Step 3 >>>>>>
     // create memory for user data
     auto fc8_user_weights_memory = memory(
-            { { fc8_weights_tz }, dt::f32, tag::nc }, eng, fc8_weights.data());
+            { { fc8_weights_tz }, dt::f32, tag::nc }, eng);
+    write_to_dnnl_memory(fc8_weights.data(), fc8_user_weights_memory);
     auto fc8_user_bias_memory = memory(
-            { { fc8_bias_tz }, dt::f32, tag::x }, eng, fc8_bias.data());
+            { { fc8_bias_tz }, dt::f32, tag::x }, eng);
+    write_to_dnnl_memory(fc8_bias.data(), fc8_user_bias_memory);
     auto user_dst_memory = memory(
-            { { fc8_dst_tz }, dt::f32, tag::nc }, eng, user_dst.data());
-
+            { { fc8_dst_tz }, dt::f32, tag::nc }, eng);
+    write_to_dnnl_memory(user_dst.data(), user_dst_memory);
+//<<<<<< ------ GPU code conversion --Step 3
+    
+    
     // create memory descriptors for convolution data w/ no specified format
     auto fc8_bias_md = memory::desc({ fc8_bias_tz }, dt::f32, tag::any);
     auto fc8_weights_md = memory::desc({ fc8_weights_tz }, dt::f32, tag::any);
