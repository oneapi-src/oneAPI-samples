{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Copyright Â© 2020 Intel Corporation\n",
    "# \n",
    "# SPDX-License-Identifier: MIT\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daal4py Linear Regression Example for Distributed Memory Systems [SPMD mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT NOTICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using daal4py for distributed memory systems, the command needed to execute the program should be **executed \n",
    "in a bash shell**. In order to run this example, please download it as a .py file then run the following command (**the number 4 means that it will run on 4 processes**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mpirun -n 4 python ./daal4py_Distributed_LinearRegression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Organizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be predicting **prices of houses in Boston** based on the features of each house.\n",
    "\n",
    "Let's start by **importing** all necessary data and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### daal4py linear regression example for distributed memory systems [SPMD mode] #####\n",
    "import daal4py as d4p\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **load** in the dataset and **organize** it as necessary to work with our model. For distributed, every file has a unique ID.\n",
    "\n",
    "We will also **initialize the distribution engine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4p.daalinit() #initializes the distribution engine\n",
    "\n",
    "# organizing variables used in the model for prediction\n",
    "# each process gets its own data\n",
    "infile = \"./data/distributed_data/linear_regression_train_\" + str(d4p.my_procid()+1) + \".csv\"\n",
    "\n",
    "# read data\n",
    "indep_data = pd.read_csv(infile).drop([\"target\"], axis=1) # house characteristics\n",
    "dep_data   = pd.read_csv(infile)[\"target\"] # house price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to **train our model** and look at the model's features! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model for prediction\n",
    "train_result = d4p.linear_regression_training(distributed=True).compute(indep_data, dep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **get training model information** and **save it to a file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our model:\n",
      "\n",
      "\n",
      " NumberOfBetas: 15\n",
      "\n",
      "NumberOfResponses: 1\n",
      "\n",
      "InterceptFlag: False\n",
      "\n",
      "Beta: array(\n",
      "  [[ 0.00000000e+00 -1.68027665e-04 -7.40435666e-02  3.72706786e-02\n",
      "    -1.32246207e-01  5.24821226e+00 -2.09646770e+00  6.15919748e+00\n",
      "    -1.17193612e-03 -8.86515999e-01  2.23344092e-02 -1.09556173e-03\n",
      "    -4.40967972e-01  1.12216533e-02 -4.74953243e-01]],\n",
      "  dtype=float64, shape=(1, 15))\n",
      "\n",
      "NumberOfFeatures: 14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieving and printing training model\n",
    "model = train_result.model\n",
    "print(\"Here's our model:\\n\\n\\n\",model , \"\\n\")\n",
    "\n",
    "model_filename = './models/daal4py_Distributed_LinearRegression_' + str(d4p.my_procid()+1) + '.sav'\n",
    "\n",
    "# saving model to a file\n",
    "pickle.dump(model, open(model_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **load up the model** and look at one of the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is one of our loaded model's features: \n",
      "\n",
      " [[ 0.00000000e+00 -1.68027665e-04 -7.40435666e-02  3.72706786e-02\n",
      "  -1.32246207e-01  5.24821226e+00 -2.09646770e+00  6.15919748e+00\n",
      "  -1.17193612e-03 -8.86515999e-01  2.23344092e-02 -1.09556173e-03\n",
      "  -4.40967972e-01  1.12216533e-02 -4.74953243e-01]]\n"
     ]
    }
   ],
   "source": [
    "# loading the training model from a file\n",
    "loaded_model = pickle.load(open(model_filename, \"rb\"))\n",
    "print(\"Here is one of our loaded model's features: \\n\\n\",loaded_model.Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Prediction and Saving the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to **make a prediction!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_data = pd.read_csv(\"./data/distributed_data/linear_regression_test.csv\").drop([\"target\"], axis=1)\n",
    "\n",
    "# now predict using the model from the training above\n",
    "predict_result = d4p.linear_regression_prediction().compute(test_data, train_result.model).prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **export the results to a CSV file**. We will also **stop the distribution engine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\n"
     ]
    }
   ],
   "source": [
    "# now export the results to a CSV file\n",
    "results_filename = \"./results/daal4py_Distributed_LinearRegression_results\" + str(d4p.my_procid()+1) + \".csv\"\n",
    "np.savetxt(results_filename, predict_result, delimiter =  \",\")\n",
    "\n",
    "d4p.daalfini() # stops the distribution engine\n",
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
