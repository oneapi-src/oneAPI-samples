--- train_ecapa.yaml	2022-09-20 14:00:46.352900022 -0700
+++ train_ecapa_commonvoice.yaml	2022-09-20 14:12:41.278972900 -0700
@@ -4,7 +4,7 @@
 # ################################
 
 # Basic parameters
-seed: 1988
+seed: 1987
 __set_seed: !apply:torch.manual_seed [!ref <seed>]
 output_folder: !ref results/epaca/<seed>
 save_folder: !ref <output_folder>/save
@@ -12,10 +12,10 @@
 data_folder: ./
 rir_folder: !ref <data_folder>
 
-shards_url: /data/voxlingua107_shards
+shards_url: /data/commonVoice_shards
 train_meta: !ref <shards_url>/train/meta.json
 val_meta: !ref <shards_url>/dev/meta.json
-train_shards: !ref <shards_url>/train/shard-{000000..000507}.tar
+train_shards: !ref <shards_url>/train/shard-{000000..000000}.tar
 val_shards: !ref <shards_url>/dev/shard-000000.tar
 
 # Set to directory on a large disk if you are training on Webdataset shards hosted on the web
@@ -24,7 +24,7 @@
 ckpt_interval_minutes: 5
 
 # Training parameters
-number_of_epochs: 40
+number_of_epochs: 10
 lr: 0.001
 lr_final: 0.0001
 sample_rate: 16000
@@ -37,15 +37,15 @@
 deltas: False
 
 # Number of languages
-out_n_neurons: 107
+out_n_neurons: 2
 
 train_dataloader_options:
-    num_workers: 4
+    num_workers: 1
-    batch_size: 128
+    batch_size: 64
 
 val_dataloader_options:
     num_workers: 1
     batch_size: 32
 
 # Functions
 compute_features: !new:speechbrain.lobes.features.Fbank
@@ -137,3 +137,20 @@
         classifier: !ref <classifier>
         normalizer: !ref <mean_var_norm>
         counter: !ref <epoch_counter>
+
+# Below most relevant for inference using self-trained model:
+
+pretrained_path: lang_id_commonvoice_model
+
+label_encoder: !new:speechbrain.dataio.encoder.CategoricalEncoder
+
+pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
+    loadables:
+        embedding_model: !ref <embedding_model>
+        classifier: !ref <classifier>
+        label_encoder: !ref <label_encoder>
+    paths:
+        embedding_model: !ref <pretrained_path>/embedding_model.ckpt
+        classifier: !ref <pretrained_path>/classifier.ckpt
+        label_encoder: !ref <pretrained_path>/label_encoder.txt
+
