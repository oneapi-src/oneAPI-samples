{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102d565c-f70d-4e03-8a47-9892f1667032",
   "metadata": {},
   "source": [
    "# Complete your thoughts with GPT-J On Intel Xeon using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970099f-4e62-455c-9ae9-5dfe5ddd495b",
   "metadata": {},
   "source": [
    "This notebook uses HuggingFace's GPT-J model to perform text generation on Intel Xeon "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564ed5c-927c-41e2-b4e7-9e06b4b12d7b",
   "metadata": {},
   "source": [
    "## Model :GPT-J (6B)\n",
    " **[GPT-J(6B)] (https://huggingface.co/EleutherAI/gpt-j-6b): released in March 2021.\u000b",
    "\u000b",
    "It was the largest open source GPT-3-style language model in the world at the time of release.**\n",
    "\n",
    " **GPT-J is similar to ChatGPT in ability, although it does not function as a chat bot, only as a text predictor. \u000b",
    "  Developed using Mesh     Tranformer & xmap in JAX**\n",
    "\n",
    " *The model consists of :\n",
    ">\n",
    "     - 28 layers \n",
    "     - Model dimension of 4096 \n",
    "     - Feedforward dimension of 16384\n",
    "\u000b",
    "     - 16 heads, each with a dimension of 256.*\n",
    ">\n",
    "\u000b",
    "The model is trained with a tokenization vocabulary of 50257, using the same set of Byte Pair Encoding(BPEs) as GPT-2/GPT-3.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc0d016-88be-4111-92e8-f79d38e89a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-15 11:38:51.378100: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-15 11:38:51.380051: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 11:38:51.419387: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-15 11:38:51.420232: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-15 11:38:52.065827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForCausalLM\n",
    ")\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39ff9e-6948-4317-9841-ced595d4e479",
   "metadata": {},
   "source": [
    "### Get Config and Tokenizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d1e22c-4050-43fd-a477-fb9f6277e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
    "\n",
    "model_name = \"EleutherAI/gpt-j-6B\"\n",
    "max_output_tokens = 32\n",
    "\n",
    "# Initialize the text tokenizer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1faf746-e288-447f-b7f6-9528145e8663",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e76424-22f8-4386-9899-ac9c292e5122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPTJForCausalLM.\n",
      "\n",
      "All the layers of TFGPTJForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-j-6B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPTJForCausalLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the model weights\n",
    "model = TFAutoModelForCausalLM.from_pretrained(model_name, config=config)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e66df92-bb99-4e4c-b210-37001d98f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kwargs = dict(do_sample=False, num_beams=4, eos_token_id=model.config.eos_token_id)\n",
    "gen = tf.function(lambda x: model.generate(x, max_new_tokens=max_output_tokens, **generate_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4861d202-57e3-426b-aeb2-0dd4629e58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_my_thought(x):\n",
    "    tokenized_data = tokenizer([x], return_tensors=\"tf\").input_ids\n",
    "    output = gen(tokenized_data)\n",
    "    decoded = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567c85da-51a0-4424-88f3-2a17116a6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_sentence = \"This is a warmup sentence. Warmup helps get the model ready to showcase its capabilities.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70edcfa3-a906-4cf6-a5d4-f992b693a6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f3adbbe5dc0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f3adbbe5dc0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "2023-09-15 11:41:43.286767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f31a042d840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-15 11:41:43.286844: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-09-15 11:41:43.315967: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "complete_my_thought(warmup_sentence);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb754511-c933-4117-a4e5-1ae1235c20c7",
   "metadata": {},
   "source": [
    "## Start Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa40c4a-84ca-4991-a5ca-b8a0e4b0f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sentence1 = \"Ann Arbor is very pleasant in summers. The Huron river is an ideal spot for people to\"\n",
    "input_sentence2 = \"Space is an intersting place. Stephen Hawking hypothesized that there might be multiple universes in which\"\n",
    "input_sentence3 = \"In a shocking finding, scientists discovered a herd of unicorns living in a remote previously unexplored\"\n",
    "input_sentence4 = \"Coffee is one of the most popular drinks in the world. It goes very well with\"\n",
    "input_sentence5 = \"Dogs are often referred to as man's best friend. There are a number of reasons why\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18a7fcb4-e849-4e0f-98f2-a32703f1139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ann Arbor is very pleasant in summers. The Huron river is an ideal spot for people to relax and enjoy the fresh air. There are many places to visit in Ann Arbor. The University of Michigan is one of the best places to visit in Ann Arbor']\n"
     ]
    }
   ],
   "source": [
    "out = complete_my_thought(input_sentence1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a7c4fc-0085-4b29-b9a9-a37275242713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Space is an intersting place. Stephen Hawking hypothesized that there might be multiple universes in which our universe is just one of many. If this is true, then there is a possibility that we are not the only intelligent life in the universe.\\n\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_my_thought(input_sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea86315-107a-44f3-949a-2e972b58976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In a shocking finding, scientists discovered a herd of unicorns living in a remote previously unexplored part of the Amazon rainforest.\\n\\nThe discovery was made by a team of researchers from Brazil's National Institute of Amazonian Research (INPA) and\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_my_thought(input_sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69d91b8-4290-4ec6-90cc-dce27aa4571b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coffee is one of the most popular drinks in the world. It goes very well with milk and sugar, and it is a great way to start the day. But did you know that coffee can also help you lose weight?\\n\\nCoff']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_my_thought(input_sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fd82df-a4ba-4723-961a-673f56582926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Dogs are often referred to as man's best friend. There are a number of reasons why this is the case. First of all, dogs are loyal, loving, and affectionate. They are also very intelligent and can be trained to do almost anything\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_my_thought(input_sentence5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcb089-09d1-48bd-b384-967a241c1ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
