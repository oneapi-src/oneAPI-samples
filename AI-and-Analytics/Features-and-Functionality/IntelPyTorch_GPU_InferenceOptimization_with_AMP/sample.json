{
  "guid": "91B5893E-028B-47BC-9D84-395A60CC1B33",
  "name": "Intel PyTorch GPU Inference Optimization with AMP",
  "categories": ["Toolkit/oneAPI AI And Analytics/Features and Functionality"],
  "description": "This sample illustrates how to use AMP BFLOAT16 in PyTorch on Intel dGPU",
  "builder": ["cli"],
  "languages": [{"python":{}}],
  "os":["linux"],
  "targetDevice": ["GPU"],
  "gpuRequired": ["ats-m","dg2","pvc"],
  "ciTests": {
    "linux": [
    {
        "id": "intel pytorch gpu inference optimization with amp",
        "steps": [
            "source /intel/oneapi/intelpython/bin/activate",
            "source activate pytorch-gpu",
            "pip install -r requirements.txt",
            "pip install jupyter ipykernel",  
            "python -m ipykernel install --user --name=pytorch-gpu",
            "python IntelPyTorch_GPU_InferenceOptimization_with_AMP.py"
         ]
    }
     ]
  },
  "expertise": "Code Optimization"
}

