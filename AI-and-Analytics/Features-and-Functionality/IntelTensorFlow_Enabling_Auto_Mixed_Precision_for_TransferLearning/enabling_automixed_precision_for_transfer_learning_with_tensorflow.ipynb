{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81375dd4",
   "metadata": {},
   "source": [
    "# Enable Auto-Mixed Precision for Transfer Learning with TensorFlow\n",
    "\n",
    "This notebook performs the following steps:\n",
    "\n",
    "- Enable auto-mixed precision with a single-line change.\n",
    "- Transfer-Learning for Image Classification using [TensorFlow Hub's](https://www.tensorflow.org/hub) ResNet50v1.5 pretrained model.\n",
    "- Export the fine-tuned model in the [SavedModel](https://www.tensorflow.org/guide/saved_model) format.\n",
    "- Optimize the SavedModel for faster inference.\n",
    "- Serve the SavedModel using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a18431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import requests\n",
    "print(\"We are using Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b469092",
   "metadata": {},
   "source": [
    "### Identifying supported ISA\n",
    "\n",
    "We identify the underlying supported ISA to determine whether to enable auto-mixed precision to leverage higher performance benefits for training and inference as accelerated by the 4th Gen Intel® Xeon® scalable processor (codenamed Sapphire Rapids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import version_check\n",
    "\n",
    "arch = version_check.arch_checker().arch\n",
    "print(\"Arch: \", arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ab7c1",
   "metadata": {},
   "source": [
    "### Transfer Learning for Image Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfdc171",
   "metadata": {},
   "source": [
    "In this section, we use [TensorFlow Hub's](https://www.tensorflow.org/hub) pretrained [ResNet50v1.5 pretrained model](https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5) originally trained on the ImageNet dataset and perform transfer learning to fine-tune the model for your own image classes.\n",
    "\n",
    "Source: https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c7aad",
   "metadata": {},
   "source": [
    "In this example, we use the **TensorFlow Flower dataset**\n",
    "\n",
    "Loading the data in a *tf.data.Dataset* format.<br />\n",
    "We use a Batch Size of 512 images each of shape 224 x 224 x 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos',\n",
    "  'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)\n",
    "\n",
    "batch_size = 512\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = np.array(train_ds.class_names)\n",
    "print(\"The flower dataset has \" + str(len(class_names)) + \" classes: \", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e1333",
   "metadata": {},
   "source": [
    "Image Pre-processing (Normalization between 0 and 1) and using buffered prefetching to avoid I/O blocking issues.\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/data_performance#prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c544aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48374986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a3a73",
   "metadata": {},
   "source": [
    "**Simple Transfer Learning:**<br />\n",
    "    1. *Select a pre-trained model from TensorFlow Hub*.<br />\n",
    "    2. *Retrain the top (last) layer to recognize the classes from your custom dataset*.<br /><br />\n",
    "\n",
    "We use a **headless ResNet50v1.5 pretrained model** (without the classification layer). Any compatible image feature vector model from TF-Hub (https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_feature_vector = \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5\"\n",
    "\n",
    "feature_extractor_model = resnet_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c0eeb",
   "metadata": {},
   "source": [
    "Create the feature extractor by wrapping the pre-trained model as a Keras layer with **hub.KerasLayer**. Use the ***trainable=False*** argument to freeze the variables, so that the training only modifies the new classifier layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dea7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)\n",
    "\n",
    "feature_batch = feature_extractor_layer(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3eb9b",
   "metadata": {},
   "source": [
    "Attach the last fully connected classification layer in a **tf.keras.Sequential** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fead8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "fp32_model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "if arch == 'SPR':\n",
    "    # Create a deep copy of the model to train the bf16 model separately to compare accuracy\n",
    "    bf16_model = tf.keras.models.clone_model(fp32_model)\n",
    "\n",
    "fp32_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9b621",
   "metadata": {},
   "source": [
    "In order to measure the training throughput, we define the following custom callback. For more information on callbacks, refer to https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98029709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.throughput = []\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        total_time = time.time() - self.epoch_time_start\n",
    "        self.times.append(total_time)\n",
    "        self.throughput.append(batch_size/total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74bb95",
   "metadata": {},
   "source": [
    "#### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_throughput_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08629163",
   "metadata": {},
   "source": [
    "#### Train without auto-mixed precision (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae2c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "time_callback = TimeHistory()\n",
    "history = fp32_model.fit(train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=[time_callback])\n",
    "avg_throughput = sum(time_callback.throughput)/len(time_callback.throughput)\n",
    "print(\"Avg Throughput: \" + str(avg_throughput) + \" imgs/sec\")\n",
    "train_throughput_list.append(avg_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d45604",
   "metadata": {},
   "source": [
    "### Enabling auto-mixed precision with `tf.config` API\n",
    "\n",
    "In this section, we show how to enable the auto-mixed precision using the `tf.config` API. Enabling this API will automatically convert the pre-trained model to use the bfloat16 datatype for computation resulting in an increased training throughput on the latest Intel® Xeon® scalable processor.\n",
    "\n",
    "You can also print the following to see whether the auto-mixed precision has been enabled.\n",
    "\n",
    "_Note: We only enable the auto-mixed precision if the underlying system is the 4th Gen Intel® Xeon® scalable processor (codenamed Sapphire Rapids)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    tf.config.optimizer.set_experimental_options({'auto_mixed_precision_onednn_bfloat16':True})\n",
    "    print(tf.config.optimizer.get_experimental_options())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a7402",
   "metadata": {},
   "source": [
    "#### Compile and train the model with auto-mixed precision (bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    # Compile\n",
    "    bf16_model.compile(\n",
    "      optimizer=tf.keras.optimizers.SGD(),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=['acc'])\n",
    "    \n",
    "    # Train\n",
    "    NUM_EPOCHS = 10\n",
    "    time_callback = TimeHistory()\n",
    "    history = bf16_model.fit(train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=[time_callback])\n",
    "    avg_throughput = sum(time_callback.throughput)/len(time_callback.throughput)\n",
    "    print(\"Avg Throughput: \" + str(avg_throughput) + \" imgs/sec\")\n",
    "    train_throughput_list.append(avg_throughput)\n",
    "    \n",
    "    model = bf16_model\n",
    "else:\n",
    "    model = fp32_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127550b",
   "metadata": {},
   "source": [
    "Now, let's compare the throughput achieved with and without auto-mixed precision enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    import pandas as pd\n",
    "    print(train_throughput_list)\n",
    "    speedup = float(train_throughput_list[1])/float(train_throughput_list[0])\n",
    "    print(\"Speedup : \", speedup)\n",
    "    df = pd.DataFrame({'training_type':['orig', 'auto_mixed_precision'], 'Training Speedup':[1, speedup]})\n",
    "    ax = df.plot.bar( x='training_type', y='Training Speedup', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3bc65",
   "metadata": {},
   "source": [
    "### Export the model in the SavedModel format\n",
    "\n",
    "Now that you've trained the model, export it as a SavedModel for reusing it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"models/my_saved_model\"\n",
    "model.save(export_path)\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03faef",
   "metadata": {},
   "source": [
    "Let's measure the performance of the model we just saved using the `tf_benchmark.py` script that runs inference on dummy data.\n",
    "\n",
    "_Note: We only use the auto-mixed precision policy if the underlying system is the 4th Gen Intel® Xeon® scalable processor (codenamed Sapphire Rapids)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6aa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    PRECISION = \"bfloat16\"\n",
    "else:\n",
    "    PRECISION = \"float32\"\n",
    "print(\"Precision for inference: \", PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855747",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tf_benchmark.py --model_path models/my_saved_model --num_warmup 5 --num_iter 50 --precision PRECISION --batch_size 32 --disable_optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0398abd",
   "metadata": {},
   "source": [
    "### Optimize the SavedModel for faster inference\n",
    "\n",
    "To get a good performance on your (re)trained model for inference, some inference optimizations are required.\n",
    "In this section, we will guide you how to optimize a pre-trained model for better inference performance using the `freeze_optimize_v2.py` script that we put together using standard TensorFlow routines to optimize the model.\n",
    "Those optimizations includes:\n",
    "\n",
    "- Converting variables to constants\n",
    "- Removing training-only operations like checkpoint saving\n",
    "- Stripping out parts of the graph that are never reached\n",
    "- Removing debug operations like CheckNumerics\n",
    "- Folding batch normalization ops into the pre-calculated weights\n",
    "- Fusing common operations into unified versions\n",
    "\n",
    "The input to this script is the directory of original saved model, and output of this script is the directory of optimzed model. Users don't need to change below command in this tutorial, but need to put related directories after \"--input_saved_model_dir\" and \"--output_saved_model_dir\" for other pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1961932",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/freeze_optimize_v2.py --input_saved_model_dir=models/my_saved_model --output_saved_model_dir=models/my_optimized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc03ce",
   "metadata": {},
   "source": [
    "Now that we have saved the optimized model, let's measure its performance using our benchmarking script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/tf_benchmark.py --model_path models/my_optimized_model --num_warmup 5 --num_iter 50 --precision PRECISION --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd8fb5",
   "metadata": {},
   "source": [
    "**Let's compare the speedup obtained with the optimized model.**\n",
    "\n",
    "`plot.py` is a python script that creates a plot of the throughput values for inference with the original and the optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd119-ffc1-4761-a614-c2ffd83e6b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
