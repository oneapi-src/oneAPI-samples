{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81375dd4",
   "metadata": {},
   "source": [
    "# Enable Auto-Mixed Precision for Transfer Learning with TensorFlow\n",
    "\n",
    "This notebook performs the following steps:\n",
    "\n",
    "- Enable auto-mixed precision with a single-line change.\n",
    "- Transfer-Learning for Image Classification using [TensorFlow Hub's](https://www.tensorflow.org/hub) ResNet50v1.5 pretrained model.\n",
    "- Export the fine-tuned model in the [SavedModel](https://www.tensorflow.org/guide/saved_model) format.\n",
    "- Optimize the SavedModel for faster inference.\n",
    "- Serve the SavedModel using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a18431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import PIL.Image as Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from copy import deepcopy\n",
    "print(\"We are using Tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b469092",
   "metadata": {},
   "source": [
    "### Identifying supported ISA\n",
    "\n",
    "We identify the underlying supported ISA to determine whether to enable auto-mixed precision to leverage higher performance benefits for training and inference as accelerated by the 4th Gen Intel® Xeon® scalable processor (codenamed Sapphire Rapids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import version_check\n",
    "\n",
    "arch = version_check.arch_checker().arch\n",
    "print(\"Arch: \", arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ab7c1",
   "metadata": {},
   "source": [
    "### Transfer Learning for Image Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfdc171",
   "metadata": {},
   "source": [
    "In this section, we use [TensorFlow Hub's](https://www.tensorflow.org/hub) pretrained [ResNet50v1.5 pretrained model](https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5) originally trained on the ImageNet dataset and perform transfer learning to fine-tune the model for your own image classes.\n",
    "\n",
    "Source: https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c7aad",
   "metadata": {},
   "source": [
    "In this example, we use the **TensorFlow Flower dataset**\n",
    "\n",
    "Loading the data in a *tf.data.Dataset* format.<br />\n",
    "We use a Batch Size of 512 images each of shape 224 x 224 x 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "data_root = tf.keras.utils.get_file(\n",
    "  'flower_photos',\n",
    "  'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "   untar=True)\n",
    "\n",
    "batch_size = 512\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_root),\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = np.array(train_ds.class_names)\n",
    "print(\"The flower dataset has \" + str(len(class_names)) + \" classes: \", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e1333",
   "metadata": {},
   "source": [
    "Image Pre-processing (Normalization between 0 and 1) and using buffered prefetching to avoid I/O blocking issues.\n",
    "\n",
    "Reference: https://www.tensorflow.org/guide/data_performance#prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c544aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48374986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a3a73",
   "metadata": {},
   "source": [
    "**Simple Transfer Learning:**<br />\n",
    "    1. *Select a pre-trained model from TensorFlow Hub*.<br />\n",
    "    2. *Retrain the top (last) layer to recognize the classes from your custom dataset*.<br /><br />\n",
    "\n",
    "We use a **headless ResNet50v1.5 pretrained model** (without the classification layer). Any compatible image feature vector model from TF-Hub (https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d593610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_feature_vector = \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature_vector/5\"\n",
    "\n",
    "feature_extractor_model = resnet_feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c0eeb",
   "metadata": {},
   "source": [
    "Create the feature extractor by wrapping the pre-trained model as a Keras layer with **hub.KerasLayer**. Use the ***trainable=False*** argument to freeze the variables, so that the training only modifies the new classifier layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dea7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False)\n",
    "\n",
    "feature_batch = feature_extractor_layer(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3eb9b",
   "metadata": {},
   "source": [
    "Attach the last fully connected classification layer in a **tf.keras.Sequential** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fead8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "fp32_model = tf.keras.Sequential([\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "if arch == 'SPR':\n",
    "    # Create a deep copy of the model to train the bf16 model separately to compare accuracy\n",
    "    bf16_model = tf.keras.models.clone_model(fp32_model)\n",
    "\n",
    "fp32_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9b621",
   "metadata": {},
   "source": [
    "In order to measure the training throughput, we define the following custom callback. For more information on callbacks, refer to https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98029709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "        self.throughput = []\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        total_time = time.time() - self.epoch_time_start\n",
    "        self.times.append(total_time)\n",
    "        self.throughput.append(batch_size/total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74bb95",
   "metadata": {},
   "source": [
    "#### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp32_model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_throughput_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08629163",
   "metadata": {},
   "source": [
    "#### Train without auto-mixed precision (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae2c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "time_callback = TimeHistory()\n",
    "history = fp32_model.fit(train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=[time_callback])\n",
    "avg_throughput = sum(time_callback.throughput)/len(time_callback.throughput)\n",
    "print(\"Avg Throughput: \" + str(avg_throughput) + \" imgs/sec\")\n",
    "train_throughput_list.append(avg_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d45604",
   "metadata": {},
   "source": [
    "### Enabling auto-mixed precision with `tf.config` API\n",
    "\n",
    "In this section, we show how to enable the auto-mixed precision using the `tf.config` API. Enabling this API will automatically convert the pre-trained model to use the bfloat16 datatype for computation resulting in an increased training throughput on the latest Intel® Xeon® scalable processor.\n",
    "\n",
    "You can also print the following to see whether the auto-mixed precision has been enabled.\n",
    "\n",
    "_Note: We only enable the auto-mixed precision if the underlying system is the 4th Gen Intel® Xeon® scalable processor (codenamed Sapphire Rapids)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d3210",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    tf.config.optimizer.set_experimental_options({'auto_mixed_precision_onednn_bfloat16':True})\n",
    "    print(tf.config.optimizer.get_experimental_options())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a7402",
   "metadata": {},
   "source": [
    "#### Compile and train the model with auto-mixed precision (bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    # Compile\n",
    "    bf16_model.compile(\n",
    "      optimizer=tf.keras.optimizers.SGD(),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=['acc'])\n",
    "    \n",
    "    # Train\n",
    "    NUM_EPOCHS = 10\n",
    "    time_callback = TimeHistory()\n",
    "    history = bf16_model.fit(train_ds, validation_data=val_ds, epochs=NUM_EPOCHS, callbacks=[time_callback])\n",
    "    avg_throughput = sum(time_callback.throughput)/len(time_callback.throughput)\n",
    "    print(\"Avg Throughput: \" + str(avg_throughput) + \" imgs/sec\")\n",
    "    train_throughput_list.append(avg_throughput)\n",
    "    \n",
    "    model = bf16_model\n",
    "else:\n",
    "    model = fp32_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127550b",
   "metadata": {},
   "source": [
    "Now, let's compare the throughput achieved with and without auto-mixed precision enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if arch == 'SPR':\n",
    "    import pandas as pd\n",
    "    print(train_throughput_list)\n",
    "    speedup = float(train_throughput_list[1])/float(train_throughput_list[0])\n",
    "    print(\"Speedup : \", speedup)\n",
    "    df = pd.DataFrame({'training_type':['orig', 'auto_mixed_precision'], 'Training Speedup':[1, speedup]})\n",
    "    ax = df.plot.bar( x='training_type', y='Training Speedup', rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3bc65",
   "metadata": {},
   "source": [
    "### Export the model in the SavedModel format\n",
    "\n",
    "Now that you've trained the model, export it as a SavedModel for reusing it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30032d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"models/my_saved_model\"\n",
    "model.save(export_path)\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a03faef",
   "metadata": {},
   "source": [
    "Let's measure the performance of the model we just saved using the `tf_benchmark.py` script that runs inference on dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855747",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run scripts/tf_benchmark.py --model_path models/my_saved_model --num_warmup 5 --num_iter 50 --precision float32 --batch_size 32 --disable_optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0398abd",
   "metadata": {},
   "source": [
    "### Optimize the SavedModel for faster inference\n",
    "\n",
    "To get a good performance on your (re)trained model for inference, some inference optimizations are required.\n",
    "In this section, we will guide you how to optimize a pre-trained model for better inference performance using the `freeze_optimize_v2.py` script that we put together using standard TensorFlow routines to optimize the model.\n",
    "Those optimizations includes:\n",
    "\n",
    "- Converting variables to constants\n",
    "- Removing training-only operations like checkpoint saving\n",
    "- Stripping out parts of the graph that are never reached\n",
    "- Removing debug operations like CheckNumerics\n",
    "- Folding batch normalization ops into the pre-calculated weights\n",
    "- Fusing common operations into unified versions\n",
    "\n",
    "The input to this script is the directory of original saved model, and output of this script is the directory of optimzed model. Users don't need to change below command in this tutorial, but need to put related directories after \"--input_saved_model_dir\" and \"--output_saved_model_dir\" for other pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1961932",
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/freeze_optimize_v2.py --input_saved_model_dir=models/my_saved_model --output_saved_model_dir=models/my_optimized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc03ce",
   "metadata": {},
   "source": [
    "Now that we have saved the optimized model, let's measure its performance using our benchmarking script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480dddda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run scripts/tf_benchmark.py --model_path models/my_optimized_model --num_warmup 5 --num_iter 50 --precision float32 --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd8fb5",
   "metadata": {},
   "source": [
    "**Let's compare the speedup obtained with the optimized model.**\n",
    "\n",
    "`plot.py` is a python script that creates a plot of the throughput values for inference with the original and the optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8157a5ec",
   "metadata": {},
   "source": [
    "### TensorFlow Serving\n",
    "\n",
    "In this section, we will initialize and run TensorFlow Serving natively to serve our retrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir serving\n",
    "!cp -r models/my_optimized_model serving/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = os.getcwd() + \"/serving\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd77c4",
   "metadata": {},
   "source": [
    "This is where we start running TensorFlow Serving and load our model. After it loads we can start making inference requests using REST. There are some important parameters:\n",
    "- **rest_api_port**: The port that you'll use for REST requests.\n",
    "- **model_name**: You'll use this in the URL of REST requests. It can be anything.\n",
    "- **model_base_path**: This is the path to the directory where you've saved your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aee14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "nohup tensorflow_model_server --rest_api_port=8501 --model_name=rn50 --model_base_path=${MODEL_DIR} > server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e486894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7606d",
   "metadata": {},
   "source": [
    "**Prepare the testing data for prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfa9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in val_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break\n",
    "test_data, test_labels = image_batch.numpy(), labels_batch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e5f62",
   "metadata": {},
   "source": [
    "First, let's take a look at a random example from our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2761dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(idx, title):\n",
    "    plt.figure()\n",
    "    plt.imshow(test_data[idx])\n",
    "    plt.axis('off')\n",
    "    plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
    "\n",
    "import random\n",
    "rando = random.randint(0,test_data.shape[0]-1)\n",
    "show(rando, 'An Example Image:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b362658",
   "metadata": {},
   "source": [
    "#### Make a request to your model in TensorFlow Serving\n",
    "\n",
    "Now let's create the JSON object for a batch of three inference requests, and see how well our model recognizes things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bf2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_data[0:3].tolist()})\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f3c8b",
   "metadata": {},
   "source": [
    "#### Make REST requests\n",
    "\n",
    "We'll send a predict request as a POST to our server's REST endpoint, and pass it three examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/rn50:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "\n",
    "for i in range(0,3):\n",
    "    show(i, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
    "        class_names[np.argmax(predictions[i])], np.argmax(predictions[i]), class_names[test_labels[i]], test_labels[i]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
