{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# Copyright © 2020 Intel Corporation\n",
    "# \n",
    "# SPDX-License-Identifier: MIT\n",
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daal4py Linear Regression Example for Distributed Memory Systems [SPMD mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT NOTICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using daal4py for distributed memory systems, the command needed to execute the program should be **executed \n",
    "in a bash shell**. In order to run this example, please download it as a .py file then run the following command (**the number 4 means that it will run on 4 processes**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mpirun -n 4 python ./IntelPython_daal4py_Distributed_LinearRegression.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Organizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be predicting **prices of houses in California** based on the features of each house.\n",
    "\n",
    "Let's start by **importing** all necessary data and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### daal4py linear regression example for distributed memory systems [SPMD mode] #####\n",
    "import daal4py as d4p\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate our sample dataset to be ready for distributed processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# organizing variables used in the model for prediction\n",
    "X = data.data # house characteristics\n",
    "y = data.target # house price\n",
    "\n",
    "# splitting the data for training and testing, with a 25% test dataset size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state =1693)\n",
    "\n",
    "# merging the training independent and dependent variable data together for ease of use with distributed engine\n",
    "X_train['target']=y_train\n",
    "full_train_data=X_train\n",
    "\n",
    "# merging the testing independent and dependent variable data together for ease of use with distributed engine\n",
    "X_test['target']=y_test\n",
    "full_test_data=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing files to be used in distributed example with unique ID\n",
    "for i in range(1,5):\n",
    "    train_filename=\"./data/linear_regression_train_\" + str(i) + \".csv\"\n",
    "    full_train_data.to_csv(train_filename)\n",
    "\n",
    "test_filename=\"./data/linear_regression_test.csv\"\n",
    "full_test_data.to_csv(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **load** in the dataset and **organize** it as necessary to work with our model. For distributed, every file has a unique ID.\n",
    "\n",
    "We will also **initialize the distribution engine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4p.daalinit() #initializes the distribution engine\n",
    "\n",
    "# organizing variables used in the model for prediction\n",
    "\n",
    "    \n",
    "# each process gets its own data\n",
    "infile = \"./data/linear_regression_train_\" + str(d4p.my_procid()+1) + \".csv\"\n",
    "\n",
    "# read data\n",
    "indep_data = pd.read_csv(infile).drop([\"target\"], axis=1) # house characteristics\n",
    "dep_data   = pd.read_csv(infile)[\"target\"] # house price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Saving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to **train our model** and look at the model's features! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model for prediction\n",
    "train_result = d4p.linear_regression_training(distributed=True).compute(indep_data, dep_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **get training model information** and **save it to a file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our model:\n",
      "\n",
      "\n",
      " NumberOfBetas: 10\n",
      "\n",
      "NumberOfResponses: 1\n",
      "\n",
      "InterceptFlag: False\n",
      "\n",
      "Beta: array(\n",
      "  [[ 0.00000000e+00  1.27631128e-05  5.23981023e-01  1.64105108e-02\n",
      "    -2.03228311e-01  9.13650400e-01  1.03602177e-05 -5.30412237e-03\n",
      "    -6.00509940e-02 -1.40622318e-02]],\n",
      "  dtype=float64, shape=(1, 10))\n",
      "\n",
      "NumberOfFeatures: 9 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/daal4py_Distributed_LinearRegression_1.sav']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving and printing training model\n",
    "model = train_result.model\n",
    "print(\"Here's our model:\\n\\n\\n\",model , \"\\n\")\n",
    "\n",
    "model_filename = './models/daal4py_Distributed_LinearRegression_' + str(d4p.my_procid()+1) + '.sav'\n",
    "\n",
    "# saving model to a file\n",
    "joblib.dump(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **load up the model** and look at one of the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is one of our loaded model's features: \n",
      "\n",
      " [[ 0.00000000e+00  1.27631128e-05  5.23981023e-01  1.64105108e-02\n",
      "  -2.03228311e-01  9.13650400e-01  1.03602177e-05 -5.30412237e-03\n",
      "  -6.00509940e-02 -1.40622318e-02]]\n"
     ]
    }
   ],
   "source": [
    "# loading the training model from a file\n",
    "loaded_model = joblib.load(open(model_filename, \"rb\"))\n",
    "print(\"Here is one of our loaded model's features: \\n\\n\",loaded_model.Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Prediction and Saving the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to **make a prediction!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_data = pd.read_csv(\"./data/linear_regression_test.csv\").drop([\"target\"], axis=1)\n",
    "\n",
    "# now predict using the model from the training above\n",
    "predict_result = d4p.linear_regression_prediction().compute(test_data, train_result.model).prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's **export the results to a CSV file**. We will also **stop the distribution engine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\n"
     ]
    }
   ],
   "source": [
    "# now export the results to a CSV file\n",
    "results_filename = \"./results/daal4py_Distributed_LinearRegression_results\" + str(d4p.my_procid()+1) + \".csv\"\n",
    "np.savetxt(results_filename, predict_result, delimiter =  \",\")\n",
    "\n",
    "d4p.daalfini() # stops the distribution engine\n",
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
