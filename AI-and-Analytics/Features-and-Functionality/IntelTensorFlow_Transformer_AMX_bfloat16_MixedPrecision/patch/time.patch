--- text_classification_with_transformer1.py
+++ text_classification_with_transformer.py
@@ -10,10 +10,38 @@
 ## Setup
 """
 
+from time import time
+import os
+
 import tensorflow as tf
 from tensorflow import keras
 from tensorflow.keras import layers
 
+from platform_util import PlatformUtil
+cpu_info = PlatformUtil("")
+
+numa_nodes = cpu_info.numa_nodes 
+print("CPU count per socket:" , cpu_info.cores_per_socket ," \nSocket count:", cpu_info.sockets, " \nNuma nodes:",numa_nodes) 
+
+if numa_nodes > 0: 
+    socket_number = 1 
+    cpu_count = cpu_info.cores_per_socket 
+    inter_thread = 1 
+else: 
+    # on non-numa machine, we should use all the cores and don't use numactl 
+    socket_number = -1 
+    cpu_count = cpu_info.cores_per_socket * cpu_info.sockets 
+    inter_thread = cpu_info.sockets
+        
+# Intel OpenMP threads and other fine-tuning parameters
+os.environ['OMP_NUM_THREADS'] = "cpu_count "
+os.environ['KMP_BLOCKTIME'] = "inter_thread"
+os.environ['KMP_AFFINITY'] = "granularity=fine,verbose,compact,1,0"
+
+# # Eigen threads
+tf.config.threading.set_intra_op_parallelism_threads(cpu_count)
+tf.config.threading.set_inter_op_parallelism_threads(inter_thread)
+
 
 """
 ## Implement a Transformer block as a layer
@@ -111,6 +139,11 @@
 model.compile(
     optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
 )
+
+start = time()
 history = model.fit(
     x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)
 )
+end = time()
+
+print("time: ", end-start)
