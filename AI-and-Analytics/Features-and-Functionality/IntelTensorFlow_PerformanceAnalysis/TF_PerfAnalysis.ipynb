{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Performance Analysis for TensorFlow Profiling Result\n",
    "This notebook guides auidences how to generate trace.json file by using TensorFlow Profiler, and then analyze it accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable TensorFlow Profiler\n",
    "***\n",
    "This section shows users how to enable TensorFlow Profiler for both Training and Infernce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the TensorFlow version used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%run -i \"../../version_check.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After TensorFlow 2.11, TensorFlow only generate a xplane.pb file and doesn't have trace.json file as output. \n",
    "This notebook could only support TensorFlow version 2.10 and prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "major_version = int(tf.__version__.split(\".\")[0])\n",
    "minor_version = int(tf.__version__.split(\".\")[1])\n",
    "if major_version >= 2 and minor_version > 10:\n",
    "    print(\"This notebook only support TensorFlow version 2.10 and pior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable TensorFlow Profiler in the word embeddings workload from Keras-IO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the pretrained word embeddedings workload from Keras IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/keras-team/keras-io/master/examples/nlp/pretrained_word_embeddings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable TensorFlow Profiler for both Training and Inference sessions in the word embeddings workloads.  \n",
    "You could see the changes in profile.patch for both training session around line 280 and infernece session around line 297.  \n",
    "We use tf.keras.callbacks.TensorBoard for training session and tf.profiler.experimental.ProfilerOptions for infernece session.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Code(filename=\"patch/profile.patch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch the pretrained_word_embeddings and enable TF Profiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!patch < patch/profile.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the word embeddings workload with TensorFlow Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the glove dataset for the word embeddings workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.keras/datasets/; wget http://nlp.stanford.edu/data/glove.6B.zip; unzip -q glove.6B.zip; mv glove.6B.* ~/.keras/datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the word embeddings for both training and inference.  \n",
    "You will have logdir-train folder with profiling result for training, and logdir-inf folder with profiling result for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%run -i \"pretrained_word_embeddings.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please change below Profile_Dir path for the latest inference result folder in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env Profile_Dir=logdir-inf/plugins/profile/2023_03_18_14_43_56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pdir = os.environ.get(\"Profile_Dir\")\n",
    "os.listdir(pdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also change the below json_path for the trace.json.gz file in the latest inference result folder.  \n",
    "We will analyze the trace.json file in the following session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env json_path=logdir-inf/plugins/profile/2023_03_18_14_43_56/icx02-tce-atsm.trace.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze TensorFlow Profiling Result\n",
    "***\n",
    "This section shows users how to analyze TensorFlow Profiling results with a analyze script and its HTML output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the json file from previous session by using Analyze/analyze script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!Analyze/analyze $json_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all the report folders in order to get the full name of the latest analyze report folder.  \n",
    "The current timestamp will be added as a postfix of the report folder name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls | grep report_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please change folder_dir and put the report folder that you want to analyze.  \n",
    "Overall, you should pick the latest report folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir=\"report_2023-03-18_15-00/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are report.html file which shows all the analysis diagrams.  \n",
    "We show all the analysis diagrams below, and your could refer to Analyze/README.md file for more details of those analysis diagrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "for images in os.listdir(folder_dir):\n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".png\")):\n",
    "        print(images)\n",
    "        x = Image(filename=folder_dir + images)\n",
    "        display(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyze script can also compare two json files from two different runs.   \n",
    "We compare two json files. The stock_timeline was generated under stock tensorflow without oneDNN and mkl_timeline was generated under stock-tensorflow with oneDNN enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!Analyze/analyze samples/stock_timeline_resnet50v1_5_fp32_infer_merged_runs.json samples/mkl_timeline_resnet50v1_5_fp32_infer_merged_runs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls | grep report_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please change folder_dir and put the report folder that you want to analyze.  \n",
    "Overall, you should pick the latest report folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir=\"report_2023-03-18_15-00/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are report.html file which shows all the analysis diagrams.  \n",
    "We show all the analysis diagrams below, and your could refer to Analyze/README.md file for more details of those analysis diagrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "folder_dir=\"report_2023-03-18_15-05/\"\n",
    "for images in os.listdir(folder_dir):\n",
    "    # check if the image ends with png\n",
    "    if (images.endswith(\".png\")):\n",
    "        print(images)\n",
    "        x = Image(filename=folder_dir + images)\n",
    "        display(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output(both stdout and stderr) is displayed on the command line console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intel-tensorflow",
   "language": "python",
   "name": "intel-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
