{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22333506-1f31-4a4d-804b-35c522bcaa74",
   "metadata": {},
   "source": [
    "# Intel AI Kit and XGBoost Using daal4py\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "* Utilize XGBoost with Intel's AI KIt\n",
    "* Take advantage of Intel extensions to SciKit Learn by enabling them with XGBoost\n",
    "* Utilize oneDaal to enhance prediction performance\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0117c64-fb29-4f27-9a65-c4b8ba30b2c3",
   "metadata": {},
   "source": [
    "In this example, we will use a dataset with particle features and functions of those features **to distinguish between a signal process which produces Higgs bosons (1) and a background process which does not (0)**. The Higgs boson is a basic particle in the standard model produced by the quantum excitation of the Higgs field, named after physicist Peter Higgs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821b722-e2ed-46e6-9068-3ac15eb8ca29",
   "metadata": {},
   "source": [
    "![image](3D_view_energy_of_8_TeV.png)\n",
    "[Images Source](https://commons.wikimedia.org/wiki/File:3D_view_of_an_event_recorded_with_the_CMS_detector_in_2012_at_a_proton-proton_centre_of_mass_energy_of_8_TeV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57efb70b-7073-4baa-b544-253551c7bb58",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2502e54-f520-4b7e-a517-c1e3a10e9722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "#unpatch_sklearn()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int16Dtype # if you don't import in this order you will get a pandas.Int64Index fix for FutureWarning error.\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "print(\"XGB Version          : \", xgb.__version__)\n",
    "print(\"Scikit-Learn Version : \", sklearn.__version__)\n",
    "print(\"Pandas Version       : \", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68230356-c247-4fc2-b9b2-9510e44584fd",
   "metadata": {},
   "source": [
    "## Import the Data: \n",
    "\n",
    "### (If you ran module 03 you should already have it and do not need to execute the following cells to get the HIGGs data; however, you do need to create a symbolic link to the HIGGS.csv) \n",
    "\n",
    "```ln -s /home/u12345/AI_Kit_XGBoost_Predictive_Modeling/03_XGBoost/HIGGS.csv HIGGS.csv```\n",
    "\n",
    "* The first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features):\n",
    "\n",
    "* The dataset has 1.1 million rows, adjust the __nrows__ value to something manageable by the sytem you happen to be using.  100K is easy for a modern laptop; however, once you start optimizing much more than that can take some time. \n",
    "\n",
    "[Data Source](https://archive.ics.uci.edu/ml/datasets/HIGGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a41477-7724-4650-8252-dd80745ca226",
   "metadata": {},
   "source": [
    "### To get the data using the Intel DevCloud execute the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7494a1a-1a2f-4c9a-a3cd-3a65caccac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cp /data/oneapi_workshop/big_datasets/xgboost/HIGGS.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd4799-114c-474b-8686-ba12156faa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tar -xzf HIGGS.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902420cc-3d6e-45e4-b110-95bec4264c63",
   "metadata": {},
   "source": [
    "### __Do not__ run this if on the Intel DevCloud.  To fetch the data for your local install execute the below two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f3305-246f-46e9-9d95-bd3fb4e2085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# if not os.path.isfile(\"./HIGGS.csv.gz\"):\n",
    "#         print(\"Fetching data set from Internet...~2.8GB\")\n",
    "#         url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
    "#         myfile = requests.get(url)\n",
    "#         with open('./HIGGS.csv.gz', 'wb') as f:\n",
    "#             f.write(myfile.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c47011e-12e5-4078-848b-43b936fee325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gunzip HIGGS.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b403ed-64c6-4a25-a9df-6031b01d1ff7",
   "metadata": {},
   "source": [
    "### Set the number of rows to use via nrows= variable.  100K is manageable on a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'HIGGS.csv'\n",
    "names =  ['class_label', 'lepton pT', 'lepton eta', 'lepton phi', 'missing energy magnitude', 'missing energy phi', 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n",
    "#data = pd.read_csv(filename, names=names, delimiter=\",\", nrows=100000)\n",
    "data = pd.read_csv(filename, names=names, delimiter=\",\", nrows=1100000)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7249bc-4e6b-4a28-8894-00b14c61d4f2",
   "metadata": {},
   "source": [
    "### Examine the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c73db-9077-4451-9306-10a1a9c1616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdebf6-da64-4ed4-bd2c-0862e27a700f",
   "metadata": {},
   "source": [
    "### Create your train/test split. \n",
    "\n",
    "* Remember the first non index column is 0 = no signal 1 = signal, so we want to leave out the labels and predict column 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff822d-c76b-4f13-bd2c-dee18ca01126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:, 1:],data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d46c222-d326-4068-9594-a003e0e884db",
   "metadata": {},
   "source": [
    "### We are using the scikit-learn methodology to create the train test/split.  Feel free to play with the split and random state, just make sure you use the same random state throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3ad68-9a82-4866-a38f-c2db24c669a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f633132-8141-46a6-a2b3-7e2b0a8c1c0a",
   "metadata": {},
   "source": [
    "### Get a baseline using the XGBoost defaults.  \n",
    "\n",
    "Now that we have our data split into train and test datasets let's use the default XGBoost parameters to see default results.  If you are familiar with these parameters feel free to add them to the parameters cell below and feel free to modify these.  We will explore how to find better results later in the notebook.\n",
    "\n",
    "* __learning_rate:__ step size shrinkage used to prevent overfitting. Range is 0 to 1 but a lower rate is usually better.\n",
    "* __max_depth:__ determines how deeply each tree is allowed to grow during any boosting round.\n",
    "* __subsample:__ percentage of samples used per tree. Low value can lead to underfitting.\n",
    "* __colsample_bytree:__ percentage of features used per tree. High value can lead to overfitting.\n",
    "* __n_estimators:__ number of trees built\n",
    "* __objective:__ determines the loss function type: \n",
    "    * reg:linear for # regression problems.\n",
    "    * reg:logistic for classification problems with only decision.\n",
    "    * binary:logistic for classification problems with probability.\n",
    "    \n",
    "    [There are many more parameters, here is the reference.](https://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters)\n",
    "    \n",
    "* For a default we are selecting three parameters:  binary:logistic, using the cpu_predictor and due to a recent change in XGBoosts behaviour setting the error metric to error rather than logistic error for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963cf37-1323-4d09-aa11-9dbb500ae3a0",
   "metadata": {},
   "source": [
    "## Set XGBoost Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8890db6-4e4b-4f02-934d-21630c412d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set XGBoost training parameters\n",
    "xgb_params = {\n",
    "    'objective':                    'binary:logistic',\n",
    "    'predictor':                    'cpu_predictor',\n",
    "    'disable_default_eval_metric':  'true',\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "t1_start = perf_counter()  # Time fit function\n",
    "model_xgb= xgb.XGBClassifier(**xgb_params)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "t1_stop = perf_counter()\n",
    "print (\"It took\", t1_stop-t1_start,\"seconds to train the model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed11623-e3e7-4300-8aa0-da17d28f2f5c",
   "metadata": {},
   "source": [
    "## Predict Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d1de1-1385-4fa5-87e9-720137482002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy\n",
    "t1_start = perf_counter()\n",
    "result_predict_xgb_test = model_xgb.predict(X_test)\n",
    "t1_stop = perf_counter()\n",
    "print (\"It took\", t1_stop-t1_start,\"seconds for prediction with XGBoost.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209be146-c3e2-446e-a324-aac26f40a34c",
   "metadata": {},
   "source": [
    "## Accuracy of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042df10-426e-43a7-b33a-9092cb069e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(y_test == result_predict_xgb_test)\n",
    "print(\"Model accuracy =\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868131df-df57-4dca-bfa9-45605c774132",
   "metadata": {},
   "source": [
    "## Convert an XGBoost model to oneDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff2cec-3df4-4089-b57a-0ea24b507f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "clf = xgb.XGBClassifier(**xgb_params)\n",
    "xgb_model = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05136153-fbcb-48a2-a34a-b17fe5fd5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "daal_model = d4p.get_gbt_model_from_xgboost(xgb_model.get_booster())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f63363-918c-42a9-aa46-7df630ed90cb",
   "metadata": {},
   "source": [
    "## Predict using oneDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c27f09-79c8-4295-afa2-b4a0b9914d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_start = perf_counter()  # Time function\n",
    "daal_prediction = d4p.gbt_classification_prediction(nClasses=2).compute(X_test, daal_model).prediction\n",
    "t1_stop = perf_counter()\n",
    "print (\"It took\", t1_stop-t1_start,\"seconds for prediction with oneDAL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa679387-dd7f-44bc-bba3-7c88c8e98494",
   "metadata": {},
   "source": [
    "## Accuracy of oneDAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cd655-3323-423e-8936-8651d9d2b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nXGBoost prediction results (first 10 rows):\\n\", result_predict_xgb_test[0:10])\n",
    "print(\"\\ndaal4py prediction results (first 10 rows):\\n\", daal_prediction[0:10])\n",
    "print(\"\\nGround truth (first 10 rows):\\n\", y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fd9e2-a9db-41f8-8251-23f28add2424",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "* We covered how to set parameters for XGBoost.\n",
    "* How to convert to an XGBoost Model to a oneDAL model.\n",
    "* We compared oneDal prediction time vs XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab837f-a610-4bd1-8447-d0081f8fb852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IntelÂ® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
