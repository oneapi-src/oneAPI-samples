{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Parallel Control (dpctl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "- [Introduction to Data parallel Control (dpctl)](#Introduction-to-Data-Parallel-Control-(dpctl))\n",
    "    - _Code:_ [dpctl.device_context()](#dpctl.device_context())    \n",
    "- [Managing SYCL USM memory using dpctl.memory](#Managing-SYCL-USM-memory-using-dpctl.memory)\n",
    "    - _Code:_ [dpctl Memory API](#dpctl-Memory-API)   \n",
    "- _Code:_ [Memory Management in numba-dpex](#Memory-Management-in-numba-dpex)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Utilize __Data Parallel Control (dpctl)__ to manage different devices\n",
    "* Usage of the classes and the functions of dpctl\n",
    "* Use dpctl.memory to create Python objects backed by SYCL USM memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Parallel Control (dpctl) \n",
    "Dpctl provides a lightweight Python wrapper over a subset of SYCL’s API. The goal of dpctl is not (yet) to provide an abstraction for every SYCL function. Dpctl is intended to provide a common runtime to manage specific SYCL resources, such as devices and USM memory, for SYCL-based Python packages and extension modules.\n",
    "\n",
    "The main features presently provided by dpctl are:\n",
    "\n",
    "1. Python wrapper classes for the main SYCL runtime classes mentioned in Section 4.6 of SYCL provisional 2020 spec (https://bit.ly/3asQx07): `platform`, `device`, `context`, `device_selector`, and `queue`.\n",
    "1. A USM memory manager to create Python objects that use SYCL USM for data allocation.\n",
    "\n",
    "\n",
    "Dpctl is available as part of the oneAPI Intel Distribution of Python (IDP). Once oneAPI is installed, dpctl is ready to be used by setting up the IDP that is available inside oneAPI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing SYCL devices using dpctl\n",
    "\n",
    "### dpctl.device_context()\n",
    "Yields a SYCL queue corresponding to the input filter string.\n",
    "\n",
    "This context manager “activates”, i.e., sets as the currently usable queue, the SYCL queue defined by the “backend:device type:device id” tuple. The activated queue is yielded by the context manager and can also be accessed by any subsequent call to dpctl.get_current_queue() inside the context manager’s scope. The yielded queue is removed as the currently usable queue on exiting the context manager.\n",
    "\n",
    "To create a scope within which the openCL GPU, a programmer needs to do the following.\n",
    "```\n",
    "import dpctl\n",
    "with dpctl.device_context(\"opencl:gpu\"):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing SYCL devices using dpctl\n",
    "\n",
    "### Classes\n",
    "\n",
    "* dpctl.SyclContext : A Python class representing cl::sycl::context\n",
    "* dpctl.SyclDevice : A Python class representing cl::sycl::device\n",
    "* dpctl.SyclEvent : A Python class representing cl::sycl::event\n",
    "* dpctl.SyclPlatform : A Python class representing cl::sycl::event\n",
    "* dpctl.SyclQueue : A Python class representing cl::sycl::event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dpctl SyclDevice\n",
    "\n",
    "This is a python equivalent for cl::sycl::device class.\n",
    "There are two ways of creating a SyclDevice instance:\n",
    "\n",
    "* By directly passing in a filter string to the class constructor.\n",
    "\n",
    "```\n",
    "import dpctl\n",
    "\n",
    "# Create a SyclDevice with an explicit filter string,\n",
    "# in this case the first level_zero gpu device.\n",
    "level_zero_gpu = dpctl.SyclDevice(\"level_zero:gpu:0\"):\n",
    "level_zero_gpu.print_device_info()\n",
    "```\n",
    "\n",
    "* The other way is by calling one of the device selector helper functions as shown below\n",
    "\n",
    "```\n",
    "import dpctl\n",
    "\n",
    "# Create a SyclDevice of type GPU based on whatever is returned\n",
    "# by the SYCL `gpu_selector` device selector class.\n",
    "# d = dpctl.select_cpu_device()\n",
    "# d = dpctl.select_accelerator_device()\n",
    "# d = dpctl.select_host_device()\n",
    "# d = dpctl.select_default_device()\n",
    "d = dpctl.select_gpu_device():\n",
    "d.print_device_info()\n",
    "\n",
    "```\n",
    "\n",
    "* dpctl.get_devices(backend=backend_type.all, device_type=device_type_t.all) returns a list of dpctl.SyclDevice instances selected based on the given dpctl.device_type and dpctl.backend_type values.\n",
    "\n",
    "* backend (optional) – Defaults to dpctl.backend_type.all. A dpctl.backend_type enum value or a string that specifies a SYCL backend. Currently, accepted values are: “cuda”, “opencl”, “level_zero”, or “all”.\n",
    "\n",
    "* device_type (optional) – Defaults to dpctl.device_type.all. A dpctl.device_type enum value or a string that specifies a SYCL device type. Currently, accepted values are: “gpu”, “cpu”, “accelerator”, “host_device”, or “all”.\n",
    "\n",
    "\n",
    "The below example shows the usage of the dpCTL API to retrieve the current device platforms and the devices specific to the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dpctl sample code\n",
    "\n",
    "The below example shows the usage of the dpCTL API to retrieve the current device platforms and the devices specific to the current device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates usage of DPCTL code: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple_dpctl_queue.py\n",
    "\n",
    "#                      Data Parallel Control (dpctl)\n",
    "#\n",
    "# Copyright 2020-2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Examples illustrating SYCL device selection features provided by dpctl.\n",
    "\"\"\"\n",
    "\n",
    "import dpctl\n",
    "\n",
    "\n",
    "def print_device(d):\n",
    "    \"Display information about given device argument.\"\n",
    "    if type(d) is not dpctl.SyclDevice:\n",
    "        raise ValueError\n",
    "    print(\"Name: \", d.name)\n",
    "    print(\"Vendor: \", d.vendor)\n",
    "    print(\"Driver version: \", d.driver_version)\n",
    "    print(\"Backend: \", d.backend)\n",
    "    print(\"Max EU: \", d.max_compute_units)\n",
    "\n",
    "\n",
    "def create_default_device():\n",
    "    \"\"\"\n",
    "    Create default SyclDevice using `cl::sycl::default_selector`.\n",
    "    Device created can be influenced by environment variable\n",
    "    SYCL_DEVICE_FILTER, which determines SYCL devices seen by the\n",
    "    SYCL runtime.\n",
    "    \"\"\"\n",
    "    d1 = dpctl.SyclDevice()\n",
    "    d2 = dpctl.select_default_device()\n",
    "    assert d1 == d2\n",
    "    print_device(d1)\n",
    "    return d1\n",
    "\n",
    "\n",
    "def create_gpu_device():\n",
    "    \"\"\"\n",
    "    Create a GPU device.\n",
    "    Device created can be influenced by environment variable\n",
    "    SYCL_DEVICE_FILTER, which determines SYCL devices seen by the\n",
    "    SYCL runtime.\n",
    "    \"\"\"\n",
    "    d1 = dpctl.SyclDevice(\"gpu\")\n",
    "    d2 = dpctl.select_gpu_device()\n",
    "    assert d1 == d2\n",
    "    print_device(d1)\n",
    "    return d1\n",
    "\n",
    "\n",
    "def create_gpu_device_if_present():\n",
    "    \"\"\"\n",
    "    Select from union of two selections using default_selector.\n",
    "    If a GPU device is available, it will be selected, if not,\n",
    "    a CPU device will be selected, if available, otherwise an error\n",
    "    will be raised.\n",
    "    Device created can be influenced by environment variable\n",
    "    SYCL_DEVICE_FILTER, which determines SYCL devices seen by the\n",
    "    SYCL runtime.\n",
    "    \"\"\"\n",
    "    d = dpctl.SyclDevice(\"gpu,cpu\")\n",
    "    print(\"Selected \" + (\"GPU\" if d.is_gpu else \"CPU\") + \" device\")\n",
    "\n",
    "\n",
    "def custom_select_device():\n",
    "    \"\"\"\n",
    "    Programmatically select among available devices.\n",
    "    Device created can be influenced by environment variable\n",
    "    SYCL_DEVICE_FILTER, which determines SYCL devices seen by the\n",
    "    SYCL runtime.\n",
    "    \"\"\"\n",
    "    # select devices that support half-precision computation\n",
    "    devs = [d for d in dpctl.get_devices() if d.has_aspect_fp16]\n",
    "    # choose the device with highest default_selector score\n",
    "    max_score = 0\n",
    "    selected_dev = None\n",
    "    for d in devs:\n",
    "        if d.default_selector_score > max_score:\n",
    "            max_score = d.default_selector_score\n",
    "            selected_dev = d\n",
    "    if selected_dev:\n",
    "        print_device(selected_dev)\n",
    "    else:\n",
    "        print(\"No device with half-precision support is available.\")\n",
    "    return selected_dev\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_default_device()\n",
    "    create_gpu_device()\n",
    "    create_gpu_device_if_present()\n",
    "    custom_select_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_dpctl_queue.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_dpctl_queue.sh; else ./run_dpctl_queue.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dpctl SyclQueue\n",
    "\n",
    "dpctl Queue is a python class representing cl::sycl::queue. There are multiple ways to create a dpctl.SyclQueue object:\n",
    "\n",
    "* Invoking the constructor with no arguments creates a context using the default selector.\n",
    "\n",
    "\n",
    "```\n",
    "import dpctl\n",
    "\n",
    "# Create a default SyclQueue\n",
    "q = dpctl.SyclQueue()\n",
    "print(q.sycl_device)\n",
    "```\n",
    "\n",
    "* Invoking the constructor with specific filter selector string that creates a queue for the device corresponding to the filter string.\n",
    "\n",
    "```\n",
    "import dpctl\n",
    "\n",
    "# Create in-order SyclQueue for either gpu, or cpu device\n",
    "q = dpctl.SyclQueue(\"gpu,cpu\", property=\"in_order\")\n",
    "print([q.sycl_device.is_gpu, q.sycl_device.is_cpu])\n",
    "```\n",
    "\n",
    "* Invoking the constructor with a dpctl.SyclDevice object creates a queue for that device, automatically finding/creating a dpctl.SyclContext for the given device.\n",
    "\n",
    "```\n",
    "import dpctl\n",
    "\n",
    "d = dpctl.SyclDevice(\"gpu\")\n",
    "q = dpctl.SyclQueue(d)\n",
    "ctx = q.sycl_context\n",
    "print(q.sycl_device == d)\n",
    "print(any([ d == ctx_d for ctx_d in ctx.get_devices()]))\n",
    "```\n",
    "\n",
    "The below example shows the usage of the dpctl queue creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates usage of DPCTL code: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/dpctl_queue_2.py\n",
    "\n",
    "#                      Data Parallel Control (dpctl)\n",
    "#\n",
    "# Copyright 2020-2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import dpctl\n",
    "\n",
    "\n",
    "def create_default_queue():\n",
    "    \"\"\"Create a queue from default selector.\"\"\"\n",
    "    q = dpctl.SyclQueue()\n",
    "    # Queue is out-of-order by default\n",
    "    print(\"Queue {} is in order: {}\".format(q, q.is_in_order))\n",
    "\n",
    "\n",
    "def create_queue_from_filter_selector():\n",
    "    \"\"\"Create queue for a GPU device or,\n",
    "    if it is not available, for a CPU device.\n",
    "    Create in-order queue with profilign enabled.\n",
    "    \"\"\"\n",
    "    q = dpctl.SyclQueue(\"gpu,cpu\", property=(\"in_order\", \"enable_profiling\"))\n",
    "    print(\"Queue {} is in order: {}\".format(q, q.is_in_order))\n",
    "    # display the device used\n",
    "    print(\"Device targeted by the queue:\")\n",
    "    q.sycl_device.print_device_info()\n",
    "\n",
    "\n",
    "def create_queue_from_device():\n",
    "    \"\"\"\n",
    "    Create a queue from SyclDevice instance.\n",
    "    \"\"\"\n",
    "    cpu_d = dpctl.SyclDevice(\"opencl:cpu:0\")\n",
    "    q = dpctl.SyclQueue(cpu_d, property=\"enable_profiling\")\n",
    "    assert q.sycl_device == cpu_d\n",
    "    print(\n",
    "        \"Number of devices in SyclContext \" \"associated with the queue: \",\n",
    "        q.sycl_context.device_count,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_queue_from_subdevice():\n",
    "    \"\"\"\n",
    "    Create a queue from a sub-device.\n",
    "    \"\"\"\n",
    "    cpu_d = dpctl.SyclDevice(\"opencl:cpu:0\")\n",
    "    sub_devs = cpu_d.create_sub_devices(partition=4)\n",
    "    q = dpctl.SyclQueue(sub_devs[0])\n",
    "    # a single-device context is created automatically\n",
    "    print(\n",
    "        \"Number of devices in SyclContext \" \"associated with the queue: \",\n",
    "        q.sycl_context.device_count,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_queue_from_subdevice_multidevice_context():\n",
    "    \"\"\"\n",
    "    Create a queue from a sub-device.\n",
    "    \"\"\"\n",
    "    cpu_d = dpctl.SyclDevice(\"opencl:cpu:0\")\n",
    "    sub_devs = cpu_d.create_sub_devices(partition=4)\n",
    "    ctx = dpctl.SyclContext(sub_devs)\n",
    "    q = dpctl.SyclQueue(ctx, sub_devs[0])\n",
    "    # a single-device context is created automatically\n",
    "    print(\n",
    "        \"Number of devices in SyclContext \" \"associated with the queue: \",\n",
    "        q.sycl_context.device_count,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_default_queue()\n",
    "    create_queue_from_filter_selector()\n",
    "    create_queue_from_device()\n",
    "    create_queue_from_subdevice()\n",
    "    create_queue_from_subdevice_multidevice_context()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_dpctl_queue2.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_dpctl_queue2.sh; else ./run_dpctl_queue2.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unified Shared Memory\n",
    "\n",
    "Unified Shared Memory (USM) is a SYCL tool for data management. USM is a __pointer-based approach__ that should be familiar to C and C++ programmers who use malloc or new to allocate data. USM __simplifies development__ for the programmer when __porting existing C/C++ code__ to DPC++.\n",
    "\n",
    "### Developer view of USM\n",
    "The picture below shows __developer view of memory__ without USM and with USM.  With USM, the developer can reference the same memory object in host and device code.\n",
    "\n",
    "<img src=\"Assets/usm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing SYCL USM memory using dpctl.memory\n",
    "\n",
    "\n",
    "dpctl.memory provides Python objects for untyped USM memory container of bytes for each kind of USM pointers: shared pointers, device pointers and host pointers. Shared and host pointers are accessible from both host and a device, while device pointers are only accessible from device. Python objects corresponding to shared and host pointers implement Python simple buffer protocol. It is therefore possible to use these objects to manipulate USM memory using NumPy or bytearray, memoryview, or array.array classes.\n",
    "\n",
    "* dpctl.memory.MemoryUSMDevice: Allocates nbytes of USM device memory only accessible from the device.\n",
    "* dpctl.memory.MemoryUSMHost: Allocates nbytes of USM host memory accessible from both host and a device.\n",
    "* dpctl.memory.MemoryUSMShared: Allocates nbytes of USM shared memory accessible from both host and a device.\n",
    "\n",
    "\n",
    "| Type | function call | Description | Accessible on Host | Accessible on Device |\n",
    "|:---|:---|:---|:---:|:---:|\n",
    "| Device | MemoryUSMDevice | Allocation on device (explicit) | NO | YES |\n",
    "| Host | MemoryUSMHost |Allocation on host (implicit) | YES | YES |\n",
    "| Shared | MemoryUSMShared | Allocation can migrate between host and device (implicit) | YES | YES |\n",
    "\n",
    "\n",
    "\n",
    "Following are the common functions used with the above classes\n",
    "* copy_from_device(): Copy SYCL memory underlying the argument object into the memory of the instance.\n",
    "* copy_from_host(): Copy content of Python buffer provided by obj to instance memory.\n",
    "* copy_to_host(): Copy content of instance’s memory into memory of obj."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dpctl Memory API\n",
    "The code below demonstrates usage of dPCtl Memory API: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/simple_dpctl.py\n",
    "\n",
    "#                      Data Parallel Control (dpctl)\n",
    "#\n",
    "# Copyright 2020-2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "Demonstrates host to device copy functions using dpctl.memory.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import dpctl.memory as dpmem\n",
    "\n",
    "ms = dpmem.MemoryUSMShared(32)\n",
    "md = dpmem.MemoryUSMDevice(32)\n",
    "\n",
    "host_buf = np.random.randint(0, 42, dtype=np.uint8, size=32)\n",
    "\n",
    "# copy host byte-like object to USM-device buffer\n",
    "md.copy_from_host(host_buf)\n",
    "\n",
    "# copy USM-device buffer to USM-shared buffer in parallel using\n",
    "# sycl::queue::memcpy.\n",
    "ms.copy_from_device(md)\n",
    "\n",
    "# build numpy array reusing host-accessible USM-shared memory\n",
    "X = np.ndarray((len(ms),), buffer=ms, dtype=np.uint8)\n",
    "\n",
    "# Display Python object NumPy ndarray is viewing into\n",
    "print(\"numpy.ndarray.base: \", X.base)\n",
    "print(\"\")\n",
    "\n",
    "# Print content of the view\n",
    "print(\"View..........: \", X)\n",
    "\n",
    "# Print content of the original host buffer\n",
    "print(\"host_buf......: \", host_buf)\n",
    "\n",
    "# use copy_to_host to retrieve memory of USM-device memory\n",
    "print(\"copy_to_host(): \", md.copy_to_host())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_simple_dpctl.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_simple_dpctl.sh; else ./run_simple_dpctl.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Management in numba-dpex\n",
    "\n",
    "numba-dpex uses USM shared memory allocator (memory_alloc) to enable host to device and vice versa data transfer. By using USM shared memory allocator, numba-dpex allows seamless interoperability between numba-dpex and other SYCL-based Python extensions and across multiple kernels written using numba_dpex.kernel decorator.\n",
    "\n",
    "numba-dpex uses the USM memory manager provided by dpctl and supports the SYCL USM Array Interface protocol to enable zero-copy data exchange across USM memory-backed Python objects.\n",
    "\n",
    "USM pointers make sense within a SYCL context and can be of four allocation types: host, device, shared, or unknown. Host applications, including CPython interpreter, can work with USM pointers of type host and shared as if they were ordinary host pointers. Accessing device USM pointers by host applications is not allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates usage of USM memory management: Inspect code, there are no modifications necessary:\n",
    "1. Inspect the code cell below and click run ▶ to save the code to file.\n",
    "2. Next run ▶ the cell in the __Build and Run__ section below the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/dpctl_mem_sample.py\n",
    "# Copyright Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import argparse\n",
    "from math import sqrt\n",
    "from time import time\n",
    "\n",
    "import dpctl\n",
    "import dpctl.memory as dpctl_mem\n",
    "import numpy as np\n",
    "\n",
    "import numba_dpex as dpex\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Program to compute pairwise distance\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\"-n\", type=int, default=10, help=\"Number of points\")\n",
    "parser.add_argument(\"-d\", type=int, default=3, help=\"Dimensions\")\n",
    "parser.add_argument(\"-r\", type=int, default=1, help=\"repeat\")\n",
    "parser.add_argument(\"-l\", type=int, default=1, help=\"local_work_size\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Global work size is equal to the number of points\n",
    "global_size = args.n\n",
    "# Local Work size is optional\n",
    "local_size = args.l\n",
    "\n",
    "X = np.random.random((args.n, args.d)).astype(np.single)\n",
    "D = np.empty((args.n, args.n), dtype=np.single)\n",
    "\n",
    "\n",
    "@dpex.kernel\n",
    "def pairwise_distance(X, D, xshape0, xshape1):\n",
    "    \"\"\"\n",
    "    An Euclidean pairwise distance computation implemented as\n",
    "    a ``kernel`` function.\n",
    "    \"\"\"\n",
    "    idx = dpex.get_global_id(0)\n",
    "\n",
    "    d0 = X[idx, 0] - X[idx, 0]\n",
    "    # for i in range(xshape0):\n",
    "    for j in range(X.shape[0]):\n",
    "        d = d0\n",
    "        for k in range(X.shape[1]):\n",
    "            tmp = X[idx, k] - X[j, k]\n",
    "            d += tmp * tmp\n",
    "        D[idx, j] = sqrt(d)\n",
    "\n",
    "\n",
    "def driver():\n",
    "    # measure running time\n",
    "    times = list()\n",
    "\n",
    "    xbuf = dpctl_mem.MemoryUSMShared(X.size * X.dtype.itemsize)\n",
    "    x_ndarray = np.ndarray(X.shape, buffer=xbuf, dtype=X.dtype)\n",
    "    np.copyto(x_ndarray, X)\n",
    "\n",
    "    dbuf = dpctl_mem.MemoryUSMShared(D.size * D.dtype.itemsize)\n",
    "    d_ndarray = np.ndarray(D.shape, buffer=dbuf, dtype=D.dtype)\n",
    "    np.copyto(d_ndarray, D)\n",
    "\n",
    "    for repeat in range(args.r):\n",
    "        start = time()\n",
    "        pairwise_distance[global_size, local_size](\n",
    "            x_ndarray, d_ndarray, X.shape[0], X.shape[1]\n",
    "        )\n",
    "        end = time()\n",
    "\n",
    "        total_time = end - start\n",
    "        times.append(total_time)\n",
    "\n",
    "    np.copyto(X, x_ndarray)\n",
    "    np.copyto(D, d_ndarray)\n",
    "\n",
    "    return times\n",
    "\n",
    "\n",
    "def main():\n",
    "    times = None\n",
    "\n",
    "    # Use the environment variable SYCL_DEVICE_FILTER to change the default device.\n",
    "    # See https://github.com/intel/llvm/blob/sycl/sycl/doc/EnvironmentVariables.md#sycl_device_filter.\n",
    "    device = dpctl.select_default_device()\n",
    "    print(\"Using device ...\")\n",
    "    device.print_device_info()\n",
    "\n",
    "    with dpctl.device_context(device):\n",
    "        times = driver()\n",
    "\n",
    "    times = np.asarray(times, dtype=np.float32)\n",
    "    print(\"Average time of %d runs is = %fs\" % (args.r, times.mean()))\n",
    "\n",
    "    print(\"Done...\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_dpctl_mem.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_dpctl_mem.sh; else ./run_dpctl_mem.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Follows Data\n",
    "Based on the Python array API standard, the “Compute Follows Data” programming model is a Python way to specify on what device a computational kernel executes. The programming model is based on the notion of the computation taking place on the device where the memory was allocated. All data movement across devices or between the host and the device is to be explicitly specified by a user. The usage inside a kernel of two arrays allocated on two different devices is disallowed.\n",
    "\n",
    "We support passing arrays of two types to a @numba_dpex.kernel decorated\n",
    "function.\n",
    "* numpy.ndarray\n",
    "* Any array with __sycl_usm_array_interface__ (SUAI) attribute.\n",
    "\n",
    "Users are not allowed to mix the type of arrays passed as arguments. As in, all the arguments passed to a @numba_dpex.kernel has to have the same type. For example, if the first array argument is of type numpy.ndarray the rest of the array arguments will also have to be of type numpy.ndarray.\n",
    "\n",
    "The following are how users can specify in which device they want to offload their computation.\n",
    "* numpy.ndarray:\n",
    "  Using context manager provided by Numba_dpex. Please look at method: select_device_ndarray()\n",
    "* Array with __sycl_usm_array_interface__ attribute:\n",
    "We follow compute follows data which states that the device where the data resides will be selected. for computation. Please look at method:  select_device_SUAI(). Users can mix SUAI arrays created using equivalent SYCL queues.\n",
    "Two SYCL queues are equivalent if they have the same:\n",
    "     * SYCL context\n",
    "     * SYCL device\n",
    "     * Same queue properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates usage of compute follows data. Inspect code; there are no modifications necessary:\n",
    "1. Inspect the following code cell and click Run (▶) to save the code to file.\n",
    "2. Next, run (▶) the cell in the __Build and Run__ section following the code to compile and execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lab/compute_follows_data.py\n",
    "# Copyright 2021 Intel Corporation\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import warnings\n",
    "\n",
    "import dpctl\n",
    "import dpctl.tensor as dpt\n",
    "import numpy as np\n",
    "\n",
    "import numba_dpex\n",
    "\n",
    "@numba_dpex.kernel\n",
    "def sum_kernel(a, b, c):\n",
    "    i = numba_dpex.get_global_id(0)\n",
    "    c[i] = a[i] + b[i]\n",
    "\n",
    "\n",
    "def allocate_SUAI_data(a, b, got, usm_type, queue):\n",
    "    da = dpt.usm_ndarray(\n",
    "        a.shape,\n",
    "        dtype=a.dtype,\n",
    "        buffer=usm_type,\n",
    "        buffer_ctor_kwargs={\"queue\": queue},\n",
    "    )\n",
    "    da.usm_data.copy_from_host(a.reshape((-1)).view(\"|u1\"))\n",
    "\n",
    "    db = dpt.usm_ndarray(\n",
    "        b.shape,\n",
    "        dtype=b.dtype,\n",
    "        buffer=usm_type,\n",
    "        buffer_ctor_kwargs={\"queue\": queue},\n",
    "    )\n",
    "    db.usm_data.copy_from_host(b.reshape((-1)).view(\"|u1\"))\n",
    "\n",
    "    dc = dpt.usm_ndarray(\n",
    "        got.shape,\n",
    "        dtype=got.dtype,\n",
    "        buffer=usm_type,\n",
    "        buffer_ctor_kwargs={\"queue\": queue},\n",
    "    )\n",
    "\n",
    "    return da, db, dc\n",
    "\n",
    "\n",
    "# ==========================================================================\n",
    "def select_device_ndarray(N):\n",
    "    a = np.array(np.random.random(N), np.float32)\n",
    "    b = np.array(np.random.random(N), np.float32)\n",
    "\n",
    "    got = np.ones_like(a)\n",
    "\n",
    "    # This context manager is specifying to use the Opencl GPU.\n",
    "    with numba_dpex.offload_to_sycl_device(\"gpu\"):\n",
    "        sum_kernel[N, 1](a, b, got)\n",
    "\n",
    "    expected = a + b\n",
    "\n",
    "    assert np.array_equal(got, expected)\n",
    "    print(\"Correct result when numpy.ndarray is passed!\")\n",
    "\n",
    "\n",
    "def select_device_SUAI(N):\n",
    "    usm_type = \"device\"\n",
    "\n",
    "    a = np.array(np.random.random(N), np.float32)\n",
    "    b = np.array(np.random.random(N), np.float32)\n",
    "    got = np.ones_like(a)\n",
    "\n",
    "    device = dpctl.SyclDevice(\"gpu\")\n",
    "    queue = dpctl.SyclQueue(device)\n",
    "\n",
    "    # We are allocating the data in Opencl GPU and this device\n",
    "    # will be selected for compute.\n",
    "    \n",
    "    da, db, dc = allocate_SUAI_data(a, b, got, usm_type, queue)    \n",
    "\n",
    "    # Users don't need to specify where the computation will\n",
    "    # take place. It will be inferred from data.\n",
    "    sum_kernel[N, 1](da, db, dc)    \n",
    "\n",
    "    dc.usm_data.copy_to_host(got.reshape((-1)).view(\"|u1\"))   \n",
    "\n",
    "    expected = a + b    \n",
    "    print(\n",
    "        \"Correct result when array with __sycl_usm_array_interface__ is passed!\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    select_device_ndarray(10)\n",
    "    select_device_SUAI(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Run\n",
    "Select the cell below and click run ▶ to compile and execute the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_compute_follows_data.sh; if [ -x \"$(command -v qsub)\" ]; then ./q run_compute_follows_data.sh; else ./run_compute_follows_data.sh; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this module you will have learned the following:\n",
    "\n",
    "* __Data parallel Control (dpCtl)__ classes and the functions of dpCtl\n",
    "* How to use dpCtl Memory Python API\n",
    "* How to perform Memory Management in numba-dpex"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.1)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "525.6px",
    "left": "28px",
    "top": "137.8px",
    "width": "301.109px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
