{
    "guid": "E8BCAF15-96AC-460A-BD45-595D48D36444",
    "name": "Getting Started with Intel® Neural Compressor for Quantization",
    "categories": ["Toolkit/oneAPI AI And Analytics/Getting Started"],
    "description": "This sample is a getting started guide for Intel® Neural Compressor to do INT8 quantization on a Huggingface BERT model. This allows us to achieve performance boosts on Intel hardware.",
    "builder": ["cli"],
    "languages": [{"python":{}}],
    "os":["linux"],
    "targetDevice": ["CPU"],
    "ciTests": {
      "linux": [
      {
          "env": [
            "apt-get update && apt-get install -y libgl1 libgl1-mesa-glx libglib2.0-0 libsm6 libxrender1 libxext6",
            "source /intel/oneapi/intelpython/bin/activate",
            "conda activate pytorch",
            "pip install uv",
            "uv python pin $(which python)",
            "uv venv --system-site-packages",
            "uv sync",
            "uv run ipython kernel install --user --name pytorch"
          ],
          "id": "quantize with inc",
          "steps": [
              "uv run jupyter nbconvert --ExecutePreprocessor.enabled=True --ExecutePreprocessor.kernel_name=pytorch --to notebook quantize_with_inc.ipynb"
           ]
      }
       ]
    },
    "expertise": "Code Optimization"
  }
