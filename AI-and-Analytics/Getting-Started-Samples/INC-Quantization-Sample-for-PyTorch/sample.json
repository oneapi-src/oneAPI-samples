{
    "guid": "E8BCAF15-96AC-460A-BD45-595D48D36444",
    "name": "Getting Started with Intel® Neural Compressor for Quantization",
    "categories": ["Toolkit/oneAPI AI And Analytics/Getting Started"],
    "description": "This sample is a getting started guide for Intel® Neural Compressor to do INT8 quantization on a Huggingface BERT model. This allows us to achieve performance boosts on Intel hardware.",
    "builder": ["cli"],
    "languages": [{"python":{}}],
    "os":["linux"],
    "targetDevice": ["CPU"],
    "ciTests": {
      "linux": [
      {
          "env": [
            "apt-get update && apt-get install -y libgl1 libgl1-mesa-glx libglib2.0-0 libsm6 libxrender1 libxext6",
            "pip install uv==0.6.3", 
            "uv sync"
          ],
          "id": "quantize with inc",
          "steps": [
              "uv run jupyter nbconvert --ExecutePreprocessor.enabled=True --to notebook quantize_with_inc.ipynb"
           ]
      }
       ]
    },
    "expertise": "Code Optimization"
  }
