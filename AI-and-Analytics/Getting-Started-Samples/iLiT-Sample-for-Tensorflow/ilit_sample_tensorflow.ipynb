{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IntelÂ® Low Precision Optimization Tool (iLiT) Sample for Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "- Train a CNN Model Based on Keras\n",
    "- Quantize Keras Model by ilit\n",
    "- Compare Quantized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iLiT Release and Sample \n",
    "\n",
    "This sample code is always updated for the iLiT release in latest oneAPI release.\n",
    "\n",
    "If you want to get the sample code for old oneAPI release, please checkout the old sample code release by git tag.\n",
    "\n",
    "1. Check tags\n",
    "\n",
    "```\n",
    "git pull\n",
    "git tag\n",
    "\n",
    "2021.1-beta08\n",
    "2021.1-beta09\n",
    "2021.1-beta10\n",
    "\n",
    "```\n",
    "\n",
    "2. Checkout old code release\n",
    "```\n",
    "git checkout 2021.1-beta10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python packages and check version.\n",
    "\n",
    "Make sure the Tensorflow is **2.2** and iLiT, matplotlib are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ilit\n",
    "print(ilit.__path__)\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a CNN Model Based on Keras\n",
    "\n",
    "We prepare a script '**alexnet.py**' to provide the functions to train a CNN model.\n",
    "\n",
    "### Dataset\n",
    "Use [MNIST](http://yann.lecun.com/exdb/mnist/) dataset to recognize hand writing numbers. \n",
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alexnet\n",
    " \n",
    "data = alexnet.read_data()\n",
    "x_train, y_train, label_train, x_test, y_test, label_test = data\n",
    "print('train', x_train.shape, y_train.shape, label_train.shape)\n",
    "print('test', x_test.shape, y_test.shape, label_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "Build a CNN model like Alexnet by Keras API based on Tensorflow.\n",
    "Print the model structure by Keras API: summary()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 10\n",
    "width = 28\n",
    "channels = 1\n",
    "\n",
    "model = alexnet.create_model(width ,channels ,classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model with the Dataset\n",
    "\n",
    "Set the **epochs** to \"**3**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "alexnet.train_mod(model, data, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze and Save Model to Single PB\n",
    "\n",
    "Set the input node name is \"**x**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "\n",
    "def save_frezon_pb(model, mod_path):\n",
    "    # Convert Keras model to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: model(x))\n",
    "    concrete_function = full_model.get_concrete_function(\n",
    "        x=tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
    "\n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_model = convert_variables_to_constants_v2(concrete_function)\n",
    "\n",
    "    # Generate frozen pb\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_model.graph,\n",
    "                      logdir=\".\",\n",
    "                      name=mod_path,\n",
    "                      as_text=False)\n",
    "fp32_frezon_pb_file = \"fp32_frezon.pb\"\n",
    "save_frezon_pb(model, fp32_frezon_pb_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la fp32_frezon.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize FP32 Model by iLiT\n",
    "\n",
    "iLiT supports to quantize the model with a validation dataset for tuning.\n",
    "Finally, it returns an frezon quantized model based on int8.\n",
    "\n",
    "We prepare a python script \"**ilit_quantize_model.py**\" to call iLiT to finish the all quantization job.\n",
    "Following code sample is used to explain the code.\n",
    "\n",
    "### Define Dataloader\n",
    "\n",
    "The class **Dataloader** provides an iter function to return the image and label as batch size.\n",
    "We uses the validation data of MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_dataset\n",
    "import math\n",
    "\n",
    "\n",
    "class Dataloader(object):\n",
    "  def __init__(self, batch_size):\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "\n",
    "  def __iter__(self):\n",
    "    x_train, y_train, label_train, x_test, y_test,label_test = mnist_dataset.read_data()\n",
    "    batch_nums = math.ceil(len(x_test)/self.batch_size)\n",
    "\n",
    "    for i in range(batch_nums-1):\n",
    "        begin = i*self.batch_size\n",
    "        end = (i+1)*self.batch_size\n",
    "        yield x_test[begin: end], label_test[begin: end]\n",
    "\n",
    "    begin = (batch_nums-1)*self.batch_size\n",
    "    yield x_test[begin:], label_test[begin:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Load FP32 Model\n",
    "Load the saved fp32 model in previous step.\n",
    "\n",
    "It's defined as alexnet.load_pb(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat alexnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Yaml File\n",
    "\n",
    "We define alexnet.yaml to save the necessary parameters for iLiT.\n",
    "In this case, we only need to change the input/output according to the fp32 model.\n",
    "\n",
    "In this case, the input node name is '**x**'.\n",
    "\n",
    "Output name is '**Identity**'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat alexnet.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tuning Function\n",
    "We follow the template to create the tuning function. The function will return a frezon quantized model (int8 model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ilit\n",
    "\n",
    "def auto_tune(input_graph_path, yaml_config, batch_size):    \n",
    "    fp32_graph = alexnet.load_pb(input_graph_path)\n",
    "    quan = ilit.Quantization(yaml_config)\n",
    "    assert(tuner)\n",
    "    dataloader = Dataloader(batch_size)\n",
    "    assert(dataloader)\n",
    "    q_model = quan(\n",
    "                        fp32_graph,\n",
    "                        q_dataloader=dataloader,\n",
    "                        eval_func=None,\n",
    "                        eval_dataloader=dataloader)\n",
    "    return q_model\n",
    "\n",
    "\n",
    "def save_int8_frezon_pb(q_model, path):\n",
    "    from tensorflow.python.platform import gfile\n",
    "    f = gfile.GFile(path, 'wb')\n",
    "    f.write(q_model.as_graph_def().SerializeToString())\n",
    "    print(\"Save to {}\".format(path))\n",
    "    \n",
    "yaml_file = \"alexnet.yaml\"\n",
    "batch_size = 200\n",
    "int8_pb_file = \"alexnet_int8_model.pb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Function to Quantize the Model\n",
    "\n",
    "Show the code in \"**ilit_quantize_model.py**\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat  ilit_quantize_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will execute the \"**ilit_quantize_model.py**\" to show the whole process of quantizing a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python ilit_quantize_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a quantized model file \"**alexnet_int8_model.pb**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Quantized Model\n",
    "\n",
    "Define a function to return validation dataset and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def val_data():\n",
    "    x_train, y_train, label_train, x_test, y_test,label_test = mnist_dataset.read_data()\n",
    "    return x_test, y_test, label_test\n",
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    same = 0\n",
    "    for i, x in enumerate(predictions):\n",
    "        if x==labels[i]:\n",
    "            same += 1\n",
    "    if len(predictions)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return same/len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define infer function to test the single frezon PB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def calc_accuracy(predictions, labels):\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    same = 0\n",
    "    for i, x in enumerate(predictions):\n",
    "        if x==labels[i]:\n",
    "            same += 1\n",
    "    if len(predictions)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return same/len(predictions)\n",
    "\n",
    "def get_concrete_function(graph_def, inputs, outputs, print_graph=False):\n",
    "    def imports_graph_def():\n",
    "        tf.compat.v1.import_graph_def(graph_def, name=\"\")\n",
    "\n",
    "    wrap_function = tf.compat.v1.wrap_function(imports_graph_def, [])\n",
    "    graph = wrap_function.graph\n",
    "\n",
    "    return wrap_function.prune(\n",
    "        tf.nest.map_structure(graph.as_graph_element, inputs),\n",
    "        tf.nest.map_structure(graph.as_graph_element, outputs))\n",
    "\n",
    "def infer_perf_pb(pb_model_file, inputs=[\"x:0\"], outputs=[\"Identity:0\"]):\n",
    "    q_model = alexnet.load_pb(pb_model_file)\n",
    "    concrete_function = get_concrete_function(graph_def=q_model.as_graph_def(),\n",
    "                                              inputs=inputs,\n",
    "                                              outputs=outputs,\n",
    "                                              print_graph=True)\n",
    "    x_test, y_test, label_test = val_data()\n",
    "\n",
    "    bt = time.time()\n",
    "    _frozen_graph_predictions = concrete_function(x=tf.constant(x_test))[0]\n",
    "    et = time.time()\n",
    "\n",
    "    accuracy = calc_accuracy(_frozen_graph_predictions, label_test)\n",
    "    print('accuracy:', accuracy)\n",
    "    throughput = x_test.shape[0] / (et - bt)\n",
    "    print('max throughput(fps):', throughput)\n",
    "\n",
    "\n",
    "    #latency when BS=1\n",
    "    bt = time.time()\n",
    "    times = 1000\n",
    "    for i in range(times):\n",
    "        _frozen_graph_predictions = concrete_function(x=tf.constant(x_test[:1]))[0]\n",
    "    et = time.time()\n",
    "\n",
    "    latency = (et - bt) * 1000 / times\n",
    "    print('latency(ms):', latency)\n",
    "\n",
    "    return accuracy, throughput, latency\n",
    "\n",
    "#warm up\n",
    "_accuracy32, _throughput32, _latency32 = infer_perf_pb(fp32_frezon_pb_file)\n",
    "\n",
    "#test\n",
    "accuracy32, throughput32, latency32 = infer_perf_pb(fp32_frezon_pb_file)\n",
    "\n",
    "accuracy8, throughput8, latency8 = infer_perf_pb(int8_pb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the functions to get the performance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(ax, rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%0.2f' % float(height),\n",
    "        ha='center', va='bottom')\n",
    "\n",
    "def draw_bar(x, t, y, subplot, color, x_lab, y_lab, width=0.2):\n",
    "    plt.subplot(subplot)\n",
    "    plt.xticks(x, t)\n",
    "    ax1 = plt.gca()\n",
    "    ax1.set_xlabel(x_lab)\n",
    "    ax1.set_ylabel(y_lab, color=color)\n",
    "    rects1 = ax1.bar(x, y, color=color, width=width)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    autolabel(ax1, rects1)\n",
    "\n",
    "\n",
    "accuracys = [accuracy32, accuracy8]\n",
    "throughputs = [throughput32, throughput8]\n",
    "latencys = [latency32, latency8]\n",
    "print('throughputs', throughputs)\n",
    "print('latencys', latencys)\n",
    "print('accuracys', accuracys)\n",
    "\n",
    "accuracys_perc = [accu*100 for accu in accuracys]\n",
    "\n",
    "t = ['FP32', 'INT8']\n",
    "x = [0, 1]\n",
    "plt.figure(figsize=(16,6))\n",
    "draw_bar(x, t, throughputs, 131, 'tab:green', 'Throughput(fps)', '', width=0.2)\n",
    "draw_bar(x, t,  latencys, 132, 'tab:blue', 'Latency(s)', '', width=0.2)\n",
    "draw_bar(x, t,  accuracys_perc, 133, '#28a99d', 'Accuracys(%)', '', width=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP32 vs INT8\n",
    "\n",
    "Compare the performance data based on data of FP32 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughputs_times = [1, throughputs[1]/throughputs[0]]\n",
    "latencys_times = [1, latencys[1]/latencys[0]]\n",
    "accuracys_times = [0, accuracys_perc[1] - accuracys_perc[0]]\n",
    "\n",
    "print('throughputs_times', throughputs_times)\n",
    "print('latencys_times', latencys_times)\n",
    "print('accuracys_times', accuracys_times)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "draw_bar(x, t, throughputs_times, 131, 'tab:green', 'Throughput Comparison (big is better)', '', width=0.2)\n",
    "draw_bar(x, t, latencys_times, 132, 'tab:blue', 'Latency Comparison (small is better)', '', width=0.2)\n",
    "draw_bar(x, t, accuracys_times, 133, '#28a99d', 'Accuracys Loss(%)', '', width=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Running is Finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[CODE_SAMPLE_COMPLETED_SUCCESFULLY]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Performance Improvement:\n",
    "\n",
    "- FP32 to INT8.\n",
    "- IntelÂ® Deep Learning Boost speed up INT8 if your CPU is the Second Generation IntelÂ® XeonÂ® Scalable Processors which supports it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
