{
	"guid": "B213F6A5-E0C3-4267-8D0B-DDA5073A3F23",
	"name": "IntelÂ® Extension for TensorFlow* Getting Started",
	"categories": ["Toolkit/oneAPI AI And Analytics/Features And Functionality"],
	"description": "This code sample will guide users how to run a TensorFlow inference workload on both the GPU and CPU by using the AI Tools.",
	"builder": ["cli"],
	"languages": [{
		"python": {}
	}],
	"os": ["linux"],
	"targetDevice": ["CPU", "GPU"],
	"gpuRequired": ["ats-m", "pvc"],
	"ciTests": {
		"linux": [{
			"env": [
				"source /intel/oneapi/intelpython/bin/activate",
				"conda activate tensorflow-gpu",
				"pip install uv",
				"uv python pin $(which python)",
				"uv venv --system-site-packages",
				"uv sync",
				"uv run ipython kernel install --user --name=tensorflow-gpu"
			],
			"id": "itex_sample_test",
			"steps": [
				"uv run jupyter nbconvert --ExecutePreprocessor.enabled=True --ExecutePreprocessor.kernel_name=tensorflow-gpu --to notebook --execute ResNet50_Inference.ipynb --output ResNet50_Inference.nbcovert.gpu.ipynb"
			]
		}]
	},
	"expertise": "Code Optimization"
}
