# TensorFlow Getting Started
Intel-optimized TensorFlow framework has been optimized using Intel(R) Deep Neural Network Library (Intel(R) DNNL) primitives. This sample shows how Intel-optimized TensorFlow enables Intel(R) DNNL calls by default. It implements an example neural network with one convolution layer and one ReLU layer. It demonstrates how to use software products that can be found in the [Intel AI Analytics Toolkit powered by oneAPI](https://software.intel.com/content/www/us/en/develop/tools/oneapi/ai-analytics-toolkit.html). 

## Key implementation details
*Please* **export the environment variable `MKLDNN_VERBOSE=1`** *to display the deep learning primitives trace during execution.*

##### Note: For convenience, code line os.environ["MKLDNN_VERBOSE"] = "1" has been added in the body of the script as an alternative method to setting this variable.

Runtime settings for `MKLDNN_VERBOSE`, `KMP_AFFINITY`, and `Inter/Intra-op` Threads are set within the script. You can read more about these settings in this dedicated document: [Maximize TensorFlow Performance on CPU: Considerations and Recommendations for Inference Workloads](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference) 

### Notes
 - The train data is generated by `np.random`. 
 - The nerual network are created by `tf.nn.conv2d` and `tf.nn.relu`.
 - The TF session is inistialized by `tf.global_variables_initializer`.
 - The train is implemented via the below for-loop: 
    ```python
    for epoch in range(0, EPOCHNUM):
        for step in range(0, BS_TRAIN):
            x_batch = x_data[step*N:(step+1)*N, :, :, :]
            y_batch = y_data[step*N:(step+1)*N, :, :, :]
            s.run(train, feed_dict={x: x_batch, y: y_batch})
    ```    

## Pre-requirement

TensorFlow is ready for use once you finish the Intel AI Analytics Toolkit installation, and have run post installation script.

You can refer to the oneAPI [main page](https://software.intel.com/en-us/oneapi) for toolkit installation, and the Toolkit [Getting Started Guide for Linux](https://software.intel.com/en-us/get-started-with-intel-oneapi-linux-get-started-with-the-intel-ai-analytics-toolkit) for post-installation steps and scripts.


## Activate conda environment With Root Access

Please follow the Getting Started Guide steps (above) to set up your oneAPI environment with the setvars.sh script. Then navigate in linux shell to your oneapi installation path, typically `~/intel/inteloneapi`. Activate the conda environment with the following command:

#### Linux
```
source activate tensorflow
```

please replace ~/intel/inteloneapi for your oneapi installation path.

## Activate conda environment Without Root Access (Optional)

By default, the Intel AI Analytics toolkit is installed in the inteloneapi folder, which requires root privileges to manage it. If you would like to bypass using root access to manage your conda environment, then you can clone your desired conda environment using the following command:

#### Linux
```
conda create --name user_tensorflow --clone tensorflow
```

Then activate your conda environment with the following command:

```
source activate user_tensorflow
```

## How to Build and Run 
To run the program on Linux*, Windows* and MacOS*, type the following command in the terminal with Python installed:
```
    python TensorFlow_GettingStarted.py
```

With successful execution, it will print out the following results:

```
    0 0.4147554
    1 0.3561021
    2 0.33979267
    3 0.33283564
    4 0.32920069
    PASSED_CICD 
```

The mkldnn run-time verbose trace should look similar to what is shown below:

2020-07-23 13:54:42.599871: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
mkldnn_verbose,exec,reorder,jit:uni,undef,in:f32_nhwc out:f32_nchw,num:1,64x4x128x128,22.9941
mkldnn_verbose,exec,reorder,simple:any,undef,in:f32_hwio out:f32_Ohwi16o,num:1,10x4x3x3,0.0249023
mkldnn_verbose,exec,convolution,jit:avx512_common,forward_training,fsrc:nchw fwei:Ohwi16o fbia:undef fdst:nChw16c,alg:convolution_direct,mb64_g1ic4oc10_ih128oh128kh3sh1dh0ph1_iw128ow128kw3sw1dw0pw1,1.302
mkldnn_verbose,exec,reorder,simple:any,undef,in:f32_nChw16c out:f32_nhwc,num:1,64x10x128x128,5.146
mkldnn_verbose,exec,eltwise,jit:avx512_common,forward_training,fdata:blocked fdiff:undef,alg:eltwise_relu,mb64ic128ih128iw10,0.744141
mkldnn_verbose,exec,eltwise,jit:avx512_common,backward_data,fdata:blocked fdiff:blocked,alg:eltwise_relu,mb64ic128ih128iw10,3.96899

Please see the [DNNL Developer's Guide](https://intel.github.io/mkl-dnn/dev_guide_verbose.html) for more details on the verbose log. 

## License  
This code sample is licensed under MIT license.